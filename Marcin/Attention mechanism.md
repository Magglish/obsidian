# Attention mechanism

Mechanizm atencji w swoim założeniu to nic innego jak uwzględnienie kontekstu wpuszczanego tekstu do modelu. Czyli podczas swoje zadania jak generowanie następnego słowa