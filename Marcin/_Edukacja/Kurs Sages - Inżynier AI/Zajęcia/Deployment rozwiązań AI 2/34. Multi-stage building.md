# 34. Multi-stage building

**

Okej zostało nam jeszcze  do omówienia jeszcze jedna ostatnia technika  nazywana Multi Stage Building,  i potem przejdziemy sobie do ćwiczeń  w którym będziecie musieli połączyć te wszystkie techniki  w jedną.

  

 multistage Building  jest Jedną z technik która jest szeroko polecana w przypadku redukcji rozmiarów kontenerów i jest ona bardzo skuteczna,  stosunkowo prosta Metoda  Ale to w głównej mierze zależy od nas jak sobie to skomplikujemy.

  

Spójrzmy sobie na naszego dockerfila.  przed chwilą omówiliśmy poetry które pozwoliło nam na to żeby  żeby w obrazie były tylko i wyłącznie pakiety pythonowe które  które używane są na produkcji.  Natomiast w naszym  obrazie są pewne rzeczy które nie są nam potrzebne do działania API.  przede wszystkim samo poetry nie jest nam potrzebne.  poetry był użyte tylko i wyłącznie po to żeby nam zainstalować środowisko  z bibliotekami używanymi na produkcji.  ale później  ja już poetry nie potrzebuję,  bo zobaczcie jak uruchamiam mój kod.  po prostu `python src/service/main.py`  i tyle. 

  

 drugą sprawą jest biblioteka `google-cloud-cli`, Generalnie na razie z nim nie skorzystaliśmy  bo Bo będziemy z niej korzystać w kontenerze dopiero na zjeździe czwartym,  natomiast ona zostanie zainstalowana w bardzo jednym prostym celu -  nasze modele wdrażana produkcja będą trzymane na jakimś storage, i najczęściej ten Storage Będzie trzymany po prostu w chmurze,  więc żeby pobrać Model z chmury to musimy mieć odpowiednią bibliotekę żeby z tą chmurą wchodzić w interakcję.  dlatego dodaliśmy tego tutaj google-cloud-cli, Skorzystamy sobie z niej dopiero w zjeździe czwartym,  tutaj nie chciałem tego robić  żeby mieć więcej czasu po prostu na Bardziej istotne tematy.  ale generalnie jakoś pobierzemy model z chmury do kontenera,  no to wszelkie te biblioteki które właśnie wchodziły w interakcje z chmurą  to nie są nam już potrzebne jak już ten model w kontenerze już jest.  więc generalnie trzeba się też ich pozbyć.

  

Właśnie multi-stage building, Który za chwileczkę poznacie,  jak sama nazwa wskazuje budujemy nasz finalny obraz wieloetapowo. I świetnie on się sprawdza właśnie w takich case'ach kiedy nie potrzebujemy już pewnych bibliotek systemowych,  i w multis-stage buildingu możemy bardzo łatwo się ich pozbyć.  zatem zacznijmy to robic:

  

Cechą charakterystyczną multiset biblijną jest to że będziemy mieli teraz więcej FROMów niż jeden.

  

Chciałbym żebyśmy po CMD dodali sobie kolejny FROM:

  

```

FROM europe-central2-docker.pkg.dev/NAZWA_PROJEKTU_NA_GCLOUD/mrybinski-live-coding-base/python:3.11-slim-bullseye-1.0.0

```

  

Który będzie dosłownie tym samym FROMem, który mamy u góry.

  

Teraz żeby odróżnić te fromy od siebie Trzeba dać im nazwę.  pierwszy FROM nazwijmy jako `build`, A drugi jako `service`.

Teraz po co to my zrobiliśmy. Zaraz się wszystko wyjaśni jak napiszemy Dockerfile do końca:

  

Następnie zróbmy ten sam krok który był u góry czyli ustawiamy sobie WORKDIR

  

```dockerfile

…

WORKDIR /app

…

```

  

I następnie wykonamy cechę charakterystyczną dla multi-stage buildingu, czyli wykorzystamy instrukcje COPY.

  

Teraz zwrócił uwagę co tutaj kopiujemy:

  

```dockerfile

…

COPY --from=build app/models models

COPY --from=build app/src src

COPY --from=build app/.venv .venv

…

```

  

Czyli Innymi słowy ja skopiowałem sobie do drugiego kroku wszystko to co zostało zbudowane w pierwszym kroku i jest zarazem niezbędne do działania mojego.  czyli w tym wypadku Są to nasze modele,  pliki konfiguracyjne,  kody źródłowy  i całe środowisko które zostały zainstalowane przez poetter i trzymane w folderze `.venv`.

  

Na końcu musimy zrobić jeszcze  dwie istotne rzeczy  to znaczy ustawić odpowiednie zmienne środowiskowe:

  

```dockerfile

ENV PATH="/app/.venv/bin:$PATH"

ENV PYTHONPATH="/app"

```

Pierwsza ścieżka `PATH`, które na początku wskazuje nam na nasze środowisko. Oznacza to że wszelkie `import`  zawarte w kodzie  najpierw mają szukać pakietów w naszym środowisku, A jeżeli nie znajdzie to  szuka dalej Zgodnie z tym co było wcześniej w `PATH` ustawione.

Druga zmienna `PYTHONPATH` Potrzebna sytuacja kiedy importujemy coś z naszych modułów z folderu `src`, Po prostu żeby python wiedział gdzie szukać naszych customowych implementacji.

  

I na końcu otwieramy  otwieramy port,  ustawiamy ENTRYPOINT wraz z CMD,  Czyli to co jest wyżej:

  

```dockerfile

…

EXPOSE 8080

ENTRYPOINT ["python"]

CMD ["src/service/main.py"]

```

  

Natomiast  to co jest w kroku Build usuwamy. 

  

Okej to teraz jakoś zdefiniowaliśmy nasz pierwszy Multi State Building To możemy całością na to spojrzeć i zastanowić się co tutaj się zadziało. 

  

Generalnie główna idea w multi stage buildingu jest bardzo proste: Budujemy kontener składający się z wielu etapów. My w tym przypadku mamy tylko dwa etapy ale może być ich dowolnie więcej. Pierwsze etapy służy do tego aby zainstalować niezbędne pakiety,  stworzyć środowisko,  pobrać jakieś rzeczy  czyli przygotować to co potrzebujemy do prawidłowego działania naszego API. A ten ostatni krok w Multi stage buildingu Zakłada skopiowanie rzeczy powstałych w poprzednich etapach  które są niezbędne do tego aby nasze API działało.  

  

Czyli w naszym przykładzie,  pierwszy krok który określił sobie jako Build  jak widzicie instaluje bibliotekę pozwalającą na interakcję Google prawdę,  która później stanie wykorzystana do pobrania modelu kontenera.  potem mamy upgrade pipa,  następnie Instalujemy poetry  po to żeby Power zainstalowane  na środowisko z pakietami używanymi na produkcji.  następnie na samym końcu kopiujemy resztę rzeczy do naszego kontenera. To jest Krok pierwszy

  

 następnie mamy krok drugi który określił jako `service`.  zobaczcie,  że krok drugi startuje od tego samego obrazu który mieliśmy.  co to oznacza?  To znaczy to to że  krok drugi startuje tylko i wyłącznie  od posiadania Pythona:3.11. Nie ma tam nic innego.  bo w tym kontenerze nic innego nie umieściliśmy tak Tam jest tylko python.  więc Potraktujcie to jako  start od początku -  mamy tylko pythona 3.11.  następnie WORKDIRA /app i  i tutaj bardzo ważna rzecz,  charakterystyczna dla multi stage buildingu,  do naszego kontenera  z czystym pythonem 3.11  kopiujemy sobie tylko to co potrzebujemy do działania naszego API.  kopiujemy to co stworzyliśmy sobie w poprzednim kroku. Modele,  konfiguracja,  pliki z kodem oraz całe powstałe środowisko, które stworzył poetry. No i na końcu ustawienia zmiennych środowiskowych, otwarcie portu ENTRYPOINT i CMD. 

  

Zobaczysz że w ten sposób my w naszym kontenerze w tym finalnym czyli serwis  nie mamy już poetry  i nie mamy już tego naszego `google-cloud-cli`.  dlaczego?  Dlatego że startowaliśmy od  obrazu tylko z Pythonem 3.11. Gdybyśmy chcieli w  W drugim etapie mieć wciąż `google-cloud-cli`  To musielibyśmy je albo skopiować albo znowu zainstalować,  ale my już go nie potrzebujemy. 

  

W ten sposób,  mając etap związany z budową wszystkiego co jest potrzebne  i potem etap  związane z kopiowaniem tego co jest niezbędne,  jesteśmy w stanie pozbyć się naszego obrazu to czego w ogóle już nie potrzebujemy. 

  

Teraz zbudujmy sobie ten kontener:

  

```bash

docker build -t mr-test -f deploy/docker/api/Dockerfile .

```

  

I zobaczmy sobie jego rozmiar:

  

```bash

docker images

```

  

Domyślnie  `docker build` w przypadku multi-stage building buduje ostatni krok, czyli nasz `service` oraz wszelkie Poprzednie kroki jeżeli są one potrzebne aby zbudować nasz krok `service`.  czyli założmy, że  w następnej fazie jest wiele dodatkowych kroków,  ale finalny krok `service`  Wymaga tylko i wyłącznie rzeczy z kroku `build`, Zatem domyślnie dopiero Build uruchomi kroki `build` oraz `service`.

  

Ale jest możliwość wskazania bezpośrednio etapu na którym chcemy zakończyć budowę,  i załóżmy że chcemy zbudować kontener  w którym Ostatni był ten pierwszy krok, czyli `build`. Do tego służy flaga `--target`.

  

```bash

docker build --target=build -t mr-test -f deploy/docker/api/Dockerfile .

```

  

Generalnie rzecz biorąc ten przykład z multi stage buildingiem myślę, że jest bardzo prosty.  ale generalnie można sobie bardzo skomplikować dockerfive'a w sytuacji kiedy chcemy tych etapów zdefiniować znacznie więcej.  my na czwartym zjeździe będziemy jeszcze definiować jeden etap pomiędzy `build` a `service`  który będzie nam potrzebne w naszym pipelineach CICD,  ale to zrobimy na zjeździe 4-tym. Natomiast  możecie spotkać się z Dockerfile’ami w których tych etapów może być znacznie znacznie więcej.  To ile ich zbudujecie to oczywiście zależy od tego z jakim obrazem kontener pracuje  oraz  to jak bardzo chcecie ten proces budowy  zdefiniować.  znacie zasadę DRY czyli Dont Repeat Yourself   której mocno trzymamy się w momencie kiedy piszemy kod,  Natomiast w przypadku docker five'a i w ogóle wszelkich skryptów dyplementowych  bardzo trudno jest tą zasadę utrzymać. Jedno z technik technik do utrzymania DRY jest  właśnie multi stage building,  ale to swój minus taki  że  wasze Dockerfile będą miały bardzo dużo etatów  przez co mogło stać cię bardzo nieczytelne  i trudne w utrzymaniu.  Jak przyjmuje zasadę że  Staram się mieć maksymalnie trzy kroki w multi-stage buildingu.  Jeżeli mam ich więcej,   to wtedy zastanawiam się czy faktycznie  nie lepiej jest jakiś kod powielić  w jakimś etapie  niż dodawać kolejne  w którym może znacznie skomplikować zrozumienie tego co się tam dzieje.  i oprócz tego Rozważam też sytuacje w której  może warto byłoby zrobić dwa Dockerfile,  odpowiedzialne za budowanie obrazów pod dwie różne rzeczy  niż próbować na siłę  wepchnąć jednego Dockerfile  kodu który stara się zbudować wszystkie rodzaje obrazów wielkie nas interesują.  mam  na myśli Case Który macie obraz zbudowany stricte pod API, Ale przy okazji na przykład  chcielibyście  użyć tego samego obrazu do  puszczania jobów odpowiedzialnych za przygotowanie danych  czy też uczeniem modeli.  Czasami wystarczy faktycznie zmienić tylko i wyłącznie ENTRYPOINT lub CMD,  ale czasami będziecie potrzebować czegoś innego w tym obrazie  i istnieje Pokusa żeby używać multi-stage buildingu  żeby właśnie mieć jednego Dockerfile’u  a w nim konkretne etapy,  gdzie jeden etap buduje  obraz pod Api inny  etap obraz pod trenowanie, a inny etap budujący obraz po przygotowanie danych. Jest to osiągalne,  Ale robi się z tego duży kolos  i trudny w utrzymaniu  i nie czytelny. Takie sytuacje lepsza jest to  aby mieć  dedykowane Dockerfile pod te case’y  niż pchać to wszystko w jeden Dockerfile. Także  uważajcie z pokusowe budowania wielkich Dockerfile i stosowania multistage buildingu aby zastosować zasadę Dont Repeat Yourself - naprawde czasami warto ją złamać, ale w efekcie bedzie mieli coś co jednak zdecydowanie łatwiej będzie utrzymać i zrozumieć zarówno przez Was samych a przede wszystkim przez waszych kolegów z zespołu. 

  

Czy macie jakieś pytania co do multi-stage building?

**