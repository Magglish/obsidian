# Cache'owanie

Jeszcze zostaniemy przy temacie warstw,  bo chciałbym teraz coś pokazać. Zbudujmy sobie kontener i otagujmy go na końcu jako test na potrzeby demonstracji. Ale teraz bez zmiennej DOCKER_BUILDKIT=0

```bash
docker build -t magglish/inzynier-ai-live-coding:test .
```

Jak widzicie pierwsza budowa kontenera trochę trwa.  Tworzony jest workdir, instalowany  pip a potem instalowane pakiety i tak dalej i tak dalej. 

A teraz wywołajmy budowę kontenera i jeszcze raz I zobaczmy wynik 

```bash
docker build -t magglish/inzynier-ai-live-coding:test .
```

Tak naprawdę kontener zbudował się w mgnieniu oka. A teraz  wprowadźmy jakąkolwiek zmianę do kodu gdziekolwiek. I Zbudujmy kontener

```bash
docker build -t magglish/inzynier-ai-live-coding:test .
```

Budowa wygląda normalnie.  z kolei kolejną uruchomienie znowu zajmie nam chwilę .

```bash
docker build -t magglish/inzynier-ai-live-coding:test .
```

Teraz o co tutaj chodzi?  Generalnie rzecz biorąc,  tak jak wam powiedziałem wcześniej,  dobre praktyki w definiowaniu Dockerfile skupiają się na dwóch rzeczach: Pierwsza jest taka żeby budowa kontenerów to było jak najszybsza,  a druga żeby kontenery były jak najmniejsze. Rozmiarami kontenerów zajmiemy się później i w ogóle tematowi rozmiarów poświęcimy bardzo dużo, czasu dlatego że to jest bardzo ważny temat. Na temat redukcji kontenerów miałem też prelekcje na dwóch konferencjach, jest to temat bardzo istotny. Teraz Natomiast skupimy się na wymiarze czasu budowy kontenera żeby on był jak najszybszy.

Fakt że ten kontener zbudował się dosłownie w sekundy, wynika to z tego że docker wykorzystuje warstwy innych kontenerów do tego aby przyspieszyć budowę danego kontenera. Domyślnie podczas uruchamiania `docker build`  wyszukuje on ten sam kontener o tej samej nazwie,  jeżeli znajduje się ona w środowisku to pobierze wszystkie warstwy które składają się na jego postać po to aby przyspieszyć jego budowę. To czy daną warstwę pociągnął z cache'a można zobaczyć po wyniku działania tej komendy, wtedy konkretne instrukcje są poprzedzane prefiksem `CACHED`. I w tym przypadku widać że wszystkie warstwy zostały pociągnięte z cache’a.  

Możemy również wskazać bezpośrednio inny kontener z którego chcemy wykorzystać warstwy korzystając z argumentu `--cache-from`.

Na przykład podczas budowy tego kontenera konkretnego możemy skorzystać z pierwszej wersji która zbudowaliśmy wcześniej:

```bash
docker build --cache-from=magglish/inzynier-ai-live-coding:1.0.0 -t magglish/inzynier-ai-live-coding:test .
```

Jeżeli w tym kontenerze które wskazaliśmy tutaj w argumencie `--cache-from` Znajdują się identyczne warstwy to po prostu Docker wykorzysta je podczas budowy naszego kontenera I proces budowy jest znacznie szybszy. Czyli dla przykładu jeżeli nasza Instrukcja `COPY . .` Kopiuję te same pliki o tych samych zawartościach co w kontenerze z którego chcemy wziąć warstwy to te pliki po prostu nie są kopiowane  z naszego systemu, tylko po prostu kopiowana jest cała warstwa z tego kontenera wskazanego jako źródło cache'a - i to znacznie przyśpiesza proces budowy kontenera.

Teraz pytanie jak docker wie czy coś się w naszej warstwie zmieniło czy nie,  tym bardziej że warstwa może dotyczyć naprawdę dużej ilości zmian w naszym kontenerze.  generalnie podczas budowy kontenera czyli podczas uruchomienia komendy `docker build` Dla każdej warstwy wyliczana jest suma kontrolna. Takie wartości są kontrole możemy podejrzeć sobie komendą docker inspect:

```bash
docker inspect magglish/inzynier-ai-live-coding:test
```

Sama ta komenda dostarczy nam bardzo dużo informacji o kontenerze, Możemy se podejrzeć To jakie są ustawione zmienne środowiskowe, Jaka jest komenda która zostanie uruchomiona podczas uruchomienia kontenera,  Jaki jest `workdir` - Generalnie wszystko to co powstało na skutek  wszystkich warstw,  czyli na podstawie wszystkich instrukcji stworzonych w Dockerfile. Na samym dole mamy listę warstw  jak widzicie każda warstwa ma swoją sumę kontrolną. Dla przypomnienia: Suma kontrola to specjalna wartość, która została wyliczona na podstawie zawartości pliku i służą do tego aby sprawdzić integralność danych. Jeżeli dwa pliki mają taką samą zawartość to ich sumy kontrole są takie same, wystarczy  wprowadzić jakąkolwiek zmianę w pliku nawet dodanie pojedynczej spacji  i cała wartość sumy kontrolnej ulega zmianie. To widzieliście poprzednio w momencie kiedy dodawaliśmy  komentarz do skryptu  i To powodowało od razu że docker budował kontener od początku. Zrobię to jeszcze raz żeby Wam pokazać.

(DODAJ TERAZ COKOLWIEK DO KODU) 

I teraz powiem ci zobaczyć że ta instrukcja WORKDIR została pociągnieta z cachea, Natomiast dalsze instrukcje zostały wykonane ponownie. 

Natomiast bardzo ważną informację dla was jest to jak te sumy kontrolne są wyliczane. 

W przypadku instrukcji COPY i ADD, którą postacie później sumy kontrole  są wliczane na podstawie plików które chcecie do kontenera skopiować. Czyli  w naszym przypadku suma kontrolna jest policzalna na całej zawartości naszego projektu.  ale suma kontrolna wszystkich innych instrukcji w dockerfile, czyli wszystkich innych warstw, jest wliczana na podstawie treści tej instrukcji. Czyli suma kontrolna dla naszej instrukcji `pip install --upgrade pip` to nie jest suma kontrolna plików które powstały lub zostały zmodyfikowane w skutek działania tej komendy, jest to po prostu suma kontrolna tego wyrażenia `pip install --upgrade pip`.

Dodatkowo Docker podczas wyliczania sumy kontrolnej uwzględnia nie tylko zawartość plików, ale również pozycję danej warstwy w Dockerfile. Więc nawet jak przesunę warstwy albo dodam/usunę inną  warstwę to zmienia się sumy kontrolne wszystkich warstw i docker będzie budował kontener na nowo.

Teraz przez to że te sumy kontrolne są tworzone w ten sposób, ma poważne implikacje przy korzystaniu z cashe’a. Rozpatrzmy ten przykład z `pip install --upgrade pip` - Ta komenda po prostu upgradeuje nam pipa do najnowszej wersji. Obecnie najnowszą wersją jest 23.3.1. Kiedy będziemy budować nasz kontener po raz pierwszy, czyli wtedy kiedy w naszym środowisku nie ma bo poprzedniego kontenera To ta komenda normalnie zostanie uruchomiona, I pip zostaje zupgradeowany do najnowszej wersji.  natomiast każda kolejna budowa będzie  korzystała z cache’a I tak naprawdę nie bedzie upgradowała pipa do najnowszej wersji tylko po prostu skopiuje zawartość warstwy z cache'a, czyli po prostu zostaną skopiowane wszystkie pliki które powstały lub zostały zmodyfikowane na skutek działania tej komendy w naszym kontenerze z którego cache’a pobieramy. I teraz wyobraźmy sobie że mija jakiś czas,  i na przykład najnowszą wersję pipa to 25.0.0. I w takiej sytuacji jeżeli uruchomimy budowę kontenera jeszcze raz,  to docker nie zrobi czegoś takiego że  sprawdzi Jaka jest wersja pipa i jeżeli jest nowsza to uruchomi to komendę,  a jeżeli jeszcze najnowsza wersja pipo to wciąż taka sama jak jest zbudowana w kontenerze z którego pobieramy casha, to wtedy skopiuję sobie warstwę - on takiego sprawdzenia nie robi. Po prostu skopiuję warstwę z cache’a i tyle, dlatego że treść tej komendy się po prostu nie zmieniła. W efekcie czego otrzymamy pipa w wersji 23.3.1, czyli tej z cachea, a nie tą najnowszą 25.0.0.

To też jest bardzo problematyczne w sytuacji gdybyście do kontenera pobierali jakiś kod znajdujący się w repozytorium gitowym.  bo tak naprawdę kod w repozytorium gitowym może cały czas się zmieniać I docker podczas budowy kontenera nie sprawdza czy coś w tym repozytorium się zmieniło i porównuje z tym co jest w cacheu.  Nie.  On tylko patrzy na naszą komendę pobierającą kod z gita czyli załóżmy, że mamy coś takiego:


```dockerfile

RUN git clone https://jakies-repo.git

```  

No to on tak naprawdę za pierwszym razem pobierze te repozytorium razem z kodem,  ale później tak naprawdę będzie pobierał cały czas z cachea to co było pobrane za pierwszym razem.  Dlatego treść tej instrukcji RUN Cały czas jest taka sama,  nie zmienia się. Czyli generalnie nie będziemy mieli za każdym razem najnowszego kodu z gita. Będziemy mieli ten, który został zapisany w kontenerze, z którego pobieramy cache'a.

**USUN TEN RUN GIT CLONE**

Teraz jak można zmusić do tego żeby  jednak proces budowy kontenera nie korzystała z cache’a, Bo na przykład chcemy żeby właśnie została pobrana najnowsza wersja pipa 25.0.0 albo żebyśmy mieli najnowszy kod w gicie.

W tym celu służy flaga `--no-cache`:

```bash
docker build --no-cache -t magglish/inzynier-ai-live-coding:test .
```

Jednakże minusem tej flagi jest to że wtedy cały cache jest wyłączony. A co gdybyśmy chcieli wyłączyć cache'a tylko dla jednej pewnej warstwy, np. właśnie dla tej komendy, którą teraz rozpatrujemy: `pip install --upgrade pip` albo dla `git clone`. Niestety docker natywnie takich możliwości nie dostarcza, ale w części zaawansowanej pokażę wam trick, dzięki któremu można wyłączyć cache’a dla konkretnej pojedynczej warstwy. 

Teraz chciałbym Wam pokazać dwie stosowane techniki wykorzystywania cache’a podczas budowy kontenerów. I teraz tak.  Wcześniej używałem takiej zmiennej środowiskowej jak DOCKER_BUILDKIT=0,  co ja z tym wskazuje na to że pewna usługa w dockerze jest wyłączona. Teraz wam powiem  pokrótce Co to jest bowiem ma to ogromne znaczenie na wykorzystanie cache’a przy budowie kontenerów. DOCKER_BUILDKIT = 0 powoduje to że budujemy obraz Na starym silniku.  domyślnie ta Zmienna jest ustawiona na jedynkę czyli na True.  oznacza to że komenda docker Build za każdym razem używa najnowszego silnika do budowy obrazów.  jakiś czas temu powstał tak zwany `buildkit` Właśnie nowy silnik do budowy obrazu który miał dodatkowe możliwości, Proces budowy obrazu był znacznie szybszy i tak dalej.  do  mniej więcej połowy poprzedniego roku  poprzedni Builder był domyślnym builderem używanym podczas budowy obrazów.  Niestety od wersji dockera 23 Która pojawiła się mniej więcej właśnie w połowie poprzedniego roku,  ten nowy silnik do budowy  obrazu stał się standardem.  i to jest oczywiście dobra rzecz bo naprawdę obudowa obrazów jest znacznie,  znacznie szybsza. Niestety ma to negatywne komplikacje na sposób używania cache'a.

Dlatego chciałbym pokazać dwie techniki wykorzystania z cachea, ale one mają związek z tym czy pracujecie na dockerze zbudowane na starym silniku czy na nowym.  Generalnie rzecz biorąc większość obrazów dostępnych na docker hubie powinna być zbudowana już na najnowszym silniku.  Jednakże to nie musi być prawda w kontekście wszystkich kontenerów. Jak można sprawdzić czy dany kontener został zbudowany na bazie nowego silnika? Korzystając z docker history:

```bash
docker history magglish/inzynier-ai-live-coding:3.0.0 
```

i wtedy przy każdej warstwie pojawi się taki komentarz jak tu widzicie `buildkit.dockerfile.v0`. W przypadku gdy nie ma tego komentarza,  czyli te pole jest puste to wtedy kontenery są wbudowane na podstawie starego silnika. 

Problem też jest z chmurami, bo nie wszystkie chmury wykorzystują  nowy silnik `buildkit` Na przykład Google Cloud jeszcze go nie ma i obrazy budowane są na starym silniku.  i tam trzeba użyć trochę innej techniki żeby skorzystać z cache’a.

Dlatego to co wam teraz pokażę to są dwie techniki korzystania z cachea: Pierwsza będzie dotyczyć obrazu zbudowanych w starszej wersji silnika czyli z ustawiona zmienna `DOCKER_BUILDKIT = 0`, A druga technika korzysta z już obrazu budowanych na nowym wersji silnika,  czyli za każdym razem kiedy korzystacie z `docker build` ale bez tej zmiennej środowiskowej ustawionej na 0 - ona domyślnie jest ustawiona na 1.

Okej w takim razie Zbudujmy pierwszy obraz na starym silniku I nazwijmy go `old-engine-1.0.0`

```bash
DOCKER_BUILDKIT=0 docker build -t magglish/inzynier-ai-live-coding:old-engine-1.0.0  .
```

I zpushujmy go:

```bash
docker push magglish/inzynier-ai-live-coding:old-engine-1.0.0
```

Następnie obraz na nowym silniku jako tag new-buildkit-engine-1.0.0:

```bash
docker build -t magglish/inzynier-ai-live-coding:new-buildkit-engine-1.0.0  .
```

I zpushujmy go:

```bash
docker push magglish/inzynier-ai-live-coding:new-buildkit-engine-1.0.0
```

Spójrzmy do naszego repozytorium czy wszystko jest. Okej mamy dwa obrazy jeden zbudowana na starym silniku i jeden na nowym 

Chciałbym abyśmy wyczyścili wszystko co do tej pory stworzyliśmy za pomocą dockera.

```bash
docker system prune --all --force
```

Dlaczego to zrobiliśmy? Dlatego, że taka sytuacja, w której nic nie ma naszym komputerze, będzie w momencie kiedy będziecie korzystać z różnych usług chmurowych do budowy kontenerów albo później na zjeździe czwartym w którym kontenerem będą budowane w pipeline CICD, a nie lokalnie na komputerze. Po prostu systemy na które będą budowane kontenery w chmurze będą całkowicie puste.

Teraz stoimy przed zadaniem zbudowania kontenera z nowym  kodem,  ale chcielibyśmy skorzystać z casha po to żeby ten proces był znacznie szybszy. 

Na początek rozpatrzymy sobie case kiedy pracujemy na kontenerach zbudowanych na starym silniku.

Powiem wam że sprawa z kontenerami zbudowanym na starym silniku jest bardzo prosta i wręcz intuicyjna.  to co musimy zrobić to tak naprawdę pobrać kontener na  nasz komputer i po prostu podczas budowy naszego kontenera musimy wskazać ten problem kontener.

Pobierzmy go sobie: 

```bash
docker pull magglish/inzynier-ai-live-coding:old-engine-1.0.0
```

Zobaczmy szybko na jego historie:

```bash
docker history magglish/inzynier-ai-live-coding:old-engine-1.0.0
```

widzimy, że ten kontener został zbudowany na starym silniku bo nie ma komentarza z buildkitem. 

A następnie zbudujmy wersję drugą wskazując w cache’u wersję pierwszą. Ale uwaga pamiętajcie o tej zmiennej DOCKER_BUILDKIT=0

```bash

DOCKER_BUILDKIT=0 docker build --cache-from=magglish/inzynier-ai-live-coding:old-engine-1.0.0 -t magglish/inzynier-ai-live-coding:old-engine-2.0.0 .

```

Udało się nie ma problemu. Zobaczymy znowu historię:

```bash
docker history magglish/inzynier-ai-live-coding:old-engine-2.0.0
```

I jest zbudowany na starym obrazie, bo nie ma komentarza z buildkitem.

A teraz zobaczymy czy możemy zbudować obraz nowym silniku Korzystając  kleszu z obrazu wybudowany na starym silniku:

Znowu wyczyśćmy sobie wszystko:

```bash
docker system prune --all --force
```

Pobierzmy obraz na starym silniku:

```bash
docker pull magglish/inzynier-ai-live-coding:old-engine-1.0.0
```

I włączę budowę jeszcze raz tego nowe obrazu ale **usuwając tą zmienną środowiskową  DOCKER_BUILDKIT=0:**

```bash
docker build --cache-from=magglish/inzynier-ai-live-coding:old-engine-1.0.0 -t magglish/inzynier-ai-live-coding:old-engine-2.0.0 .
```

Widzicie tak naprawdę nie skorzystałem w ogóle z warstw z tej wersji pierwszej.  niestety wynika to właśnie z różnic w silnikach używanych do budowy obrazów. Natomiast jeżeli jeszcze raz puszczę to sobie 

```bash
docker build --cache-from=magglish/inzynier-ai-live-coding:old-engine-1.0.0 -t magglish/inzynier-ai-live-coding:old-engine-2.0.0 .
```

to teraz ten cache zadziałał. Dlaczego? Dlatego że po tej budowie on sobie stworzył tego cache’a na nowo, odpowiednio go oznaczył itd. i przechowuje go w dedykowanym miejscu. To jest jakby jedna z zalet tego nowego silnika - że nawet jak nie będzie takich samych warstw w kontenerze wskazanym w `--cache-from` to i tak poszuka on czy takich wartw nie ma gdzie indziej - mówiąc w skrócie, bo nie będziemy wnikać głęboko w szczegóły działania mechanizmu cacheowania przez Dockera, to nie jest aż tak istotne.

Czyli podsumowując, dla kontenerów zbudowanych na starym silniku musimy najpierw pobrać jakieś kontener z repozytorium,  a potem go wskazać w argumencie `--cache-from` Co jest moim zdaniem bardzo intuicyjne.  Ale wadą tego rozwiązania jest to że:
1. musimy pamiętać o tej zmiennej `DOCKER_BUILDKIT=0`
2. oraz musimy pobrać cały obraz z którego chcemy skorzystać zanim uruchomimy budowę naszego kontenera, co generalnie może wydłużyć nasz cały proces, po oprócz budowania naszego kontenera musimy zrobić coś jeszcze przed rozpoczęciem jego budowy.  

Teraz wyczyśćmy sobie znowu nasze całe środowisko  Korzystając z `docker prune`

```bash
docker system prune --all --force
```

I teraz zobaczmy jak możemy wykorzystać cache’a dla obrazów zbudowanych na nowym silniku.

W przypadku obrazów zbudowano nowym silniku zaletą nowego silnika jest to że nie musimy pobierać całego obrazu przed. Dlatego przy tym etapie pomijamy pobieranie obrazu o tagu `new-buildkit-engine-1.0.0` korzystając z `docker pull`. Możemy tak naprawdę przejść od razu do budowy czyli do `docker build`:

```bash
docker build --cache-from=magglish/inzynier-ai-live-coding:new-buildkit-engine-1.0.0 -t magglish/inzynier-ai-live-coding:new-buildkit-engine-2.0.0 .
```

I jak widać niestety cache nie zadziałał. I od razu powiem że nie chodzi tutaj o to że tego konteniera nie pobraliśmy wcześniej. Chodzi o coś zupełnie innego. Niestety ale  nowy silnik który jest domyślnie używany podczas używania `docker build`  ma pewne rozwiązanie optymalizujące jego  które mają na celu po prostu  zmniejszenie przestrzeni dyskowej jakiej potrzebujemy Żeby trzymać go w repozytorium.  to jest zmiana na lepsze oczywiście. Ale to ma ze sobą komplikuj se taką że podczas budowy kontenerów na nowym silniku  ale w taki sposób aby można było z nich później korzystać w cashu  musimy dodać pewną zmienną do budowy go Która wprost będzie określać że my świadomie chcemy żeby te warstwy wszystkie zostały zapisane w naszym repozytorium. Komplikacje to ma taką że po prostu wasz kontener będzie za mało znacznie więcej miejsca w repozytorium,  ale Użyć go w cashu żeby przyspieszyć waszą Budowę kolejnych kontenerów z kolejnymi wersjami.

  

Znowu wyczyścmy sobie środowisko:

  

```bash

docker system prune --all --force

```

  

Musimy wrócić do procesu budowy naszego kontenera na nowym silniku i dodać jedną nową zmienną:

  

```bash

docker build -t magglish/inzynier-ai-live-coding:new-buildkit-engine-1.0.0  --build-arg BUILDKIT_INLINE_CACHE=1 . 

```

  

Ta zmienna nazywa się `BUILDKIT_INLINE_CACHE` Którą musimy ustawić na wartość równą 1 czyli Innymi słowy `True`. Ta zmiana oznacza że chcemy aby wraz z kontenerem zapisywanym do repozytorium,  były zapisane również wszystkie jego warstwy tak aby można było z nich korzystać w cashu  podczas budowy przyszłych kontenerów.

  

Zpushujmy sobie tak zmodyfikowany obraz do naszego repozytorium:

  

```bash

docker push magglish/inzynier-ai-live-coding:new-buildkit-engine-1.0.0

```

  

I znowu wyczyścmy sobie środowisko:

  

```bash

docker system prune --all --force

```

  

I teraz po tych zmianach spróbujmy zbudować nowy kontener wersja 2.0.0

  

```bash

docker build --cache-from=magglish/inzynier-ai-live-coding:new-buildkit-engine-1.0.0 -t magglish/inzynier-ai-live-coding:new-buildkit-engine-2.0.0 .

```

  

Widzicie udało się.  Zobaczmy sobie jeszcze history:

```bash
docker history magglish/inzynier-ai-live-coding:new-buildkit-engine-2.0.0
```

I widzimy, że nasze warstwy teraz mają komentarz, że zostały zbudowane z wykorzystaniem buildkita.

teraz tak naprawdę przy tym podejściu warstwy są pobierane bezpośrednio z docker huba. Zalety tego podejścia jest taka że nie pobieramy całego obrazu tak to było W pierwszej metodzie wykorzystywanej w kontekście kontenerów budowane na starym silniku.  w przypadku kontenerów zbudowanych na nowym silniku te Sumy kontrolne są porównywane z warstwami zachowanymi już na repozytorium. Ma to tą zaletę że Pobierane są tylko i wyłącznie te warstwy których sumy kontrolne się zgadzają.  a pozostałe Oczywiście są odbudowywane od zera. Ten proces znacznie przyspiesza Budowę naszych kontenerów  Korzystając z cashe’a. Tylko niestety cały niuans polega na tym aby pamiętać o tej zmiennej podczas budowy kontenera `--build-arg BUILDKIT_INLINE_CACHE=1`. I moim skromnym zdaniem Osobiście wolałbym żeby działał to w drugą stronę.  żeby Trzeba było wyłączyć cache’a A nie go włączyć, Bo do tej pory przed nowym silnikiem  to było naturalne że w rejestrze kontenerów były kontenery ze wszystkimi ich warstwami które Dzięki czemu można było skorzystać z casha. I to było wręcz naturalne nad tym się człowiek nie zastanawiał. Każdy się do tego przyzwyczaił. A teraz żeby umożliwić skorzystanie z casha ja jako budujący muszę pamiętać o tym argumencie, który nie jest prosty do zapamiętania i intuicyjny. Po prostu moim zdaniem korzystanie teraz z Dockera, na nowym silniku, jest znacznie trudniejsze i tym bardziej jest to trudniejsze dla początkujących osób które mają styczność z budową kontenerów po raz pierwszy. 

  

 wracając -  to były dwie techniki wykorzystania Kesha  podczas budowy naszych kontenerów. I generalnie rzecz biorąc podczas budowy kontenerów czy to lokalnie,  czy  Czy w jakiejś usłudze chmurowej  zawsze Staramy się z tego kasza korzystać po to aby te procesy były jak najszybsze -  Powód jest bardzo prosty:  jeżeli korzystacie z chmury,  to każdy sekunda wykorzystamy procesora,  czy Bajt zajęty na dysku po prostu was kosztuje.  jeżeli coś działa szybciej Oznacza to również mniejsze koszty.  No i druga sprawa jest taka Oczywiście że jak coś działa szybciej,  to jesteście w stanie szybciej literować,  wdrażać swoje rozwiązania To też przekłada się po prostu na lepszą pracę, bo wiadomo, że nikt nie lubi czekać.  

  

Oprócz tych technik oczywiście Są jeszcze inne ale  i użyć jest raczej bardziej skomplikowane bo  w innych technikach  już zakłądamy Że pliki które służą  do użycia w cacheu są przechowywane w innym miejscu - np. na AWS na s3,  a sam obraz w innym miejscu. Ale to już są tematy bardzo zaawansowane, które wymagają doinstalowywania nowych sterowników do dockera i proces budowy kontenerów jest inny. generalnie rzadko się z tym spotkacie, najczęściej będziecie doświadczać tych dwóch podejść które Wam pokazałem. 

  

Czy macie jakieś pytania do tej części?

**