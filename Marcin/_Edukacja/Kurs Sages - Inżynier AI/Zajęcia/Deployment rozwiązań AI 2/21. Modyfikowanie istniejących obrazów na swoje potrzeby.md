# Modyfikowanie istniejących obrazów na swoje potrzeby

**

Okej to przejdźmy sobie teraz do tego co chciałbym z wami przerobić.  wcześniej podczas uruchamiania API na zjeździe pierwszym Używaliśmy komend `make redis` oraz `make postgres`. Jak spojrzymy sobie do `Makefile` co robią Te kroki. To zobaczymy że to naprawdę Te kroki uruchamiają nasze bashowe skrypty. W takim razie Spójrzmy sobie co w nich jest. Otwórzmy sobie `run_postgres.sh`. Tak za pewno się już możecie domyślać,  Ten skrypt powstał po to żeby zsetupować bazę postgresa I w tym celu po prostu używam kontenerów.  Przejdźmy sobie szybciutko co ten skrypt robi I co my  zaraz będziemy robić:

  

1. Zaczynam sobie od ustawiania zmiennej środowiskowych które  będą wykorzystywane później w skrypcie.
    
2.  Pobieram sobie obraz z moim postgresem.
    
3.  potem sprawdzam czy już jakieś kontener istnieje  na tym samym porcie i Jeżeli tak to go Usuwam. To jest dosłownie To co wy robiliście przed chwilą na ćwiczeniach.
    
4. Następny po prostu uruchamiam nasz obraz po zgresa,  wskazując flagę d żeby działał w tle,  p wskazujący na porty,  ustawiam sobie zmienność środowiskową Mówiącą o haśle No i potem skazany na obraz.
    
5.  chwilę czekamy
    
6.  potem sprawdzamy czy jest połączenie z bazą danych
    
7. I następnie jest proces związany z tworzeniem naszej bazy danych -  monitoring
    
8.  i potem kolejno odpowiednie tabele,  które  są potrzebne bo do nich zapisujemy wszystkie dane o requestach i responseach z naszych endpointów. 
    

  

Czyli  Innymi słowy pobieramy obraz  z bazą Postgres, Uruchamiamy ją i następnie operację Tak żeby ją odpowiednio skonfigurować do naszego use casea. To jest jak najbardziej okej,  Tak też może być.  natomiast można to rozwiązać troszeczkę inaczej - Tak jak widzieliście na przykładzie naszego API,  pobieraliśmy kontener z pythonem 3.11  i go sobie konfigurowaliśmy tak żeby nasze API w nim działało. I tak samo możemy zrobić przypadku każdego innego kontenera,  i też w przypadku postgresa. 

  

Generalnie W codziennej pracy przy korzystaniu z kontenerów  i dostosowania ich właśnie pod nasz use-case  spotkacie się z podejściem takim że po prostu tworzycie  obraz kontenera a w obrazie jest zaimplementowana przez cała logika wasza.  po prostu w ten sposób uzyskujecie separację, tzn. ktoś inny może zarządzać tym  obrazem i to jaki jest on tworzony np. Machine Learning Engineer,  a inna osoba (Data Scientist)  nie musisz znać całej logiki tworzenia tych baz danych i tak dalej, on se ten obraz po prostu pobierze i go Uruchomi. 

  

Więc to co my teraz chcemy zrobić to po prostu stworzymy swój własny obraz z bazą po zgresa w którym to obrazie zaimplementujemy całą logikę tworzenia bazy danych i tabel. 

  

Zaczniemy sobie od dostosowania naszej struktury projektu do tego zadania. 

1. Chciałby żebyśmy stworzyli sobie folder `deploy`
    
2. W nim folder `docker`
    
3. Następnie w folderze `docker` utwórzmy sobie 4 foldery: `api`, `python`, `redis`, `postgres`.
    
4. Przenieśmy nasz Dockerfile do `api`
    
5. A w `redis` oraz `postgres` utwórzmy nowy Dockerfile
    

  

Pobierzmy sobie obraz postgresa  oraz redisa bo na nich będziemy teraz pracować. 

  

```bash

docker pull postgres:15.4

```

  

oraz

  

```bash

docker pull redis:7.2

```

  

Otwórzmy sobie też postgresa w Docker Hubie. Jak widzicie warstw jest sporo.  i w zależności od tego co chcemy zrobić to zadanie może być łatwiejsze bądź trudniejsze. Natomiast my  w naszym przypadku nie chcemy nic zmieniać w konfiguracji samego podkresa tylko raczej chcemy wypełnić naszą bazę danych po prostu tabelkami nic więcej.  więc te warstwy związane z konfiguracją instalowaniem tego podcast'a całego czyli od 1 do 18 Nas nie interesują.  to co powinno zainteresować to to właśnie jak ta baza jest inicjowana.

  

I Spójrzcie proszę że mamy tutaj zdefiniowane ENTRYPOINT oraz CMD. I powiem od razu przeważnie w takich obrazach bazodanowych, ogólnie dostępnych Właśnie w tym ENTRYPOINT jest stworzona cała logika Inicjowania bazy danych. Widzimy, że ENTRYPOINT wskazuje na `docker_entrypoint.sh` Spójrzmy sobie na warstwę przed enterpointem żeby zobaczyć gdzie ten skrypt jest - widzimy, że kopiowany jest do `/usr/local/bin`.

  

To w takim razie Zobaczmy co ten entry Point robi.  uruchomimy sobie tego postgresa po prostu w tle:

  

```bash

docker run -d -e POSTGRES_PASSWORD=12345 postgres:15.4

```

  

Postgres wymaga od nas żebyśmy ustawili hasło w zmiennej środowiskowej.

  

a następnie wejdziemy na nasz kontener w trybie interaktywnym z shellem:

  

```bash

docker exec -it <<CONTAINER_NAME_OR_ID>> /bin/bash

```

  

przejdźmy do tej lokalizacji

  

```bash

cd /usr/local/bin

```

  

i wypiszmy sobie ten entrypoint

  

```bash

cat docker-entrypoint.sh

```

  

Jak widzicie ten enterpoint jest  bardzo obszerny,  jesteś zainteresowana cała logika inicjalizacji bazy postgres.  dlatego mówiąc że entry Point jest niezmienialny, Miała na myśli właśnie takie kejsy.  doker pozwalam żeby tego enterpointa zmienić właśnie flagą --entrypoint, Ale tego się unika No bo przeważnie enterpointach jest zdefiniowana pewna logika działania.  jeżeli jest coś co możemy zmienić to przeważnie Robimy to  poprzez CMD czy to właśnie w dockerfeilu czy na przykład poprzez przekazanie argumentów do obrazu tak to robiliśmy wcześniej,  czyli po nazwie obrazu pisaliśmy co dalej ma się zadziać.

  

Teraz tak my nie będziemy oczywiście analizować całego tego enterpointa który to widzicie,  bo na to można poświęcić cały dzień.  to co teraz ja zrobię to po prostu napiszę do Carrefoura który nam ten postgres Inicjuje od początku,  a dla was zadanie będzie zrobić to z Redisem który jest znacznie prostszy Niż postgres,  ale z racji tego że to jest wasz pierwszy kontakt z kontenerami to też może stanowić pewne wyzwanie.  dla osób zainteresowanych  polecam Po zjeździe spązie sobie na tego enterpointa,  zobaczyć jak  on stawia całą bazę danych  i  zestawić z tym co teraz w Dockerfile zdefiniuje.

  

Otworzymy sobie Dockerfile w folderze postgres:

  

```dockerfile

FROM postgres:15.4

```

  

Na początek oczywiście wskazuje postgresa.

  

```dockerfile

COPY configs/postgres/schemas/tables/decisions.sql /docker-entrypoint-initdb.d

COPY configs/postgres/schemas/tables/probabilities.sql /docker-entrypoint-initdb.d

COPY configs/postgres/schemas/tables/risk_categories.sql /docker-entrypoint-initdb.d

```

  

I tak się składa że kontener w postgresie ma taki folder jak `docker-entrypoint-initdb.d`, Do którego możemy umieścić nasze skrypty SQL  i w tym przypadku ja po prostu kopiuję z naszej polityków konfiguracyjnych to jak wygląda schema dla tabel  do tego folderu. I ten entry Point który jest w post gresie po prostu w momencie inicjalizacji bazy danych uruchomi te sql-ki.

  

```dockerfile

ENV POSTGRES_USER monitoring

ENV POSTGRES_DB monitoring

```

  

I na koniec jeszcze Musimy ustawić w pokresie informacje o naszym userze i bazie danych I niestety aby to zadziałało to te dwie zmienne muszą  przyjmować te same wartości.

  

I na koniec dodaje CMD, tak jak jest to w specyfikacji w Docker Hubie

  

```dockerfile

CMD ["postgres"]

```

  

Cały dockerfile

  

```dockerfile

FROM postgres:15.4

COPY configs/postgres/schemas/tables/decisions.sql /docker-entrypoint-initdb.d

COPY configs/postgres/schemas/tables/probabilities.sql /docker-entrypoint-initdb.d

COPY configs/postgres/schemas/tables/risk_categories.sql /docker-entrypoint-initdb.d

ENV POSTGRES_USER monitoring

ENV POSTGRES_DB monitoring

CMD ["postgres"]

```

  

I takiego postgresa sobie zbudujemy:

  

```bash

docker build -t magglish/inzynier-ai-live-coding:postgres -f deploy/docker/postgres/Dockerfile .

```

  

Tutaj pojawił się nowy argument `-f`, którym wskazujemy o który Dockerfile chodzi.

  

I również spóźnimy go sobie do naszego repozytorium.

  

Teraz wróćmy do naszego skryptu z postgresem i po prostu zmodyfikujmy go  Korzystając z naszego obrazu  i po prostu usuwałem całe logikę z setupowaniem bazy danych bo ona już została zaimplementowana w obrazie. 

  

1. Zmienną `POSTGRES_IMAGE` zmieniam na `magglish/inzynier-ai-live-coding:postgres` 
    
2. I dalej po prostu usuwam cały ten kod związany ze stopowaniem bazy
    


**CAŁY SKRYPT POWINIEN WYGLĄDAC TAK:**


```bash
#!/bin/bash  
  
set -euo pipefail  
  
POSTGRES_IMAGE="magglish/inzynier-ai-live-coding:postgres"  
HOST="127.0.0.1"  
PORT=5432  
POSTGRES_PASSWORD="12345"  
  
echo "Pulling $POSTGRES_IMAGE"  
docker pull "$POSTGRES_IMAGE"  
echo "$POSTGRES_IMAGE successfully pulled"  
echo "Checking if anything is already running on $HOST:$PORT"  
container_id=$(docker ps -f "expose=$PORT" --format "{{.ID}}")  
if [[ -n "$container_id" ]]  
then  
    echo "$HOST:$PORT is occupied by a container - killing it."    docker kill "$container_id"  
else  
    echo "Nothing is running on $HOST:$PORT"  
fi  
  
echo "Running $POSTGRES_IMAGE on $HOST:$PORT"  
postgres_container_id=$(docker run -d -p $PORT:$PORT -e POSTGRES_PASSWORD=$POSTGRES_PASSWORD "$POSTGRES_IMAGE")  
  
echo "Waiting 5 seconds for postgres to start up"  
sleep 5  
  
echo "Checking if we can connect to postgres on $HOST:$PORT"  
set +e  
response=$(pg_isready --host=$HOST --port=$PORT --username=postgres)  
if [ "$response" == "$HOST:$PORT - accepting connections" ]; then  
  echo "Success - we can connect to postgres on $HOST:$PORT"  
else  
  echo "Fail - we can't connect to postgres on $HOST:$PORT"  
  echo "$response"  
  exit 1  
fi
```



Sprawdźmy czy to zadziała:  czyli uruchamiam sobie

  

```bash

make postgres

```

  

I następnie połączmy się z naszą bazą postgres:

  

```bash

psql --dbname=monitoring --user=monitoring --host=127.0.0.1 --port=5432

```

  

Następnie sprawdźmy czy są tabelki

  

```bash

\dt

```

  

Widzimy, że są. Czyli wszystko działa.

  

```bash

exit

```

  

Czy jak widzicie udało się w ten sposób przenieść tą logikę inicjalizacji bazy danych która była po u jej uruchomieniu,  do Dockerfile Dzięki czemu ten obraz już został zbudowany z całą tą logiką inicjalizacji naszej bazy I w momencie kiedy skorzystamy z naszego obrazu żeby bazę postawić ona już będzie po prostu gotowa do naszego use-casea. 

  

Tak mówię zachęcam was do tego żeby w wolnej chwili w domu przestudiować sobie Ten entrypoint który był w postgresie. Natomiast dla was mam ćwiczenie polegające na tym abyście samodzielnie spróbowali zrobić to samo dla Redisa. 

  

Jak będziemy sobie do skryptu `run_redis.sh`. Jest on znacznie prostszy niż postresowy  i zadanie też będzie znacznie prostsze,  ale to jest wasz pierwszy kontakt z kontenerami więc chcę żebyście po prostu Zaczęli od czegoś prostszego  i spróbowali zmodyfikować jakiś kontener pod swój własny case.

  

Treść zadania oczywiście jest przygotowana,  ale Mówiąc krótko to co chcę żebyście zrobili to  przeczytali Ten skrypt który tutaj jest,  zrozumieli go co się w nim dzieje I napisali dedykowany docker file który modyfikuje ten bazowy obraz radissa  w taki sposób żeby tą inicjalizację redisa przenieść z tego skryptu do dockerfila -  analogicznie tak jak zrobiłem to w przypadku postgresa przed chwilą. Umówmy się tak że dam wam 10-15 minut na zastanowienie jesteś spróbowanie,  jeżeli  większość z was utknie na tym zadaniu to po prostu przejdziemy sobie przez nie kroczek po kroczku  żebyście wzięli dokładnie  jak to zrobić.  A jeżeli stwierdzicie  że zadanie jest proste to prosto będę chciał żeby się to rozmawiać do końca a potem sobie omówimy rozwiązanie.

