# Kolejność warstw

To jeszcze nie jest koniec na koniec naszych dywagacji o warstwach. Chciałbym teraz coś pokazać. 

Znowu jeszcze raz wyczyszczę sobie całość środowisko:

```bash
docker system prune --all --force
```

Zbuduję sobie nasz kontener jako wersję 4-tą:

```bash
docker build -t magglish/inzynier-ai-live-coding:4.0.0 .
```

Teraz dodam sobie  nową warstwę jako instrukcja utworzenia przykładowej zmiennej środowiskowej pomiędzy po instalacji bibliotek 

```dockerfile
…
RUN pip install --upgrade pip
RUN pip install -r requirements.txt
ENV EXAMPLE_ENV='test'
…
```

Zbudujmy na nowo obraz w wersji 4-tej

```bash

docker build -t magglish/inzynier-ai-live-coding:4.0.0 .

```

Jak widzicie poszło bardzo szybko.

Teraz przesunę tą zmienną wyżej pomiędzy upgradem pipa a instalacją naszych bibliotek.

```dockerfile
RUN pip install --upgrade pip
ENV EXAMPLE_ENV='test'
RUN pip install -r requirements.txt
```

Zbudujmy na nowo obraz w wersji 4-tej

```bash
docker build -t magglish/inzynier-ai-live-coding:4.0.0 .
```

Teraz widzicie że ta część związana z instalacją pipa została pociągnięta z cache’a A z kolei nasze biblioteki instalują się na nowo.

Pójdę krok dalej teraz umieszczę tą zmianą środowiskową przed instalacją pipa:

```dockerfile
ENV EXAMPLE_ENV='test'
RUN pip install --upgrade pip
RUN pip install -r requirements.txt
```

Zbudujmy na nowo obraz w wersji 4-tej

```bash
docker build -t magglish/inzynier-ai-live-coding:4.0.0 .
```

I zobaczysz tym razem zarówno  pip się upgradeuje do najnowszej wersji no i też nasze biblioteki zostały zainstalowane. Teraz pytanie powstaje dlaczego. Przecież ja tak naprawdę nic nie zmieniłem w moich instrukcjach Związanych z upgradem pipa i  instalacją bibliotek. Ja tylko dodałem moją zmienność środowiskową warstwa przed nimi i nic więcej.

Teraz to wynika z tego że działania Dockera jest następujący sposób: Jeżeli pojawiła się nowa warstwa, w tym przypadku pojawiła się nowa zmienna środowiskowa,  albo zostały dokonane jakieś zmiany w warstwie która już istniała -  czyli na przykład zmieniły się jakieś pliki bądź zmieniła się instrukcja, To doker jest w stanie to rozpoznać, dlatego że sumy kontrolne mu się nie zgadzają. Przypominam: podczas kalkulacji sum kontrolnych brana jest pod uwagę nie tylko sama treść instrukcji albo pliki jakie są kopiowane/dodawane, ale również pozycja warstwy w Dockerfile. I w takiej sytuacji docker robi tak że wszystkie warstwy które znajdują się pod warstwą dla której suma kontrolna jest inna po prostu będą odtwarzane na nowo, czyli te instrukcje zostaną wykonane ponownie a nie pobrane z cachea. 

Dlatego tak teraz widzicie w outpucie z `docker build` To `WORKDIR /app` oraz `COPY . .` Zostały pobrane z cache'a.  A potem docker Zobaczył że jest nowa warstwa związana z utworzeniem zmiennej środowiskowej  i w związku z taką zmianą on wszystkie pozostałe warstwy,  Czyli wszelkie instrukcje w dockerfine które znajdują się pod tą nową War,  czyli pod tą instrukcją tworzącą nową zmienną środowiskową odtwarza na nowo,  Czyli po prostu uruchomi na nowo te instrukcje. 

Teraz jaka logika za tym stoi - Docker nie ma mechanizmów które pozwoliłyby na wgląd bardzo szczegółowy to czy zmiana w tej jednej warstwie,  czyli Dodanie zmiennej środowiskowej ma faktycznie wpływ na kolejne warstwy. Czyli czy dodanie `EXAMPLE_ENV` wpływa w jakiś sposób na pliki które powstaną w wyniku instrukcji `pip install --upgrade pip` czy też `pip install -r requirements.txt`. Nie ma takiego mechanizmu dlatego że stworzenie takiego mechanizmu jest wręcz niemożliwe, bo musieli by rozpatrzyć każdy możliwy przypadek zmian jakie mogą zajść. Po drugie gdyby taki mechanizm nawet istniał to zakładam że trwałoby sprawdzanie tego trwało by wieki. Dlatego Docker z góry zakłada Że zmiana w jednej warstwie  może mieć wpływ na pozostałe warstwy.  może ale nie musi oczywiście,  ale Docker tego nie wie. Dlatego w takim przypadku stosowana jest technika po prostu od warstwy w której widać zmianę wszystkie pozostałe warstwy muszą zostać odtworzone na nowo. Czyli wszystkie instrukcje pod `ENV EXAMPLE_ENV='test'` Zostaną ponownie wykonane.

Teraz co to oznacza dla osób definiujących Dockerfile. Podczas budowy kierować powinny Wami dwie zasady: Kontener powinny budować się jak najszybciej i  i Kontenery powinny zajmować jak najmniej miejsca.  teraz skupiamy się na czasie budowy a odpowiednim momencie skupimy się na ich rozmiarze. 

Czyli tak naprawdę skoro wiemy o tym że docker będzie nam odtwarzał wszystkie warstwy po tej warstwie na której zobaczę jakąkolwiek zmianę, to to co my musimy zrobić to ułożyć warstwy w taki sposób,  czyli ułożyć nasze instrukcje w Dockerfile W taki sposób, aby najczęściej zmieniane warstwy były na samym końcu,  a warstwy które się najrzadziej zmieniają były na samym początku.  po to aby wszelkie zachodzące zmiany miały jak najmniejszy wpływ na proces budowy kontenera. 

To jest bardzo ważne co powiedziałem:  układamy warstwy od warstwy która może najrzadziej się zmieniać do warstwy która może często się zmieniać.

Są pewne generalne zasady ułożenie niektórych instrukcji, na temat przy bardziej rozbudowanych Dockerfile które zobaczycie później tych instrukcji będzie sporo  i po prostu znajomość waszej aplikacji jest tutaj kluczowa którą chcecie wdrażać.  czyli pisząc każdą tak naprawdę instrukcję w Dockerfile trzeba się zastanowić nad faktem Czy ona będzie się rzadko zmieniać Czy często zmieniać.  a w przypadku ustawiania zmiennych środowiskowych też trzeba już zadać sobie pytanie kiedy one są używane.  Zobaczmy sobie jak na przykład wyglądają Warstwy dla naszego python:3.11-slim-bullseye.

Spójrzmy sobie jak to wygląda.  

Mamy warstwę która ustawia nam zmienną `PATH` Czyli podstawową zmienną środowiskową która wskazuje Gdzie można znaleźć pliki wykonalne. 

Następnie mamy ustawienie zmiennych środowiskowej z językiem oraz kodowanie. 

Następnie jest instrukcja RUN która ustawia update’uje informacje o najnowszych wersjach paczek do pobrania i potem instaluje jakieś pakiety. Czy jak widzicie na początku zostało ustawione takie globalne zmienne środowiskowe I doinstalowano kilka pakietów systemowych po to aby móc dalej wykonywać kolejne operacje.

potem widzimy ustawienie już obowiązkowe związanych z kluczem gpg i wersją Pythona którą chcemy zainstalować i potem konkretne instrukcje RUN, które  tego Pythona instalują.

A potem na końcu mamy ustawienie zmiennej środowiskowych o PIPie i setup_tools I następnie oczywiście instrukcja RUN która Instaluję tego pipa i setup toolsa. Czyli jak widzicie te instrukcje zostały ułożone tak jakby od ogółu do szczegółu.  od bardziej globalnych rzeczy po coraz bardziej szczegółowe. I tak naprawdę jeżeli na przykład  w przyszłości ten obraz pythonowy zostanie zaktualizowany,  i tak jak widzicie tutaj jest taka informacja jak LAST PUSHED Czy one są cały czas update'owane  i w sytuacji kiedy np. Zmienią wersję pipa na najnowszą  to dzięki takiemu ułożeniu instrukcji,  tak naprawdę tylko warstwy pod tą zmienną środowiskową z wersją pipa  ulegną ponownemu utworzeniu, czyli Ta instrukcja zostaną wykonane ponownie.  A wszystko co było przed czyli instalacja Pythona oraz wszelkich niezbędnych bibliotek systemowych  poprostu zostanie pobrana z cache’a. A teraz Wyobraźcie sobie że te  warstwy,  Czyli instrukcję,  są ułożone na odwrót. Bo tak naprawdę zmiana wersji pipa ciągnęłaby za sobą zmianę reinstalowanie Pythona i jakiś bibliotek. Technicznie tam nie było możliwe Tak no bo jak zainstalować pipa nie mając Pythona,  ale generalnie Wiecie o co mi chodzi.

Druga istota sprawa jest to że zobaczcie że te zmienność środowiskowe zostały ustawione wtedy kiedy są tak naprawdę potrzebne.  tutaj nie widzimy czegoś takiego że to zmienia środowiskowe zostało na początku ustawione a dopiero potem kolejne instrukcje.  one są wstawane wtedy kiedy są potrzebne.  to To jest właśnie związane z tym żeby optymalizować czas budowy naszego kontenera.  gdyby te zmiany środowiskowe były ustawione na samym początku. No to obserwowalibyśmy ten fakt że zmiana wersji pipa  ciągnęłaby ze sobą instalowanie na nowo bibliotece systemowych i znowu Pythona  co jest w ogóle nieefektywne i zupełnie niepotrzebne. Dlatego cała trudność w budowie kontenera jest ułożenie instrukcji w Dockerfile W taki sposób aby po prostu  instrukcje które rzadko się zmieniają były zdefiniowane jako pierwsze, a te które najczęściej mogą się zmieniać jako ostatnie. 

  

Wróćmy teraz do naszego dockerfine i Spójrzmy do niego. Ja usunę tą zmienną example `EXAMPLE_ENV`. Nasz dockerfile W tej chwili jest stosunkowo prosty i tutaj dużo instrukcji nie ma,  więc też nie mamy za bardzo się na czym zastanawiać,   ale później nasz docker Fire będzie się rozładowywał cały czas i im więcej instrukcji tym więcej będziemy się zastanawiać nad tym czy faktycznie ich ułożenie jest poprawne.

  

 Generalnie rzecz biorąc każdy Dockerfile zaczyna się od FROM  i kończy się na CMD lub ENTRYPOINT - czym jest CMD a czym jest ENTRYPOINT  powiem o tym później.

  

Okej więc początek i koniec mamy załatwiony.

  

Dalej po FROM Instalowane są przeważnie biblioteki systemowe  Czyli wszystko to co wymagane  instalujecie za pomocą komendy `apt get install` Tak na przykład tutaj jest to widoczne w obrazie z pythonem 3.11 -> (PRZEJDZ DO OBRAZU I IM POKAŻ) `apt-get update; apt-get install -y --no-install-recommends ca-certificates netbase tzdata`. My w naszym przypadku takich bibliotek nie Instalujemy na razie.  ale nic nie stoi na przeszkodzie żeby spojrzeć dalej czy może jednak coś jest.  Zobaczcie jest sobie nasza komenda która updatetuje nam pipa. I zobaczymy na jej pozycję.  znajduje się ona obecnie po warstwie `COPY . .` Pytanie do was czy chcemy za każdym razem instalować najnowszego pipa w sytuacji gdy zmieni się na przykład kawałek naszego kodu? No raczej nie. Pip w naszym przypadku służy tylko i wyłącznie do instalowania bibliotek. I generalnie  instrukcje które tutaj odpowiedzialna jest za jego upgradeowanie można potraktować jak instrukcja instalacja jakiś systemowe pliki. Więc co to możemy tutaj zrobić to po prostu przenieść naszą komendę `RUN pip install --upgrade pip` pod FROMEM.

  

Okej idziemy dalej. Mamy naszego WORKDIRa I tutaj wam generalnie powiem że workdear jest przeważnie ustawione od razu po instalacji bibliotek systemowych.  Najlepiej jest go ustawić jak najszybciej,  bardzo ważne żeby go ustawić przed instrukcją `COPY . .` Raz że łatwiej jest z niej korzystać, A dwa że w sytuacji gdybyś się nie ustawili w ogóle WORKDIRA,  albo ustawili go później  to macie ryzyko popsucia sobie kontenera i zdebugowanie czegoś takiego jest bardzo bardzo trudne. Dlaczego? Kontener opiera się o system linuxowy i ma tą Samą strukturę plików jak on. 

  

(OTWÓRZ TERMINAL I PRZEJDŹ DO `cd /`)

  

Zobaczcie na mój terminal.  Kontener ma taką samą strukturę plików jak tutaj nasz Ubuntu,  nad wyjątkiem pewnych folderów na pewno nie będzie tam,  ale generalnie jest zbliżony w 90%. ` WORKDIR /app` oznacza,  co już wcześniej mogli się zauważyć Kiedy porównywała wam kontener do gita, Że ten folder `/app` Powstał właśnie w naszym Katalogu głównym I wszelkie pliki które kupowaliśmy do kontenera właśnie były zachowane w tym katalogu `/app` I teraz gdybyś się nie użyli Instrukcji WORKDIR w Dockerfile Albo Użyj tego za późno,  w sensie dopiero po skopiowaniu jakich plików To musicie być świadomie tego ryzyka że wszystko co skopiujecie do komputera znajdzie się właśnie w katalogu głównym. I Ryzyko jest takie że jeżeli macie jakieś pliki  o tej samej nazwie  znajdujący się w  folderach o tej samej nazwie  to może dojść do napisania czegoś  i po prostu coś Wam w kontenerze nie bedzie działało. Generalnie dobrą praktyką jest to żeby WORKDIRA ustawić po instalacji bibliotek systemowych. Więc u nas jest to okej.

  

Teraz czas na rozpracowanie `COPY . .`. Ta warstwa odpowiedzialna jest za to żeby skopiować nam całą zawartość naszego repozytorium.  i Spójrzcie proszę na kolejną warstwę Jaka jest która odpowiedzialna jest zainstalowanie bibliotek z naszego pliku `requirements.txt`. Teraz to coś widzieliście wcześniej to to że jak Wprowadzałam jakąkolwiek zmianę w skrypcie pythonowym  to ponownie były instalowane te biblioteki No bo tak są ułożone warstwy.  jeżeli coś się zmieni w plikach źródłowych czyli w instrukcji `COPY . .` to wszystkie pozostałe warstwy pod nią zostaną uruchomione ponownie.

  

Pytanie jakie sobie możemy teraz zadać to czy my musimy instalować biblioteki pythonowe wszystkie na nowo jeżeli zmieniliśmy coś w naszym kodzie źródłowym na przykład dodaliśmy docstringa do funkcji. Nie. Instalowanie bibliotek w takim przypadku jest po prostu bezsensowne  i tylko zajmuje nam czas.

  

 Generalnie to co się robi to na początku kopiuje się te pliki które odpowiedzialne są za stworzenie środowiska,  a dopiero później kupujemy pliki pozostałe które  są niezbędne do działania naszej aplikacji. W naszym przypadku sprawa jest bardzo prosta,  my tak naprawdę na początku Potrzebujemy tylko i wyłącznie `requirements.txt` żeby zainstalować nasze środowisko. Więc to co ja zrobię to przeniosę `COPY . .` po warstwie związanej z instalacją bibliotek. A przed nią to tam nową warstwę związaną tylko i wyłącznie z kopiowaniem `requirements.txt`.

  

W ten sposób zmiany tylko i wyłącznie w rekormensach spowodują reinstalowanie  wszystkich  biblioteki na nowo. A z kolei jakiekolwiek zmiany w kodzie źródłowym po prostu nie spowodują tak to było wcześniej ponowne instalowanie pilota,  Bo to jest po prostu niepotrzebne. Dalej mamy naszą zmienność środowiskową i otwarcie portu. Tak wam powiedziałem zmienność na wojskowe najlepiej jest umieścić w miejscu w którym faktycznie potrzebujemy.  A my tej zmiany potrzebujemy wtedy kiedy uruchamiamy naszą komendę `python src/service/main.py` Więc generalnie można by przesunąć ENV PYTHONPATH po EXPOSE. Ale tu jest pewny wyjątek. Generalnie dobrą praktyką jest to aby instrukcja EXPOSE Czy otwarcie portu było przed ostatnią instrukcją w dockerfilu.  to jest praktyka wynikająca z wygody,  o portach będę mówił trochę później,  ale chodzi o to w tym żeby użytkownicy którzy muszą się dowiedzieć tego jakie porty są otwarte w kontenerze nie musieli werterować po wszystkich warstwach które są w kontenerach  Tylko żeby spojrzeli na przedostatnią warstwę w której powinna znaleźć informacja o otwarciu portów. Więc w tym wypadku CMD jak ostatnie, a EXPOSE jako przedostatnia. I tobie na ten moment zakończyło naszą optymalizację Dockerfila:

  

```dockerfile

FROM python:3.11-slim-bullseye

RUN pip install --upgrade pip

WORKDIR /app

COPY requirements.txt .

RUN pip install -r requirements.txt

COPY . .

ENV PYTHONPATH='/app'

EXPOSE 8080

CMD python src/service/main.py

```

  

W takim razie teraz zbudujmy go sobie:

  

```bash

docker build -t magglish/inzynier-ai-live-coding:4.0.0 .

```

  

No i dla przykładu spróbujmy sobie zmienić coś w naszym kodzie źródłowym i zobaczmy jak będzie wyglądał proces budowy

  

(ZMIEŃ COŚ W src/service/main.py)

  

I znowu Zbudujmy nasz kontener:

  

```bash

docker build -t magglish/inzynier-ai-live-coding:4.0.0 .

```

  

I teraz wycisz że praktycznie zmiana wchodzisz w domu spowodowała to że nasz ko kontener zbudował się w imieniu oka - nie musieliśmy już czekać na  instalację bibliotek tak jak to było wcześniej. 

  

Czy macie jakieś pytania do tej części?

  

 generalnie my przez cały nasz weekend poświęcony na kontenerem będziemy cały czas zastanawiać się nad tym jak te warstwy układać  więc generalnie wraz z praktyką i budową różnych kontenerów nabierzecie takiej intuicji  Jak układać te instrukcje w Dockerfile Aby  aby czas budowy tych kontenerów było mnie po prostu jak najszybszy.

  

Okej to na koniec Zbudujmy sobie jeszcze nasz kontener z tą flagą pozwalająca na korzystanie później z cachea:

  

```bash

docker build -t magglish/inzynier-ai-live-coding:4.0.0 --build-arg BUILDKIT_INLINE_CACHE=1 .

```

  

I zpushujmy go sobie do repo:

  

```bash

docker push magglish/inzynier-ai-live-coding:4.0.0

```**