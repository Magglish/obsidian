# Praca z kontenerem

### TUTAJ DO README DODAJ ŚCIĄGI JAKIE KOMENDY SĄ POTRZEBNE DO ZREALIZOWANIA ĆWICZEŃ


## ZAPROPONUJ IM ZEBY ZAPISYWALI SOBIE WSZYSTKIE KOMENDY GDZIES NA BOKU

Okej jak już zrobiliśmy dyskusję od tego czym jest obraz Czym jest kontener w takim razie będziemy powoli zapoznawać się ze wszystkimi najważniejszymi komendami które podczas pracy z dokerem będziecie używać.

  

Weźmy sobie do dokumentacji dockera  i zobaczmy jaki mamy komendy: [https://docs.docker.com/engine/reference/commandline/docker/](https://docs.docker.com/engine/reference/commandline/docker/) . Jak widzicie jest ich naprawdę dużo my nie będziemy oczywiście omawiać wszystkich z nich tylko pewne komendy które bardzo często możecie korzystać.  później w trakcie pracy Jeżeli będzie potrzeba skorzystania z czegoś innego to sobie po prostu spokojnie poradzicie generalnie interakcja z obrazami i kontenerami nie jest trudna i dokumentacja do Kara jest bardzo bardzo dobra dlatego że oprócz wyjaśnienia co tego będę robił podaje też konkretne przykłady jakiś użyć więc nie jest to takie straszne. 


 rzućmy sobie  okiem szybciutko na docker Run. Patrzcie że tak samo mnogość opcji,  argumentów jakie może podać do gwara jest bardzo duża. Tak samo nie będziemy omawiać wszystkich argumentów tylko te które są najważniejsze,  ale Spójrzcie proszę na prawą stronę czyli na spis treści, Że jest cała masa przykładów tego jak konkretne argumenty użyć,  nawet. Nawet na przykład w naszym przypadku jest sekcja  Jak uruchomić kontener żeby on miał dostęp do naszej karty graficznej co w naszym przypadku amelowym jest bardzo istotne bo część modeli będzie uczę na kartę graficznych albo na przykład inferencja będzie wykonywana na kartach graficznych. Jest naprawdę dokumentacja dockera jest świetna I to jest wasz największy przyjaciel podczas pracy z Jokerem. 

  

Więc tak jak mówiłem: Chcę omówić najważniejsze komendy z których najczęściej się korzysta, Oraz tak samo Omówię najważniejsze argumenty który też się najczęściej korzysta.  a ćwiczenia będą tak ułożone żebyście korzystali z kilku komend na raz Żeby rozwiązać jakiś problem. A z kolei wasze notatki które powstaną słuchając mnie oraz dokumentacja doktora będą waszymi największymi przyjaciółmi żeby rozwiązać dane zadanie. 

  

Zaczniemy sobie od interakcji z obrazami.

  

Mówiąc interakcja z obrazami a na myśli nasze komendy które do tej pory używaliśmy czyli build, push i pull. Polecam wam otworzę sobie dokumentację na boku tak żeby widzieć potem zalety argumenty.

  

Zaczniemy w takim razie od naszego builda, które bardzo dużo wcześniej używaliśmy:

  

```bash

docker build -t magglish/inzynier-ai-live-coding:old-engine-example

```

  

Wspominał na początku najważniejszym argumentem w sumie do kepi Gdzie jest  tag naszego obrazu, który  nadawaliśmy przez argumenty `-t`, albo `--tag`.  ale oczywiście możemy nadać wiele tagów dla jednego obrazu. Generalnie obrazy mają  przeważnie wiele tagów,  bo tam po prostu łatwiej je do zrozumieć.  my na przykład na zjedzie czwartym poświęconym CICD, Będziemy dodatkowo nadawać tagi obrazom Jako wartości komitów czy na przykład gitowego Taga tak żeby  odnaleźć konkretne obraz kontenera z konkretną implementacją z naszego repo. To jest jeden z best practises.

  

Jeżeli w trakcie budowania zapomnimy jakimś tagu dodać, To nic straconego jest do tego konkretna komenda:

  

```bash

docker tag magglish/inzynier-ai-live-coding:4.0.0 magglish/inzynier-ai-live-coding:new-example-tag

```

Można też dodać tag do obrazu, który nie ma tagu, robiąc to po IMAGE ID:


```
docker tag 00c2e6569a2f costam/example:test
```

Pierwszy argument podajemy po prostu  obraz który chcemy atakować,  a potem w drugim argumencie podajemy całą pełną nazwę.  i możemy to sobie zobaczyć komendą:

  

```bash

docker images

```

  

Że mamy teraz dany obraz z kilkoma tagami.

  

Kolejnym argumentem, z którego korzystaliśmy to był `--cache-from`

  

```bash

docker build --cache-from=magglish/inzynier-ai-live-coding:4.0.0 -t magglish/inzynier-ai-live-coding:old-engine-example

```

  

Wskazanie na kontener, którego użyjemy jako cachea. Przy czym Możemy użyć argumentu --cache-from kilkukrotnie,  i będziemy tego używać ale dopiero później kiedy poznacie Czym jest budowanie wiele atomowe, czyli multi-stage building. Bardzo ważne podkreślana jest to,  że Że jeżeli nie wskażecie kontenera w argumencie --cache-from  to i tak docker będzie starał się tego cachea użyć - robi to na dwa sposoby:  Jeżeli istnieje już taki sam obraz jak nasz,  ale z Tagiem `latest`, czyli najnowszy,  to  postaraj się go wykorzystać do cache’a. Natomiast jeżeli nie ma,  no to nowy silnik to wygląda na rów który jest domyślny  on ma swoje jakieś wydarzenie mechanizmy szukania cache’a w plikach których on sobie zapisuje gdzieś. Jeżeli w sumie kontrolnej sobie gadają to oczywiście skorzysta z tych warstw z cache’a zamiast budować je na nowo.

  

Jest też argument `--no-cache`

  

```bash

docker build --no-cache -t magglish/inzynier-ai-live-coding:old-engine-example

```

  

Który po prostu wyłącza nam kasza podczas budowy obrazu. Generalnie w praktyce zawsze Staramy się z tego korzystać po to aby nasza budowa po prostu była szybka.  natomiast czasami możecie skorzystać  z argumentów --no-cache ale to raczej w sytuacji sprawdzenia czegoś, zdebugowania. Bardziej w celach eksperymentalnych.  jest pewien Case kiedy cache’a warto wyłączyć -  wtedy kiedy Korzystamy w naszym o obrazie z pobrania kodu z repozytorium gita ale wtedy stosuje się pewien trik, żeby  wyłączyć każda tylko i wyłącznie dla warstwy związanej z pobraniem kodu z gita,  ale nie dla całego kontenera.  To wam pokaże dopiero przy tematach  związane z best practises, bardziej zaawansowany temat. Także w produkcyjnym i automatycznym budowaniu kontenerów podczas Wdrażania  nowego kodu do repo gitowego  nie zobaczycie raczej wykorzystania argumentów --no-cache Bo tak powiedziałem,  cały etap budowy obrazów wygląda zawsze się układa tak żeby z tego cache jak najbardziej skorzystać.

  

 jest jeszcze jeden ważny argument,  --build-arg, którego używaliśmy raz:

  

```bash

docker build -t magglish/inzynier-ai-live-coding:example --build-arg=BUILDKIT_INLINE_CACHE=1 .

```



Pamiętacie te problemy z `pip install upgrade pip` albo z `git clone` o którym mówiłem.

  

Generalnie --build-arg Stosowane są po to żeby sterować jakoś tym jak ten obraz musi być zbudowany. Tak to widzieliście tutaj tym argument określałem żeby w obrazie były zapisane wszystkie meta dane aby można było skorzystać z niego jako źródło dla cachea. Natomiast my też możemy swoim teorfio zdefiniować argumenty,  którymi można sterować z poziomu właśnie `docker build`, Ale jest na temat bardziej zaawansowany będziemy to robić później. 

  

Generalnie rzecz biorąc  przeważnie docker build bez żadnych argumentów jest w zupełności wystarczający żeby zbudować obraz i z tego korzystać. Stosowanie tych konkretnych argumentów oznaczać będzie jakiś specjalny use-case, których oczywiście na zjeździe będziecie się uczyć.

  

Następnie po budowie  obrazu trzeba by go zpushować. 

  

```bash

docker push magglish/inzynier-ai-live-coding:example 

```

  

Nie ma za bardzo co ustawiać,  natomiast na pewno warto wskazać na pewien argument,  który kiedyś w tokerze był wartości domyślną  ustawioną na tak a teraz trzeba to wprost explicite wskazać. 

  

```bash

docker push --all-tags magglish/inzynier-ai-live-coding:example 

```

  

Chodzi o argument `--all-tags`, Który jest ważny wtedy kiedy ten sam obraz nazywa się tak samo tylko po prostu on ma różne tagi.  i jeżeli chcemy współżywać obraz w taki sposób żeby ten dany obraz miał te wszystkie takie na sobie,  to musimy to zrobić z `--all-tags`, Bo bez tego po prostu zostanie zburzona tylko jeden obraz z jednym tagiem. Będziemy to robić w momencie kiedy będziemy przychodzić na chmurę, Nasz obrazek po prostu będziemy tagować  kilkoma nazwami tak żeby łatwiej się odnaleźć w nich.

  

Skoro spuszowaliśmy teraz to rzućmy okiem na pulla:

  

```bash

docker pull magglish/inzynier-ai-live-coding:example 

```

  

Jak widzicie to się w ogóle nie różni za bardzo w stosunku do `docker push`. Też jest argument `--all-tags`, Ale z kolei w przypadku pulla, My wprost wiemy co chcemy zpulować, I generalnie tego `--all-tags` się rzadko używa,  bo to zacznie pobierać dużo obrazów,  a wy po prostu będziecie potrzebować jednego konkretnego. 

  

Wyświetlenie listy obrazów jaką dostępne na naszym komputerze może zabrać dwiema komendami.

  

 Pierwsza z nich

  

```bash

docker images

```

  

druga z nich

  

```bash

docker image ls

```

  

Jakie są różnice pomiędzy tymi komendami - zaraz wyjaśnię.

  

To co otrzymujemy to z lista naszych obrazów które mamy.  Jak pobrać obraz to już wiecie docker Pool, do docker pulla przejdziemy później.

  

Informacja o temacie to oczywiście jest repozytorium, tag,  Unikatowe idc obrazu,  ten IDich obrazu jest unikalny na waszych komputerze, Każdy z was powinien mieć go  inny,  data utworzenia No i oczywiście rozmiar.

  

To teraz słów kilka o tym dlaczego mam dwie komendy.  generalnie wynik z nich jest identyczny tak samo argumenty które możemy do niej podać też są identyczne.  Dlaczego zatem są dwie komendy.

  

POKAZ IM https://docs.docker.com/engine/reference/commandline/images/

  

  po prostu aby utrzymać kompatybilność wsteczną.  kiedyś używano zawsze `docker image` A potem konkretnie `ls`,  Build,  Bush,  Pool  i tak dalej. Ale potem jakby  komendy się zmieniły,   uprościli je  i zamiast pisać `docker image pull`  mamy teraz po prostu do `docker pull`.

  

I nawet jak wejdziemy sobie w te stare komendy to zobaczycie że tutaj jest w description Napisane aby po prostu wejść teraz w opis tej komendy która obecnie jest używana.  na ten my na nasze zajęciach będziemy używać tych najbardziej aktualnych komend, to jest oczywiste.

  

Teraz docker images oczywiście ma pewne argumenty, pokażę wam te najważniejsze.

  

Tylko images ma możliwość wyświetlenia wszystkich obrazów, Nawet tych pośrednich. Ale żeby to zobaczyć to musimy wrócić do naszego poprzedniego kroku i zbudować kontener w starym stylu 

  

```bash 

DOCKER_BUILDKIT=0 docker build -t magglish/inzynier-ai-live-coding:old-engine-example .

```

  

I zobaczmy teraz mamy jedynkę nasz kontener Zbudowany w tym obecnym silniku,  i jeden Zbudowany w tym starym teraz jak wyświetlimy sobie wszystkie kontener damy flaga All

  

```bash

docker images --all

```

  

To obok tych naszego Obrazy zbudowanego na starym silniku pojawiły się też takie  nowe wpisy które jak widzicie mają wszędzie none,  i te wpisy się powielają Jedyna różnica to jest to że idki są inne.  teraz Co to jest -  flaga All pozwala nawet na wyświetlenie jeszcze pośrednich obrazów tak zwanych intermediate containers. Generalnie my nie będziemy zaglądać i panowie dokładnie czym są indermediate containers, czyli pośrednie kontenery/ Średnio obrazy bo generalnie wy nie będzie z nich tych pośrednich obrazów korzystać,  one są tylko i wyłącznie używane przez dockera w momencie używania cachea. Czyli te intermedit containers tutaj Widzicie to tak naprawdę  obrazy  z poszczególnych kroków naszego torfalu.

  

Czy jak spojrzymy sobie na nasz Dockerfile to z każdego kroku jest tworzony  tak zwany intermediate container. Czyli terminy dyskontainer to jest działanie instrukcji  od pierwszej do drugiej,  potem kolejny intermittainer to jest działanie instrukcji od pierwszej do trzeciej,  potem  od pierwszej do czwartej,  potem od 1 do 5, i tak dalej i tak dalej,  czyli w sumie to co mam tłumaczyłem przy warstwach i  pokazywałem jak się zmieniają zawartości kontenera właśnie po każdym etapie.  więc nas potrzeby swojego działania docker tworzę takie właśnie pośrednie kontenery po to żeby móc je wykorzystać potem jako Cash.  więc generalnie to są takie techniczne rzeczy dla dockera i dopiero Zobaczymy je wtedy kiedy wywołamy argument `--all`. Ale generalnie w praktyce nie będziecie mieli potrzeby żeby patrzeć na te intermedit containers, Więc nie będziecie Za bardzo używać tej flagi `--all`.

  

Natomiast jak uruchomimy sobie `docker images`, ale bez flagi `--all` To wciąż możemy zobaczyć takie dziwne rzeczy jak na przykład obrazy które właśnie nie mają ani repozytorium ani tego mają tylko IDka, co to jest? Teraz to są obrazy które zostały zbudowane,  one miały wcześniej  nazwę repozytorium oraz Taga,  ale później został zbudowany inny obraz  i temu  nowemu obrazowi zostało nadana nazwa repozytorium oraz tak taki sam jaki był wcześniej na innym obrazie.  w efekcie czego te  te nazwy repozytorium i Taga przechodzą na inny obraz,  a ten poprzedni ma wszędzie puste wartości. 

  

Czy gdybym ja teraz zbudował Nowy obraz o tych samych nazwach to ten obraz który teraz zaznacza on straci te wszystkie nazwy będzie <none>, A ten nowo zbudowany obraz będzie miał po prostu nazwę repozytorium i tag.

  

Okej Przejdźmy sobie do jeszcze jednego bardzo ważnego argumentu, który nam się przyda przyszłości.

  

Tak jak wspomniałem ten image ID który tutaj widzicie on jest stworzony tylko i wyłącznie na naszym komputerze. To znaczy że ja mam innego idk niż wy macie u siebie. Natomiast każdy z obrazów ma takie unikalny idik globalny który zawsze będzie taki sam  i można go znaleźć poprzez  argument Digest

  

```bash

docker images --digests

``` 

  

Jak widzicie macie teraz taką informację że każdy z naszych obrazów ma Digest i pewien ciąg znaków Czyli po prostu hasz jednoznacznie go identyfikujący. Teraz po co to jest będziemy z tego później korzystać  przy temacie zapewnienia sobie reprodukowalności naszego kontenera w stu procentach. Trzeba teraz powiedzieć o jednej bardzo ważnej rzeczy, obrazy które są w dockerhubie jak tutaj w naszym przykładzie Python 3.11-slim-bullseye Są update'owane co jakiś czas,  tak to widzicie i ostatni update był kilka dni temu.  Więc pomimo tego że zobaczę wpisane Python 311 slim bullseye,  No za każdym razem Możecie dostać inny obraz źródłowy No bo on jest cały czas updatetowany do grabie.  rozwiązaniem jest oczywiście na przykład skorzystanie nie z 3.11 a np. z 3.11.6 Czyli generalnie wskazujemy wprost wersję patcha.  jest to jakieś lepsze rozwiązanie bo jak se zobaczymy na przykład na wersję 3.11.1 No to ostatni update tego obrazu Był bardzo bardzo dawno temu -  generalnie on się nie będzie zmieniał. Ale tak jest w przypadku tego obrazu, No i wiadomo generalnie dobrą praktyką jest to żeby wersjonować nasze rozwiązania,  Jeżeli są jakieś zmiany w kodzie No to musimy nadać konkretną nową wersję w zależności od wielkości zmian naniesionych,  ale nie każdy może tego się pilnować.  w przypadku obrazu pythonowego nie mam jeszcze czego obawiać ale co jeżeli chcielibyśmy skorzystać z innego obrazu,  bardziej niszowego I chcielibyśmy się zabezpieczyć że faktycznie dostaniemy ten obraz który chcemy za każdym razem. 

  

 jeżeli spojrzymy sobie na obraz który jest do carrefoubie To zwróćcie uwagę że U góry jest napisane coś takiego jak Digest. Unikalny id każdego obrazu I każdej zmiany która zostanie do niego wprowadzona,   czyli nawet jeżeli byście korzystali z obrazu który cały czas się zmienia to możecie wrócić do konkretnych zmian Właśnie poprzez odniesienie się do tego digesta.  zatem jedna z technik zagwarantowania sobie tego żeby mi za każdym razem ten sam obraz który chcemy jest właśnie skorzystanie z digesta a nie wprost z nazwy repozytorium I taga tego obrazu. 

  

Po prostu mogę sobie skopiować ten Digest który widzicie z komendy docker images 

 i wrzucić go do `FROM`-a. Z tą różnicą że trzeba użyć małpy,  więc generalnie w którą wygląda.

  
  

```dockerfile

FROM python@sha256:876367fcc8100c84fb6951363e29112452d065eb28f8c3f05e49ca74d53eb23f

```

  

W ten sposób macie gwarancję że zawsze będzie pobierać ten sam obraz.  ale jest pewien minus dlatego że docker Hub z tego co wiem utrzymuje historię zmian obrazów przez około 5 lat,  więc po pięciu latach ten obraz o tym digeście  po prostu zniknie  no i to może być problem. Rozwiązaniem jest dosyć proste i porozmawiamy sobie to o tym później przy właśnie tematach związanych z zapewnieniem sobie  stu procentowej reprodukowalności naszego  kontenera.  Wróćmy na ten moment do naszego poprzedniego `FROM`-a.

  

Jeszcze jedna komenda która jest bardzo przydatna to po prostu filtrowanie wyników obrazów:

  

Filtorwanie obrazów które nie mają żadnego tagu:

  

```bash

docker images --filter=dangling=true

```

  

Filtrowanie obrazu z naszego repozytorium

  

```bash

docker images --filter=reference='magglish/*'

```

  

No i ostatnia rzecz - formatowanie wyniku tej komendy

  

```bash

docker images --format="{{.ID}}"

```

  

Niestety formatowanie   jest troszeczkę nieprzyjemne bo jak to widzicie mamy podwójne  klamry i nazwy kolumn z outputu, najlepiej jest to robić z otwartą dokumentacją obok. Teraz w ramach lifecodin po prostu będziemy omawiać sobie komendy najważniejsze i argumenty,   do was Ćwiczenia które dla was przygotowałem po prostu będą zakładać użycie  wielu komend naraz,  aby osiągnąć pewien cel,  więc w trakcie ćwiczeń nabierzecie wprawy.  

```bash

docker images --format="{{.ID}} - {{.CreatedAt}}"

```

Tak jak mogliśmy pobrać obrazy docker pull,  tak Tak samo możemy też się ich pozbyć  poprzez komendę

  

```bash

docker rmi <<NAZWA_OBRAZU>>

```

  

Przy czym Proszę mieć na względzie to że w ten sposób usuniemy obraz który jest dostępny u nas lokalna komputerze,  nie  nie jesteśmy w stanie usunąć obrazu  który znajduje się w repozytorium  docker Hub czy po prostu w prywatnym repozytorium w chmurze. Aby usunąć coś w docker habie trzeba to po prostu zrobić ręcznie,  a w przypadku repozytorium trzymanych w chmurze  można ręcznie oczywiście,  albo   można skorzystać z dedykowanych komend do interakcji z tą chmurą.

  

Okej więc podejrzenie obrazów mam umówione w takim razie przejdźmy do kontenerów,  ale zanim zrobimy to uruchomimy jeden kontener tak żebyśmy  mieli na co patrzeć

  

```bash

docker run -d -p 8080:8080 magglish/inzynier-ai-live-coding:4.0.0

``` 

  

Uruchomić kontener z  flagą d oraz p  wyjaśnie je później jak dojdziemy do komendy docker run.

  

Okej jeżeli w trakcie obrazu mieliśmy `docker images` to w przypadku kontenerów będzie po prostu `docker containers`

  

```bash

docker containers

```

  

ALE. Niestety tak nie jest,  działające kontenery podejrzymy sobie komendą `docker ps`

  

`ps` Od naszego linuxowej  komendy `ps` Czyli po prostu `processes`, Bo uruchamiany kontener to nic innego jak proces linuxowy,  dlatego mamy `docker ps`

  

Ale jeżeli komuś to się nie podoba to może jeszcze użyć starej komendy  zachowanej aby utrzymać kompatybilność wsteczną czyli

  

```bash

docker container ls

``` 

  

I znowu `ls` poprzez analogię do  naszej linuksowej komendy `ls`.

  

Okej wynik jest podobny troszkę się czy się pojawiło nowych.  mamy ID kontenera,  z jakiego obrazem powstało,  bardzo ważne jaka komenda została uruchomiona,  Kiedy są stworzone,  status,  otwarte porty,  jego nazwa która w tym przypadku została nadana losowa przez dockera ale my też można nazwać swoją nazwę to później będziemy robić.

  

Generalnie rzecz biorąc  argumenty które można przekazać do `docker ps` Są praktycznie takie same jak do  `docker images`, Jest kilka argumentów nowych jak sobie spojrzymy do dokumentacji. 

  

Natomiast bardzo ważna argumentu to jest flaga `--all`:

  

```bash

docker ps --all

``` 

  

Dlatego że flaga --all pokazuje nam też kontenery które zostały zatrzymane. 

  

Analogicznie jak w przypadku obrazów,  możemy  również usunąć kontener  poprzez

  

```bash

docker rm <<ID_LUB_NAZWA_KONTENERA>>

```

  

Teraz jak zatrzymać kontener, żeby przestał działać? Do tego służy po prostu

  

```bash

docker kill <<ID_OR_CONTAINER_NAME>>

``` 

  

któremu się podać idk naszego kontenera ALBO nazwe -  nie musi to być pełen idik, Albo cała nazwa wystarczy że wpiszemy pierwsze litery i docker będzie szukał już tego kontenera. 

  

Jeżeli w outpucie `docker kill` dostaniecie to co właśnie wpisaliście To znaczy że kontener został ubity.  ale on de facto dostał tego zatrzymany, Wrócimy do naszej komendy 

  

```bash

docker ps --all

```

  

To zobaczymy czy tylko dany po prostu jest status Exited.

  

Oprócz kila też jest po prostu stop:

  

```bash

docker stop <<ID_OR_CONTAINER_NAME>>

```

  

A teraz co jeżeli Chcielibyśmy go z powrotem ożywić reanimować  do tego służy po prostu

  

```bash

docker start

```

  

Do którego analogicznie albo podajemy id albo nazwę. Zobaczę sobie poprzez `docker ps`, Że nasz kontener  sobie działa  i dla testu wyślijmy sobie request:

  
  

```bash

make request

```

Okej w takim razie wracamy do naszej komendy `docker run` i przy niej spędzimy najwięcej czasu, bo jest ona najważniejsza przy pracy z kontenerami. Jak spojrzymy sobie na dokumentację to mamy mnogość różnych argumentów,  jest ich kilkadziesiąt  ale generalnie do pracy z kontenerami potrzebujemy znajomość tylko kilku z nich bo większość jest naprawdę bardzo specyficzna i wymagana w bardzo konkretnych przypadkach.

  

Zacznijmy od początku,  uruchomić kontener można w ogóle bez żadnych argumentów:

  

```bash

docker run magglish/inzynier-ai-live-coding:4.0.0 

```

  

Jak widzicie API działa,  Pytanie tylko czy przyjmuje od nas requesty.  Sprawdźmy to:

  

```bash

make request

``` 

  

Jak widzicie niestety nie,  dostajemy błąd że aby nie jest dostępna.  nawet jak spróbujemy sobie wejść na naszego lokal hosta czyli na ten link który się pojawił To widzimy że strona nie jest osiągalna. Teraz zapytasz A widział to my musimy wykonać bardzo ważny krok  czyli otworzyć porty abyśmy mogli wysłać requesty do naszego kontenera. Czyli muszę dodać argument który do tej pory cały czas dodawaliśmy

  

```bash

docker run -p 8080:8080 magglish/inzynier-ai-live-coding:4.0.0 

```

  

Spróbuj wysłać requesta

  

```bash

make request

``` 

  

I wszystko działa. Natomiast musze zrobić pewien wyjątek, tego argumentu Chciałbym zostawić na inną sekcję poświęconej zagadnieniem sieciowym w momencie kiedy będziemy już uruchamiać nasze kontenery na chmurze I będę umawiał to jak wygląda ruch sieciowy z naszego laptopa do naszego serwisu na chmurze. Tak żebyście widzieli Jak wygląda pełna ścieżka requesta od serwisu lub użytkownika  do waszego API i co po drodze może się zepsuć.  wtedy też pojęcie portu i otwieranie portów łatwiej będzie mi wytłumaczyć na konkretnym przykładzie. Dlatego na ten moment każdy uruchomienie kontenerem będziemy robić z tym argumentem  bo inaczej to nie zadziała,  natomiast dokładnie porozmawiamy sobie o nim później.

  

Okej jak widzicie po logach nasze API działa,  przyjmuje requesty,  Logi są widoczne  i możemy też interaktywnie na przykład zatrzymać działanie kontenera poprzez CTRL + C. 

  

Otwórzmy sobie drugi terminarz I zobaczmy czy faktycznie nasz kontener działa. Czy ktoś pamięta jaką komendę musze użyć, żeby zobaczyć czy mój kontener działa?

  

```bash

docker ps

```

  

Natomiast takie uruchomienie ma pełną wadę. Nasz terminal jest zablokowany  i musimy otworzyć następne żeby sobie pracować.  Generalnie w Pycharmie czy w Visual Studio Code Żaden problem ponieważ  możemy sobie otworzyć drugi terminal, no ale Wyobraźmy sobie sytuację że logujemy się na VM poprzez SSH I tam w sumie mam taką jedną sesję z jednym terminem,  więc takie blokowanie terminalu przez kontener  Może być problematyczne.  W tym celu jest flaga `--detach` , Które po prostu uruchomi nam kontener i zwolni nam terminal. A zanim to zrobimy to zatrzymajmy sobie nasz kontener który przed chwilą uruchomiliśmy. 

  

```bash

docker run -p 8080:8080 --detach magglish/inzynier-ai-live-coding:4.0.0

```

  

Jak widzicie terminal nie jest zatrzymany i dostajemy przy okazji ID kontenera, Co zobaczycie później że jest bardzo przydatne ponieważ wynik działania te komendy będziemy mogli sobie zapisywać do jakiejś zmiennej,  a w tej zmiennej będzie mieli idka kontenera i będzie nam łatwiej potem wchodzić interakcję z tym konkretnym kontenerem, Na przykład sytuację kiedy będziemy chcieli jakieś operacje sobie zautomatyzować w skrypcie bashowym - będziecie to robić w ramach ćwiczeń.

  

Okej podejrzymy sobie to GPS

  

```bash

docker ps

```

  

Jak widzicie jest nasz kontener on sobie działa.  A co z poprzednim kontenerem którego ubiliśmy?

  

```bash

docker ps --all

```

  

Jak widzimy są ze statusem exit. A spróbujmy sobie teraz uruchomić poprzedni kontener,  w momencie kiedy działa nam ten obecny.

  

```bash

docker start <<CONTAINER_ID>>

```

  

Jak widzicie nie udało się uruchomić poprzednią kontenera czytając błąd jest tutaj informacja że port jest właśnie zaalokowany. 

  

Generalnie jak sobie spojrzymy na argumenty które ma `docker start` To widzimy że to jest za bardzo nie ma  co przekazywać,  więc to oznacza że  jak już kontener powstanie to nie za bardzo mamy jak na niego wpłynąć. Dlatego bardzo ważne jest to żeby wszystko poprawnie określić to jak mają działać właśnie w  `docker run`. 

  

Umówimy sobie nasz kontener i idziemy dalej.

  

```bash

docker kill <<CONTAINER_ID

```

  

Tak widzieliście z komendy `docker ps` Mamy również nazwę naszego kontenera który też  Możemy się posługiwać w momencie pisania jakiś skryptów automatyzujących pracę. Więc te nazwy możemy sobie spokojnie nadać.

  

```bash

docker run -p 8080:8080 --detach --name=my-api magglish/inzynier-ai-live-coding:4.0.0

```

  

Generalnie polecam wam  nie korzystanie z historii komend poprzez strzałki góra dół  tylko cały czas pisać komendy od początku do końca tak żeby nabrać wprawy  i zapamiętać je wszystkie. 

  

Jak widzicie nadawanie nazwy bardzo proste  i w jakim celu jest to użyteczne? Generalnie łatwiej pracuje się z kontenerami bo nie musimy tutaj  sięgać po idki które se losowo wygenerowane,  tylko po prostu odbywa się do nazwy.  a tak się składa że praktycznie wszystkie komendy dockera  pracują zarówno na idkach jak i na nazwach.  więc nadawanie nazwy  po prostu ułatwi wam prace.

  

Ale trzeba pamiętać o bardzo ważnej rzeczy,  Zobaczcie że ja teraz ubiję ten nasz kontener o nazwie `my-api`. I jeżeli spróbuję Uruchomić nowy kontener z tą samą nazwą 

  

```bash

docker run -p 8080:8080 --detach --name=my-api magglish/inzynier-ai-live-coding:4.0.0

```

  

Macie informacje o tym  że taki kontener o takiej nazwie już istnieje.  i docker proponuje że albo usuniecie kontener albo zmienicie jego nazwę. 

  

Spróbujemy w takim razie obu rzeczy.

  

Na początek usuniemy już klontener na który staliście

  

Trochę jest bardzo prosta:

  

```bash

docker rm my-api

```

  

I zobaczmy to czy dalej jest taki kontener:

  

```bash

docker ps --all

```

  

Jak widać nie ma go. 

  

Możemy teraz stworzyć nowy kontener z to samo nazwą

  

```bash

docker run -p 8080:8080 --detach --name=my-api magglish/inzynier-ai-live-coding:4.0.0

```

  

 i widzimy że działa.

  

Znowu go ubijmy i teraz spróbujemy zmienic jego nazwe:

  

```bash

docker kill my-api

```

  

zobaczmy czy jest

  

```bash

docker ps --all

```

  

 zmiana nazwy jest bardzo prosta:

  

```bash

docker rename my-api my-api-old

```

  

Zobaczmy czy działa:

  

```bash

docker ps --all

```

  

I mamy to - nasz kontener nazywa sie teraz `my-api-old`

  

Okej włączmy sobie nasz kontener z powrotem o nazwie `my-api`. Jest on cały czas uruchamiany w tle, bo używamy flagi `--detach`  zatem nie widzimy nie widzimy całych logów z naszego API. A co jeżeli chcieliby się podejrzeć jak nasze API działa.  w tym celu służy komenda docker logs:

  

```bash

docker logs my-api

```

  

Jak widzicie otrzymałem Logi naszego API.  Ale co jeżeli chcielibyśmy te login non stop obserwować. W tym celu mamy flage `follow`:

  

```bash

docker logs --follow my-api

```

  

I wyślijmy sobie request naszego API zobaczymy czy coś tam wyprintuje. Jak widzimy działa mamy logi. Jak z tego wyjść po prostu? Po prostu CTRL+C.

  

Umówimy sobie nasz kontener i uruchomić go ponownie ale teraz bez flagi detach tak jak robiliśmy wcześniejbez flagi:

  

```bash

docker run -p 8080:8080 --name=my-api magglish/inzynier-ai-live-coding:4.0.0

```

  

 to też tak naprawdę mamy zablokowaną sesję ale  jesteśmy w trybie interaktywnym z naszym kontenerem  i generalnie wszelkie  rzeczy jakie będziemy robić Będą przekazywane właśnie do niego. Oczywiście Teraz nie mamy pola do manewru Bo jedyne co zrobimy to  możemy zasygnalizować stop działania API poprzez CTRL+C i wtedy nasze API przestanie działać.

  

Pytanie czy możemy uzyskać podobną interakcję w momencie kiedy uruchomimy nasze kontener w trybie --detach. Oczywiście możemy. Włączmy nasz komputer w trybie detach

  

```bash

docker run -p 8080:8080 --detach --name=my-api magglish/inzynier-ai-live-coding:4.0.0

```

  

I żeby wejść w interakcje z naszym kontenerem ponownie tak jak dowiedzieliście wcześniej,  wystarczy użyć komendy attach

  

```bash

docker attach my-api

``` 

  

I teraz wyślijmy sobie requesta z terminal obok:

  
  
  

```bash

make request

```

  

Jak widzicie Logi się pojawiły,  spróbujmy teraz ubić nasze API poprzez CTRL+C. I jak widzicie Zadziałało Czyli po prostu nasz kontenery przyjmował wszystko to co mu wysłaliśmy.

  

Natomiast z podpinanie się pod kontener w ten sposób jest  zależne Od tego co my zdefiniujemy w Dockerfile w ENTRYPOINT, Boat Report w tym przypadku to jest właśnie komenda która zostanie wykonana w momencie kiedy kontener zostanie uruchomiony. 

  

Jeżeli my w tym przypadku uruchomisz nasz API,  No to podbieraczy pod kontener jakby jesteśmy w tym stanie uruchomionego API. A co jeżeli chcielibyśmy na przykład podpiąc się pod kontener i móc Na przykład korzystać z Pythona który tam jest,  albo odpalić sobie shell bashowy żeby móc wykonać jakieś operacje w środku niego.

  

Włączmy sobie nasz kontener:

  

```bash

docker start my-api

```

  

 i spróbujemy wejść do niego ale w taki sposób żeby mieć dostęp do terminala i na przykład wykonywać jakiś operacje bashowe.

  

W tym celu służy `docker exec` Która pozwala wam na wykonywanie pewnych komend właśnie w dockerze.

  

Na początek wypiszmy sobie w jakim folderze się znajdujemy

  

```bash

docker exec my-api pwd

```

  

Zadziałało. Widzimy, że jest to `/app` czyli to co zostało w specyfikowane w instrukcji `WORKDIR`. 

  

Szkoda że sobie co się znajduje w kontenerze

  

```bash

docker exec my-api ls -la

```

  

Czyli zawartość w kontenerze to co skopiowaliśmy sobie w ramach tego.

  

Ale jak widzicie dostajemy  wynik naszego komendy i interakcje za kontenerem się kończy Jest możliwość, Właśnie korzystałem z `docker exec`  aby połączyć się z kontenerem  w sposób interaktywny i ciągły także możemy cały czas w nim  pozostawać i wykonywać odpowiednie  komendy.  jest to bardzo przydatne w przypadku debugowania  kontener który przestał działać:

  

```bash

docker exec --tty --interactive my-api /bin/bash

```

  

Czy Widzimy tutaj musimy uruchomić dwa  argumenty `--tty` oraz `--interactive`.

  

Zacznijmy od wyjaśnienia sobie wyjaśnia czym jest `interactive`. Pomiędzy procesami w systemie linuxowym są jakby trzy kanały komunikacji:

  

1. STDOUT - Oznacza kanał komunikacji, w którym to proces Wysyła nam jakieś informacje,  i do kanału STDOUT  trafiają wszelkie printy, echo, logi w trybie info czy debug
    
2. STDERR - Drugi kanał  komunikacji  służy do przekazywania informacji o błędach czy ostrzeżeniach  z procesu.  i to właśnie trafiają wszelkie warningi i errory
    
3. STDIN - Jest trzeci kanał komunikacji STDIN,  kiedy to my możemy wysłać jakiś input do procesu.  na przykład proces prosi nas o podanie hasła,  a my mu je przekazujemy właśnie tym kanałem komunikacji STDIN.
    

  

W momencie kiedy uruchamiacie  kontener poprzez `docker run` Domyślnie są  u ramiona Tylko wyłączyć dwa kanały komunika - STDOUT oraz STDERR, ale nie STDIN.  Zatem oznacza to że my nie możemy wysłać żadnych  danych do kontenera.

  

Ale jest taka możliwość Żeby włączyć ten kanał. W momencie docker run możemy podać argumenty `--interactive` wtedy kanał komunikacji STDIN jest uruchamiany. Natomiast nasz kontener nie był uruchamiany z tym trybem  i generalnie kontenery nie są uruchamiane z trybem w ogóle, Jeżeli nie jest on wymagany.  w lepszym przypadku API ten tryb nie jest wymagany No bo my tak naprawdę wysłała do niego dane bo przez requesty i protokół HTTP, czyli przez internet. 

  

Natomiast to co my chcemy uzyskać to właśnie interakcje z naszym kontenerem tak żebyśmy mogli z poziomu terminala móc wykonywać je w nim komendy.  za ten kanał komunikacji jest potrzebny do otwarcia żebyśmy uzyskali to co chcemy.

  

W takim razie wyłączmy na razie naszą komendę tylko w trybie Interactive

  

```bash

docker exec --interactive my-api /bin/bash

```

  

Jak widzimy mamy czarny ekran, Ale kanał komunikacji jest otwarty, Bo na przykład teraz mogę wysłać mu komendę:

  

```bash

echo “Test”

```

  

Jak będziecie wyprintował to co chcemy. Tak samo zadziała nam:

  

```bash

ls -la

```

  

Ale generalnie korzystanie w taki sposób jest niewygodne.

  

Wyjdźmy sobie z połączenia:

  

```bash

exit

```

  

Dlatego wchodzi drugi argument `--tty`. TTY oznacza Teletype, ale sama nazwa nam niewiele mówi. Jak spojrzymy sobie dokumentację to też dostaniemy  niewiele informacji. Jest tam mowa o czymś co nazywa się pseudo-TTY,  to też niewiele mówi. A teraz generalnie chodzi o to że symulowane jest zachowanie prawdziwego terminala. 

  

Zobaczmy od razu na przykładzie:

  

```bash

docker exec --interactive --tty my-api /bin/bash

```

  

Czyli połączyć mi się znowu z kontenerem,  od razu widać że termin zaczyna się od `root@ID_KONTENERA` Czyli od nazwy użytkownika, domyślnie w kontenerze jesteśmy rootem, a ten ID-ik to ID kontenera. 

  

Wykonaj mi teraz te same komendy co wcześniej i widzimy że mam jakby pracę taką samą jakąś normalnie otworzyli swój własny terminal. Co jest bardzo wygodne.

  

Spróbujmy teraz uruchomić to samo ale bez Interactive:

  

```bash

docker exec --tty my-api /bin/bash

```

  

Czyli Zobacz czy mamy zaalokowany Sztuczny terminal  ale bez otwartego kanału STDIN tak naprawdę niestety nie zrobimy. Żadna komenda nie przejdzie.

  

Potem żebyśmy mogli  Spokojnie weź sobie te kontenera i wykonałeś tam jakieś operacje  i mieć te same doświadczenia jak ma normalnie pracujemy sobie na laptopie to właśnie najlepiej jest to zrobić z flagą `--interactive` oraz `--tty`. I generalnie przyjęło się w praktyce aby korzystać z tych argumentów ale sposób krótki:

  

```bash

docker exec -it my-api /bin/bash

```

  

Czyli po prostu `-it`, gdzie `i` oznacza `--interactive`, a `t` oznacza `--tty`.

  

Czy jesteś przy komputerze Możemy nawet sobie odpalić naszą sesję pythonową.

  

```bash

python

```

  

Widzimy, że jesteśmy w Pythonie 3.11. I generalnie mamy dostęp do naszego repo, ale w kontenerze:

  

```python

from src.models.credit_score import CreditScoringModel

```

  

Okej czyli Wiemy już jak wchodzi te kontenera, jak móc w nim wykonywać pewne czynności. 

  

Pytanie jakie możemy sobie teraz zadać to czy można uruchomić już kontener w trybie interaktywnym.  No bo tutaj mamy sytuację że kontenery już sobie działa i do działającego kontenera wchodzimy poprzez `docker exec` A czy można to uzyskać od razu to znaczy ja uruchamiam kontener `docker run` i jestem w trybie interaktywnym,  mogę wykonywać  pewne operacje. Jak najbardziej jest to możliwe.

  

Do tokarana możemy przekazać te same argumenty co wcześniej czyli `--interactive` oraz `--tty` Ale zrobimy to w tym skróconym wariancie czyli `-it`. Ale to jeszcze nie wszystko dlatego że to co my robiliśmy w `docker exec` To wskazywaliśmy na uruchomienie Shella czyli `/bin/bash` I tak samo tu musimy zrobić. No ale naszym enterpointem czyli tą komendą która zostanie wykonana jest  uruchomienie naszego API. Na szczęście można zmienić entrypoint bez przebudowy naszego kontenera. I do tego właśnie służy argument `--entrypoint`. Dajmy też żeby wyrzucić argument `--detach`,  No bo to się przeczy od razu z naszym celem, W którym chcemy od razu  wejść do kontenera i móc w nim wykonywać komendy

  

```bash

docker run -p 8080:8080 --name=my-api --entrypoint=/bin/bash -it  magglish/inzynier-ai-live-coding:4.0.0

```

  

 Czyli zobaczcie co tutaj się zadziało.  Ja uruchomiłem mój kontener  w którym mam cały kod na API. I Dockerfile jest tak właśnie zdefiniowane że w momencie kiedy uruchomimy nasz kontener To  po prostu uruchomić nasz API.  my  natomiast zmieniliśmy to i powiedzieliśmy że chcemy żeby eterpointem było po prostu uruchomienie naszego Shella.  jak widzicie jesteśmy w trybie interaktywnym, możemy se podejrzeć co jest naszym kontenerze:

  

```bash

ls -la

```

  

Wchodzenie do uruchomionego kontenera poprzez `docker exec` Czy też uruchomienie obrazu jakiegoś kontenera ale zmieniając mu enterpointa na uruchomienie powłoki/shella To bardzo ważne umiejętności które wam się przydadzą W przypadku debugowania.  na przykład wejście do kontenera który działa i rzuca błędami żeby zobaczyć co może być nie tak,  Czy  czy na przykład zanim uruchomimy dane kontener i jego główną funkcję  to może chcemy po prostu uruchomić go i wejść do niego żeby zobaczyć co w nim jest. To jest szczególnie przydatne kiedy na przykład  chcecie skorzystać z jakiegoś kontenera nie waszego,  checie podejrzeć co jest w środku Żeby mniej więcej zrozumieć Jaka jest struktura plików i jakie tam są pliki  bo na przykład chcecie coś zmodyfikować W tym kontenerze  pod swoje własne potrzeby.  Nie będziemy tego robić teraz na tych ćwiczeniach,  ale w ramach przyszłych ćwiczeń będę chciał żebyście stworzyli swoje własne kontenery  z bazami danych Redis oraz Postgres dostosowane pod nasz use case. 

  

Teraz Spójrzmy sobie na nasze kontenery, które powstały

  

```bash

docker ps --all

```

  

Jak widać jest ich sporo,  i tak naprawdę będzie ich sporo bo cały czas one są ubijane ale zostaje nam taki troszeczkę śmietnik jak to widzicie. Teraz czy warto je usuwać,  To wszystko zależy.   one są zastopowane i generalnie żadnych zasobów w postaci Ramu czy co były w ogóle nie wykorzystują,  ale wykorzystują pewną przestrzeń dyskową. Żeby się ich pozbyć jest w tym celu stworzona komenda

  

```bash

docker container prune

```

  

Która po prostu usuwa wszystkie nieużywane kontenery.  i możemy zobaczyć ile zaoszczędziliśmy sobie miejsca. 

  

Teraz czy możesz jakoś zabezpieczyć przed tym,  żeby te  kontenery w momencie i zatrzymania same znikały.  i jest na to flaga w `docker run`:

  

```bash

docker run -p 8080:8080 --detach --name=my-api --rm -it  magglish/inzynier-ai-live-coding:4.0.0

```

  

Jest to flaga `--rm`, Która oznacza żeby kontener po prostu usunąć w momencie kiedy skończy swoją pracę.  w takim razie Sprawdźmy to

  

```bash

docker ps

```

  

Widzimy że działa to teraz go zatrzymamy:

  

```bash

docker kill my-api

```

  

I sprawdźmy:

  

```bash

docker ps --all

```

  

Widzimy, że nie ma żadnego kontenera. 

  

Tak jak Wam wspominałem, kontener ma dostęp do całego hardweru Którą mam na komputerze Czyli generalnie do całej pamięci RAM, czy wszystkich procesorów. Pytanie jakie możemy sobie zadać To ile teraz nasz kontener wymaga  zasobów i czy możemy jakoś go ograniczyć.

  

 do tego aby spojrzeć ile nasza kontenery wykorzysta zasobów istnieje komenda:

  

```bash

docker stats

```

  

Która domyślnie jest uruchamiana w takim trybie interaktywnym,  Czyli po prostu na żywo nam pokazuje jakie jest wykorzystanie.  Wejdźmy sobie z tego i Wejdźmy do trybu takiego bardziej statycznego:

  

```bash

docker stats --no-stream

```

  

Czyli w tym wypadku dostajemy informację o właśnie wykorzystanie CPU Memory w danym momencie.  i Widzimy tutaj ID kontenera,  nazwy kontenera,  procent wykorzystania CPU,  memory,  sieć,  blok i o, PIDS czyli liczba uruchmionych procesów

  

PYTANIE: CO TO JEST NET IO BLOCK IO

Domyślnie Kontener ma dostęp do całej pamięci i te wszystkie procesorów. Ale można spokojnie sobie to ograniczyć  w komendzie `docker run` poprzez stosowanie odpowiednich argumentów:

  

```bash
docker run -p 8080:8080 --detach --name=my-api --cpus=1 --memory=1GB magglish/inzynier-ai-live-coding:4.0.0
```

Argumenty `--cpus` i `--memory` Cóż tego żeby ograniczać zasoby kontenera. Sprawa tutaj jest bardzo prosta.

Co się stanie jeżeli zaalokujemy za mało pamięci?

Przy pamięci trzeba jeszcze powiedzieć o czymś co jest określone jako `memory swap`.

Jeżeli ustawimy taką wartość:

```bash
docker run -p 8080:8080 --detach --name=my-api --cpus=1 --memory=1GB --memory-swap=2GB magglish/inzynier-ai-live-coding:4.0.0
```

Oznacza to, że kontenerowy alokujemy fizycznej pamięci 1GB, natomiast jeżeli proces będzie wymagał większej ilości pamięci, to wtedy będzie korzystał ze `swap`-a. Tzn. te rzeczy, które nie zmieszczą się w pamięci będzie zapisywał na dysku. I w sytuacji kiedy będzie potrzeba sięgnięcia po dane, które sa na dysku, to obecne obiekty nie wykorzystywane które są w pamięci, zapisze na dysku żeby zwolnić pamięć, następnie wczyta obiekty z dysku, które są potrzebne, do swojej pamięci. I tak będzie zamieniał obiekty pomiędzy pamięcią a dyskiem, czyli od angielskiego słowa `swap`, czyli zamiana jest właśnie ta nazwa argumenty `--memory-swap`.

Teraz jakie to ma znaczenie? Nie wiem czy pamiętacie taki wykres z poprzedniego zjazdu gdzie pokazywałem czas odczytu danych z pamięci vs. czas odczytu danych z dysku na przykładzie Redisa - generalnie czytanie z dysku jest znacznie wolniejsze, więc jeżeli dojdzie do sytuacji, że kontener będzie swapował pamięć no to zauważycie znaczy spadek w szybkości działania, bo czytanie z dysku jest znacznie wolniejsze.

Domyślnie memory-swap, jeżeli go nie ustawimy wynosi 2 krotność memory. Natomiast jeżeli chcemy aby kontener nie korzystał ze swapa to trzeba go ustawić takiego samego jak memory:

```bash
docker run -p 8080:8080 --detach --name=my-api --cpus=1 --memory=1GB --memory-swap=1GB magglish/inzynier-ai-live-coding:4.0.0
```

A co by się stało gdybyśmy ustawili za małą pamięć?

```bash
docker run -p 8080:8080 --name=my-api --cpus=1 --memory=1MB --memory-swap=1MB magglish/inzynier-ai-live-coding:4.0.0
```

Nie dostaliśmy żadnej informacji.

Logi:

```bash
docker logs my-api
```

Też nic nie wskazują. Niestety nie dostaniecie informacji od kontenera o tym. Natomiast jest jedno miejsce gdzie taka informacja będzie.

```bash
docker inspect my-api
```

Trzeba odnaleźć tą informacje w kluczu State i Exit Code wskazuje wtedy na wartość 137. 

Widać, że jest. Oznacza to, że kontener został zabity albo właśnie nie wystartował dlatego, że brakuje mu pamięci.

Tą informację można również uzyskać jedną komendą, która filtruje nam output z `docker inspect`:

```bash
docker inspect my-api --format="{{.State.ExitCode}}"
```

To też powinno być widoczne na liście kontenerów

```bash
docker ps --all
```

Widizmy, że STATUS wskazuje na `Exited (137)`, czyli kontener miał za mało pamięci. Ten status code 137 jest bardzo ważny do zapamiętania, to jest sygnał, że wasz kontener ma za mało pamięci i z nim będziecie mieli doczynienia na produkcji, więc warto zapamiętać, co ta liczba oznacza. 

Możemy również zaktualizować wymagania odnośnie zasobów wykorzystywanych przez kontenery korzystając z `docker update`

```bash
docker update --memory=2GB --cpus=2 my-api 
```


I na koniec jeszcze jedna rzecz,  do tej pory umawialiśmy cały czas komendę `docker run`, Ale oprócz komendy jest `docker create`, Która przyjmuje praktycznie te same argumenty które możemy podać do `docker run` [https://docs.docker.com/engine/reference/commandline/create/](https://docs.docker.com/engine/reference/commandline/create/) , Ale Różnica jest taka że  kontener jest tworzony,  ale nie jest uruchamiany. Aby go uruchomić po prostu trzeba następnie uruchomić `docker start`. Czyli `docker run` To nic innego jak działanie dwukomet jednocześnie `docker create` i `docker start`. Więc nie będę omawiał do `docker create`,  ale w ćwiczeniu będzie przykład z tą komendą więc tam sobie ją przećwiczycie.



Została nam do omówienia jeszcze jedna, bardzo ważna rzecz zanim przejdziemy sobie do ćwiczeń na kontenerach.

  

Tak jak wam wspominałem kontener działa na naszym systemie,  generalnie on ma tak żebyś widzieliście swój własny system plików, W którym przechowywane są wszystkie pliki wraz z naszym kodem na API,  które jest potrzebne do prawidłowego działania naszego API. Tak wam mówiłem tak że kontener to jest taki wirtualny zasobnik w którym  umieszczamy wszystko to co jest niezbędne do tego aby działało, i jest on wyizolowany. Natomiast jest możliwość aby dzielić się plikami już z kontenerem który działa albo jest zatrzymane. Dzielenie jest obie strony czyli my możemy coś do kontenera sobie wysłać albo coś z kontenera wyciągnąć. Są na to dwa sposoby:

  

 Pierwsza z nich będzie polegała na kopiowanie plików z komputera do komputera,  i z kontenera do komputera  i komenda `docker cp`. Włączmy sobie nasz kontener:

  

```

docker run -p 8080:8080 --detach --name=my-api magglish/inzynier-ai-live-coding:4.0.0

```

  

Stwórzmy sobie plik testowy:

  

```bash

echo "Test" > test_cp_file.txt

```

  

I skopiujmy go sobie do kontenera:

  

```bash

docker cp ./test_cp_file.txt my-api:/app

```

  

Wskazujemy nasz plik,  i w tym wypadku możemy odnieść się do ścieżki ratywnej,  czyli od kropki mówiącej że chodzi nam o ten folder w którym Teraz jesteśmy w terminalu.  Następnie musimy wskazać nasz kontenery,  potem dwukropek, I następnie wskazuje lokalizację i tu musimy już wskazać pełną ścieżkę zaczynając od roota. 

  

 Wejdźmy sobie na kontener zobaczyć że fakturę ten plik jest:

  
  

```bash

docker exec -it my-api /bin/bash

```

  

następnie

  

```bash

ls -la

```

  

Jak widzicie jest ten plik. Teraz modyfikujmy go sobie z poziomu kontenera i zobaczymy czy możemy go skopiować z powrotem:

  

```bash

echo "from container" >> test_cp_file.txt

```

  

wychodze z kontenera:

  

```bash

exit

```

  

I kopiuje z kontenera do naszego folderu:

  

```bash

docker cp my-api:/app/test_cp_file.txt ./

```

  

Sprawdzamy:

  

```bash

cat test_cp_file.txt

```

  

Sprawa jest prosta.  natomiast należy pamiętać o tym że to co my zrobiliśmy to Kopiowanie do kontenera,  a nie do obrazu.  czyli jeżeli  znowu utworzymy nowy kontener no to tam go nie będzie.  chcemy żeby jakiś plik był cały czas naszym kontener,  to trzeba go dorzucić do obrazu w momencie kiedy on jest budowany.

  

To co my tutaj Zrobiliśmy to po prostu skupowaliśmy sobie plik do komputera,  albo z kontenera na komputer. Natomiast jest możliwe aby tworzyć pewne połączenie z kontenerem Dzięki czemu możemy się cały czas z tym plikami wymieniać.  tak jak wy nawijamca na której pracujecie musieliście sobie skonfigurować tak zwany Shared Folder, Przez które możecie się wymieniać plikami między VMką a fizycznym komputerem. To samo można zrobić w przypadku kontenera,  czyli wskazać pewien folder który będzie dostępny zarówno dla kontenera jak i dla komputera  i po prostu wymieniać plikami cały czas tak jak długo działa wasz kontener.  to o czym mówię nazywa się volume I volume jest stosowane Powszechnie właśnie po to aby wymieniać się plikami z kontenerem.

  

Bardzo ważne jest to że Volume określamy w momencie uruchomienia komputera czyli do `docker run`, Jeżeli  nie wskażemy na volume w docker run To potem już nie będzie takiej możliwości żeby go dodać.

  

Chciałbym pokazać wam dwa sposoby na to Jak podpiąć Volume,  czyli folder z którymi będziemy dzielić się danymi z kontenerem. Istnieją dwa sposoby na to,  co jest od razu wskazane w dokumentacji Zeptera ([https://docs.docker.com/storage/volumes/#choose-the--v-or---mount-flag](https://docs.docker.com/storage/volumes/#choose-the--v-or---mount-flag) ). Pokażę wam nowe podejście montowania volumes,  które mi się osobiście nie podoba,  bo ma jedną istotną wadę i moim zdaniem to tylko komplikuje mocno sprawę,  i pokażę wam poprzednie podejście,  które do tej pory działa i na pewno będzie działać  i zobaczycie różnice  w nich. 

  

Pierwsze,  nowe podejście:

  

 na początek musimy zdefiniować sobie obiekt Volume,  który jest po prostu folderem który będziemy siedzieli z naszym kontenerem:

  

```bash

docker volume create my-api-vol

```

  

Następnie uruchomimy sobie nasze API podpinając sobie ten volume do kontenera:

  

```bash

docker run --mount type=volume,source=my-api-vol,target=/app/mnt -p 8080:8080 -it --entrypoint=/bin/bash --name=my-api --rm magglish/inzynier-ai-live-coding:4.0.0

```

  

To co robię to odpalam kontener w trybie interaktywnym z shellem,  po to żeby zobaczyć faktyczny wolnym jest.  ty zwróćcie uwagę na to że używamy argumentu --mount I następnie po spacji podajemy argumenty, type = volume, w source wskazujemy nasz volume  ktory stworzylismy my-api-vol a nastepnie target, czyli gdzie w kontenerze ten volume ma być dostępny.

  

Jesteśmy w kontenerze i zobaczmy strukture folderów

  

```bash

ls -la

```

  

Jak widzimy jest to taki folder Jak mnt,  w skrócie Mount,  czyli to jest ten folder który jest teraz  wspólny dla kontenera jak i dla komputera.  czyli to  co stworzy w tym folderze będzie dostępne w folderze u nas na komputerze. W takim razie stwórzmy sobie jakiś plik testowy.

  
  

```bash

echo "Test" > mnt/test_file.txt

```

  

Wyjdźmy z kontenera i teraz zobaczmy gdzie te dane są.

  

```bash

exit

```

  

Służy do tego `docker volume inspect` 

  

```bash

docker volume inspect my-api-vol

```

  

Jak widzicie ten folder z danymi jest określony w wartości Mountpoint I te dane są przywołane w var lib docker volumes. Spróbujmy sobie tam wejść. 

  

```bash

cd /var/lib/docker/volumes

```

  

Okazuje się że mamy permission denied, Nie możemy wejść do tego folderu.  Rozwiązaniem tego jest przejście na roota

  

```bash

sudo su -

```

  

potem

  

```bash

cd /var/lib/docker/volumes/my-api-vol/_data

```

  

i na końcu

  

```bash

cat test_file.txt

```

  

Dopiero w taki sposób mam dostęp do tego pliku. Co moim zdaniem jest bardzo niewygodne żeby dostać się do danych z którymi dzielimy się z kontenerem.  byłem w stanie stworzyć Volume na swoim użytkowniku `marcin`,  ale żeby  z tych danych móc potem skorzystać to Potrzebuję przejść na roota,  trochę wydaje mi się to bez sensu.  problem też jest taki że korzystając z komendy `docker volumes create` Po to żeby utworzyć nam taki obiekt  to niestety nie mamy możliwości określenia ścieżki w której ten folder  chcemy żeby został stworzony.  A może po prostu chcielibyśmy się podzielić z kontenerem danymi które są w repozytorium,  albo  albo chcemy żeby kontener wykonał jakąś operację No i te dane zapisał do naszego repozytorium.  to nie jest osiągalne Korzystając z tego rozwiązania. 

  

 teraz wam  pokażę Drugi sposób na to żeby podzielić się danymi z kontenerem.  znowu oprzemy się oczywiście o volu ale troszkę inny sposób.

  

Otworze nowy terminal i tam najpierw usune ten volume ktory stworzyliśmy, bo to nie będzie potrzebne:

  

```bash

docker volume rm my-api-vol

```

  

I teraz skorzystamy z innego argumentu, mianowicie argumentu o nazwie `--volume`!

  

```bash

docker run --volume=./mnt:/app/mnt -p 8080:8080 -it --entrypoint=/bin/bash --name=my-api --rm magglish/inzynier-ai-live-coding:4.0.0

```

  

Pierwsza ścieżka którą podałem na wolił to ścieżka na naszym komputerze lokalny  i zwróćcie uwagę że zacząłem  tutaj od kropki czyli od obecnego folderu w którym uruchamiamy kontener,  Czyli naszego repozytorium  i wskazuje folder który chce żeby był wspólny dla nas -  dla komputera i dla kontenera.  i to zaleta jest taka że jeżeli taki folder nie istnieje to po prostu zostanie on stworzony na naszym komputerze. Następnie oddajemy dwukropek  i podajemy ścieżkę w kontenerze gdzie ma być ten folder,  tutaj bardzo ważne jest to żeby wskazać od początku, czyli od roota, całą ścieżkę, ja mam `/app/mnt`  I następnie podajemy dalej  te argumenty które poznaliśmy wcześniej.

  

jesteśmy w kontenerze i zobaczymy czy jest ten folder

  

```bash

ls -la

```

  

 jak widać jest.  stwórzmy sobie jakiś plik w nim:

  

```bash

echo "Test" > mnt/test_file.txt

```

  

wyjdźmy z kontenera

  

```bash

exit

```

  

I sprawdźmy czy jest. Widzimy w strukturze mojego projektu w PyCharmie  pojawił się folder `mnt`,  i widzę że jest tam ten plik który stworzyliśmy. Ja teraz w drugim terminalu na moim komputerze stworzę sobie inny plik w tym folderze:

  

```bash

touch test_file_from_computer.txt

```

  

Ale niestety nie mogę. Dlaczego? Jak spojrzymy sobie na uprawnienia tego folderu

  

```bash

ls -la

```

  

To zobaczymy że folder są stworzone przez roota, ja jako marcin nie mam dostępu do pisania tam, a jedynie do wczytania i execute. widać to po informacji drwxr-xr-x`, że mamy `r-x`. 

  

Najlepsze rozwiązanie jest po prostu stworzyć sobie swój własny folder  który używane będzie do dzielenia się danymi z kontenerem więc ja w tym celu stworzę po prostu sobie `mnt2` 

  

```bash

mkdir mnt2

```

  

I teraz ja mam do niego uprawnienia wszystkie:

  

```bash

ls -la

```

  

W takim razie zatrzymamy nasz kontener ii podepniemy się do nowego folderu który teraz stworzyliśmy:

  

```bash

docker run --volume=./mnt2:/app/mnt -p 8080:8080 -it --entrypoint=/bin/bash --name=my-api --rm magglish/inzynier-ai-live-coding:4.0.0

```

  

Stwórzmy sobie pliczek

  

```bash

echo "Test" > mnt/test_file.txt

```

  

Zobaczmy w terminalu na kompie, że jest:

  

```bash

cd mnt2; ls -la

```

  

Mamy go.  stwórzmy sobie plik nasz I zobaczmy czy on będzie widoczny w kontenerze 

  

```bash

echo "costam" > test_file_from_computer.txt

```

  

Jak teraz wrócę do terminalu w którym  jestem w kontenerze  to zobaczymy że ten plik jest dostępny:

  

```bash

ls -la

```

  

Wróćmy do naszego komputera i zobaczymy że te pliki wciąż mają różne uprawnienia,  To wszystko zależy od tego czy Właśnie ja na komputerze ten plik stworzę czy to konto tego stworzy.  jeżeli będziemy chcieli coś z plikami z kontenera zrobić a to będzie musieli zmienić uprawianie do pliku ale to  przećwiczycie na ćwiczeniach,  czyli będzie powtórka trochę z tego co robiliście na zajęcia z linuxa. 

Jedna rzecz istotna jeszcze w przypadku volume - co jeżeli chcemy nadać uprawnienia tylko do odczytu, ale nie do modyfikacji:

```
docker run --volume=./mnt2:/app/mnt:ro -p 8080:8080 -it --entrypoint=/bin/bash --name=my-api --rm magglish/inzynier-ai-live-coding:4.0.0
```

Wtedy zwrócćie uwagę, że na końcu dodaję jeszcze dwukropek `:`

Okej To tyle jeśli chodzi o te wszystkie komendy które wam chciałem pokazać.  jak widzicie jest tak naprawdę dużo,  każda komenda ma jeszcze swoje własne argumenty.  oczywiście nie jesteśmy w stanie umówić wszystkiego i powiem szczerze że  wszystkiego też nie bęðziecie raczej używać. te przykłady które tutaj robiliśmy w trakcie lifecodingu były takie,  że tak powiem,  wyizolowane to znaczy  omawiałem je indywidualnie.  natomiast na ćwiczeniach  będę chciał żebyście zrealizowali pewnie scenariusz działania,  a ten scenariusz będzie wymagał od was zastosowaniu kilku komend na raz żeby coś uzyskać, Więc przecież wszystkie komendy które teraz omawiałem po prostu na konkretnych use-caseach, z którymi możecie na co dzień się spotkać. 

  

Są jeszcze trzy istotne argumenty które nie umówiłem w tym momencie a które są do karanie Natomiast chcę je zostawić na później,  na bardziej adekwatne tego moment tak żebyście po prostu mogli łatwiej to przyswoić -  mam  na myśli ten argument `-p` który za każdym razem by używany teraz. Są też argumenty związane z  ustawianiem zmiennych środowiskowych,  ale to mówimy sobie później,  w lepszym momencie. A teraz przejdziemy sobie do ćwiczeń.**

### niech zrzucą sobie całą historię do pliku bo sie im przyda