# Wrzucenie bazowych obrazów do swojego repozytorium
**

To w takim razie zaczynam od pierwszego kroku czyli wrócimy bazowe obrazy naszego repozytorium. 

  

 Naszymi repozytoriami będą repozytoria w Artifact Registry trzymane w Google Cloud. (WSTAW LINKA DO NIEGO)

  

Ale zanim Możecie je podejrzeć To prosiłbym o to żeby zainicjować połączenie z Google Cloudem i z projektem na którym będziemy pracować. Dzisiaj będziemy mieli pierwszy kontakt z chmurą,  a Znacznie większy będzie na następnym zdjęciu poświęconym Kubernetesowi,  bo na następnym zjeździe będziemy pracować na klastrze który dostępny będzie w chmurze więc tam tych interakcji z chmurą będzie więcej. 

  

Zacznijcie proszę o to żeby zainwestować połączenie poprzez

  

```bash

gcloud init

```


Następnie

```bash
gcloud auth application-default login
```
  

(ODPAL TO TEZ I POMÓZ IM PRZEJSC PRZEZ TUTORIAL)

  

Potem musimy jeszcze zrobić ostatni krok czyli zalogować się do krem do naszych repozytorów:

  

```bash

gcloud auth print-access-token | docker login -u oauth2accesstoken --password-stdin europe-central2-docker.pkg.dev

```

  

I w ten sposób będziemy mogli korzystać z naszych repozytoriów w chmurze.

  

W takim razie Przejdźmy sobie do  do początku coś spushowania bazowych obrazów do naszego repo.

  

Teraz naszych obrazów będzie sporo więc musimy to sobie jakoś zorganizować.

  

Chciałbym żebyście:

  

1. otworzyli folder `deploy`
    
2. następnie w nim `docker`
    
3. Tutaj 4 foldery: `python`, `api`, `postgres`, `redis`
    
4. Do folderu `api` przenieść naszego Dockerfile’a z głównej lokalizacji do tego folderu. Sprawdźcie czy nie zrobiły się takie ścieżki `../../../` - jeśli tak to je usuńcie.
    
5. W folderze `python` zrobimy sobie folder `base`
    
6. A w folderach `redis` oraz `postgres` zrobimy sobie folder `base` oraz `api`.
    

  

Okej to zaczniemy od Pythona. W folderze `base` stwórzmy sobie Dockerfile, a w nim tylko jedna linijka:

  

```dockerfile

FROM python:3.11-slim-bullseye

```

  

I to koniec naszego naszego Dockerfile. Teraz możecie sobie zastanawiać po co to jest.  generalnie można sobie to odpuścić,  i po prostu pobrać obraz pythonowy Korzystając z `docker pull`, Nadać mu  odpowiednią nazwę  z naszym repozytorium w chmurze,  zaraz zobaczycie jak na nazwa wygląda, zpushować to do repo, I koniec. Sposób też kontener pythonowy znajdzie się w naszym repozytorium.  Tylko pamiętajcie o tym że te kroki które zrobiłem Muszę zrobić ręcznie,  to też oczywiście może zautomatyzować,  ale Bardziej istotne jest to że one nie mają historii.  git w wersjonuje pliki,  Ale nie jakby komendy które wykonaliśmy,  więc generalnie chodzi o to że taki docker fajek który to widzicie który ma tylko i wyłącznie jedną komendę FROM, To nic innego jak po prostu  Zbuduj mi w swój własny kontener który jest tym samym co `python:3.11-slim-bullseye`. Ponieważ taką Tłumaczymy wcześniej FROM jest po prostu jak `git pull`,  Więc pobieramy wszystkie warstwy z `python:3.11-slim-bullseye`, I na tym budynku nasz kontener czyli nasz kontener będzie identycznie tym samym co ten `python:3.11-slim-bullseye`. Tylko zaleta trzymaję tego w Dockerfile jest taka że po prostu ten plik będzie w repozytorium trzymany  i on będzie wersjonowany u was w repo więc jeżeli zajdą jakieś zmiany w bazowych obrazach,  których definicja będzie trzymać właśnie w gicie,  no to będziecie mieli całą historię zmian. Będziecie w stanie trakować to wszystko co się dzieje w waszych obrazach bazowych. A jak poznacie Potem pipeline CICD,  to będzie ci w stanie po prostu sobie nawet cały proces aktualizacji obrazów bazowych zautomatyzować żeby tylko wprowadzać zmianę do tego do carfajla i ten obraz Jest budowany,  automatycznie tagowany co bedziemy robic na 4-tym zjeździe. 

  

Natomiast wracając do tego co mówiłem - z tym `python:3.11-slim-bullseye` Jest problem bo może cały czas się zmieniać. Natomiast w Dockerhubie jest IDik obrazu, który zawsze będzie się zmieniał wraz z kolejnymi zmianami - jest to DIGEST czyli unikalny idik dla konkretnego obrazu i przyjmue wartość SHA256. Więc to co my musimy zrobić to zamiast `python:3.11-slim-bullseye` użyć DIGESTa obrazu, na którym w tym momencie budujemy nasze rozwiązanie, które idzie na produkcję: 

  

Czyli:

  

(TO SIE MOŻE ZMIENIĆ JAK BĘDZIESZ KODZIŁ W TRAKCIE LIVE-CODINGU)

  

```dockerfile

FROM python@sha256:5f1f2daf3357113f0d33caaf92ba9bb1b573ef0682f8ebf555a04720e62d69d2

```

  

Teraz dzięki wskazaniu na sha256 obrazu, mamy gwarancję tego że za każdym razem będzie pullowany obraz ten konkretny. Niestety ten SHA w Dockerhubie Jest pokazane tylko włączę dla najnowszego obrazu.  i nie ma możliwości z poziomu Docker Huba żeby podejrzeć stare obrazy. Natomiast docker Hub buduje obrazy w sposób automatyczny  i Wszystko to co on buduje jest trzymane w repozytorium gitowym  i można znaleźć sh256 starych obrazów  w ich repozytorium Ale nie jest to wygodne.

  

Repo to [https://github.com/docker-library/repo-info/tree/master/repos](https://github.com/docker-library/repo-info/tree/master/repos) . Odnajdźmy w nim Pythona, potem folder `remote` i tutaj mamy markdowny mówiące o obecny wersjach Pythona, wejdźmy sobie do jednego z nich np. `python:3.11.6-slim-bullseye.md` i tutaj musimy odnaleźć konkretną wersję która nas interesuje. Następnie jak klikniemy sobie `history` w prawym górnym rogu no to mamy historie commitowania i jak wybierzemy sobie konkretny okres, ktory nas interesuje, to wchodzac w to dostaniemy zmiany, ktore zaszły i jednocześnie informacje o tym jakie były wcześniej SHA256. Powiem Wam szczerze jest to bardzo niewygodne, ale to jest jedyny sposób dojścia do tych obrazów. Docker Hub przechowuje te stare obrazy, Wcześniej był pomysł taki żeby wyrzucać wszystkie obrazy nieaktywne przez 6 miesięcy, Z tego pomysłu  na rzecz ide subskrypcji,  więc jeżeli Ktoś ma wersję tam Enterprise czy coś no to te kontener będą przechowywane przez nielimitowany czas.  tak jest W przypadku wszystkich obrazów które Tu widzicie w repozytorium  i to jest repozytorium z oficjalnymi obrazami Różnych języków aplikacji, baz danych i tak dalej Więc generalnie można założyć że  będzie dostępna cała historia  wszystkich zmian  w obrazach I poprzez SHA256  można ściągnąć konkretny obraz teraz interesuje.

  

To co ja wam polecam z własnego doświadczenia  to to że jak rozpoczynacie proces wdrażania waszych rozwiązań na produkcję,  albo  nawet nawet wcześniej - Wtedy kiedy realizujecie jakiś Proof of Concept, Wrzucacie nawet potem na jakiś system  to żeby zobaczyć Po prostu jak działa pierwsza literacja waszego rozwiązania.  to już po prostu od samego początku sprawdzić jakie są  wasz w tym momencie  wartości SHA256 Na docker hubie obrazów z których korzystacie  i po prostu użyć ich od razu w Dockerfile. Będziecie mieli od początku gwarancję tego że cały czas pracujecie na tym samym obrazie,  więc unikniecie wszelkich takich rzeczy typu w trakcie Proof of Concept działało, A nagle po kilku miesiącach coś nie działa, wy nic w repo nie zmienialiście, a wychodzi na to że właśnie ten obraz w Docker Hubie się zmienił. 

  

Dlatego to co my zrobimy to po prostu  będziemy korzystać od razu już z SHA256 Zarówno w bazowym obrazie pythonowym, redisowym jak i postgresowym.

  

Jeszcze się jest jedna zaleta takiego podejścia - Tak jak wam mówiłem ten plik docker File będzie trzymany u was w repozytorium,  czyli Wszelkie zmiany dokonywane w nim Będą widoczne w historii kombitowania.  Zatem Jeżeli ktoś będzie chciał zaktualizować bazowy obraz,  to bedzie musiał zmienić SHA256, Zatem zmiany będą widoczne i trakowane w gicie. Wy też jako deweloperzy będziecie widzieli że ktoś zmienia obraz bazowy,  więc może w Merge Requescie zapytacie dlaczego. Może spróbujecie  zbudować swoje własne API na przykład na tym konkretnym obrazie zobaczycie czy będzie działał,  zanim taka zmiana zostanie wprowadzona.  a jeżeli taka zmiana zostanie wprowadzona i coś się popsuje No to bardzo łatwo jest wrócić do poprzedniej wersji bo wszystko jest skomitowane więc macie całą historię  i  posługujecie się SHA obrazów Więc też jesteście w stanie z powrotem budować na poprzednim  obrazie który działał dobrze Co nie jest osiągalne w sytuacji gdybyście po prostu korzystali z pełnych nazw obrazów, czyli tego `python:3.11-slim-bullseye`, który mieliśmy wcześniej. 

  

Czyli robimy analogiczną rzecz w przypadku postgresa oraz redisa - tworzymy Dockerfile z samym FROM na digest.

  

Okej czyli mając definiowane te doker faile możemy sobie zbudować nasze bazowe obrazy  i wysłać je do naszego repozytorium. 

  

(PAMIĘTAJ ŻEBY WSKAZAĆ, ŻE MAJĄ ZMIENIĆ NAZWE REPO NA SWOJEGO UŻYTKOWNIKA)

```bash
docker push europe-central2-docker.pkg.dev/inzynier-ai-30-09-2023/mrybinski-live-coding-base/python:test
```

```bash 

docker build -f deploy/docker/python/base/Dockerfile -t europe-central2-docker.pkg.dev/<<NAZWA_PROJEKTU_NA_GCLOUD>>/mrybinski-live-coding-base/python:3.11-slim-bullseye-1.0.0 .

```

  

Mamy wiele Dockerfile więc tutaj skorzystamy z flagi `-f` w `docker build` żeby wskazać o konkretny Dockerfile o który nam chodzi. Teraz zaletą podejście naszego z własnym repozytorium jest to  że możemy teraz stworzyć własne tagi Czyli jeszcze dodatkowo to wersjonować  i mieć pewność że cała historia zmian jest u nas odpowiednio otagowana. I co to ja proponuję to żeby sobie stworzyć taki tag `python:3.11-slim-bullseye-1.0.0` Czyli na końcu dodaję sobie jeszcze `1.0.0`. No jeżeli w przyszłości będziemy zmieniać bazowy obraz, ale wciąż będzie bazował na `3.11-slim-bullseye`  to tymi wersjami na końcu będziemy mogli je odróżnić. Dajmy na to, że ktoś za kilka dni będzie chciał zaktualizować o najnowszy SHA256, więc wtedy taki obraz będzie miał taga już z `2.0.0` na końcu.

  

Zróbmy tak samo w przypadku postgresa:

  

```bash

docker build -f deploy/docker/postgres/base/Dockerfile -t europe-central2-d

ocker.pkg.dev/<<NAZWA_PROJEKTU_NA_GCLOUD>>/mrybinski-live-coding-base/postgres:15.4-1.0.0 .

```

  

oraz redisa:

  

```bash

docker build -f deploy/docker/postgres/base/Dockerfile -t europe-central2-docker.pkg.dev/<<NAZWA_PROJEKTU_NA_GCLOUD>>/mrybinski-live-coding-base/redis:7.2-1.0.0 .

```

  

I teraz wystarczy je zpushować do naszego repo:

  

python

  

```bash

docker push europe-central2-docker.pkg.dev/<<NAZWA_PROJEKTU_NA_GCLOUD>>/mrybinski-live-coding-base/python:3.11-slim-bullseye-1.0.0 .

```

  

postgres:

  

```bash

docker push europe-central2-docker.pkg.dev/<<NAZWA_PROJEKTU_NA_GCLOUD>>/mrybinski-live-coding-base/postgres:15.4-1.0.0 .

```

  

redis:

  

```bash

docker push europe-central2-docker.pkg.dev/<<NAZWA_PROJEKTU_NA_GCLOUD>>/mrybinski-live-coding-base/redis:7.2-1.0.0 .

```

  

I przejdźmy sobie do naszego repozytorium w Artifact Registry, żeby zobaczyć czy mamy nasze obrazy.

  

To co chciałbym żebyśmy zrobili to teraz zmodyfikowali Dockerfile z API aby korzystał z obrazu z naszego repozytorium:

  

```dockerfile

FROM europe-central2-docker.pkg.dev/NAZWA_PROJEKTU_NA_GCLOUD/mrybinski-live-coding-base/python:3.11-slim-bullseye-1.0.0

…

```

  

I zbudujmy sobie nasze API już korzystając z obrazu z naszego repozytorium:

  

```bash

docker build -f deploy/docker/api/Dockerfile -t europe-central2-docker.pkg.dev/<<NAZWA_PROJEKTU_NA_GCLOUD>>/mrybinski-live-coding-api/api:6.0.0

```

  

I zpushujmy sobie ten obraz do repo:

  

```bash

docker push europe-central2-docker.pkg.dev/<<NAZWA_PROJEKTU_NA_GCLOUD>>/mrybinski-live-coding-api/api:6.0.0

```

  

Ok widzimy, że mamy, więc w ten sposób mamy pierwszy krok spełniony.

  

Teraz przechodzimy do drugiego kroku.

  
  
  
  
  
  
**