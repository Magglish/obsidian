# Docker compose

**Okej w takim razie przechodzimy do następnego tematu Czyli do uruchamiania wielokontenerów na raz.  mamy Już zbudowany obraz naszym API,  obraz z naszym redisem  oraz  z naszym postgresem. Na poprzednim zjeździe prosiłem was zawsze o tym żeby uruchomić komendy `make redis` oraz `make postgres` zanim uruchomimy api korzystajac z komendy `make api`. 

  

Ale jest to niewygodne bo musimy ręcznie  odpalać każdy kontener po kolei.  w dodatku Musielibyśmy jeszcze zmienić ustawienia sieciowe żeby te kontener się widziały. Do uruchamiania wielu kontenerów jest  stworzone  dedykowana narzędzie nazywa się `docker-compose` Która jest bardzo często stosowana po prostu w trakcie developmentu czy testowania nasze rozwiązań,  natomiast nie jest używana produkcji. Dlaczego nie jest używana produkcji to powiem na końcu.  Dlatego  temat docker compose pokryjemy od tej strony funkcjonalnej To znaczy jak tego użyć w przypadku naszego API do modelu,  natomiast nie chcę wchodzić w szczegóły dokładnie  jak to działa  w środku,  to chciałbym wstawić do domu  żebyś sobie poczytali,  Natomiast  `docker-compose` nie jest jakimś Rocket Science Bo to jest po prostu nakładka  na komendy dockera które do tej pory poznawaliście, Stworzona po to żeby po prostu łatwiej można było uruchamiać wiele kontenerów na raz. W naszym przypadku jest to idealne rozwiązanie dlatego że tak dobrze pamiętacie nasze API korzysta z redisa jako cache oraz Z bazy danych postgres które zapisywaliśmy sobie wszelkie dane o requestach oraz response’ach które później służyć będą jako monitoring  naszego modelu. 

  

Jeżeli wrócimy sobie na chwileczkę do naszego `src/service/main.py` w którym było zdefiniowane  uruchomienie API, To zwróćcie uwagę że na ten moment Ja na razie za komentowałem interakcję z bazami danych  specjalnie po to żebyśmy mogli normalnie pracować na samym API.  Natomiast teraz skoro mamy już zbudowane obrazy z naszym redisem i postgresem no to po prostu wrócimy do tych Funkcjonalności które zakomentowałem. Teraz proszę was o to żebyśmy sobie od komentowali to co tutaj za komentowałem:

  

1. Czyli kod w naszej funkcji startup,
    
2. Kod w funkcji shutdown
    
3. Oraz kod w naszym endpoincie trzeba odkomentować i dodać identacje do IFa
    

  

CAŁY KOD

  

```python

@app.on_event("startup")

def startup():

    logging.info("Starting API and initializing all objects")

    app.state.model = CreditScoringModel(path=Path("models/classifier.pkl"))

  

    redis_connector = RedisConnector()

    app.state.redis_connector = redis_connector

    app.state.decision_redis_client = DecisionRedisClient(redis_connector)

    app.state.risk_category_redis_client = RiskCategoryRedisClient(redis_connector)

    app.state.probability_redis_client = ProbabilityRedisClient(redis_connector)

  

    postgres_connector = PostgresConnector()

    app.state.postgres_connector = postgres_connector

    app.state.decision_postgres_client = DecisionPostgresClient(postgres_connector)

    app.state.probability_postgres_client = ProbabilityPostgresClient(postgres_connector)

    app.state.risk_category_postgres_client = RiskCategoryPostgresClient(postgres_connector)

    logging.info("Successfully started API and initialized all objects")

  
  

@app.on_event("shutdown")

def shutdown():

    logging.info("Closing API.")

    app.state.redis_connector.close()

    app.state.postgres_connector.close()

    logging.info("Successfully closed API.")

  
  

@app.post("/decisions")

async def decisions(

    request: DecisionRequest,

    background_tasks: BackgroundTasks,

) -> DecisionResponse:

    logging.info(f"Received {request=}")

    response = app.state.decision_redis_client.read(request)

    if response is None:

        decision = app.state.model.predict_decision(request.to_dataframe())[0]

        response = DecisionResponse(decision=decision)

        background_tasks.add_task(

            func=write_to_redis,

            redis_client=app.state.decision_redis_client,

            request=request,

            response=response,

        )

  

    background_tasks.add_task(

        func=write_to_postgres,

        postgres_client=app.state.decision_postgres_client,

        request=request,

        response=response,

    )

    logging.info(f"Returning {response=}")

    return response

```

  

Okej to w takim razie po tych czynnościach możemy zdefiniować sobie plik który określa jak nasze kontenery muszą powstać.  Przejdźmy sobie do `deploy/docker`  i stwórzmy tam plik konfiguracyjny o nazwie `compose.yaml`.

  

Okej w takim razie zaczynamy od zdefiniowane sobie słowa kluczowego `services`

  

```yaml

services:

```

  

Który po prostu określa listę kontenerów który będzie uruchamiać.  i następnie Dodajmy sobie trzy wpisy:

  

```yaml

services: 

  redis:

  postgres:

  api:

```

  

Zaczniemy sobie od naszych baz danych  i tutaj wielkiej filozofi nie ma.

  

1.  na początku określimy sobie nasz obraz który ma być uruchomiony 
    
2. I potem nazwę naszego kontenera:
    

  

```yaml

  redis:

    image: europe-central2-docker.pkg.dev/<NAZWA_PROJEKTU_NA_GCLOUD>/mrybinski-live-coding-api/redis:1.0.0

    container_name: my-redis

  

```

  

Okej Ready załatwione tak samo możemy zrobić z naszym postgresem:

  

```yaml

  postgres:

    image: europe-central2-docker.pkg.dev/<NAZWA_PROJEKTU_NA_GCLOUD>/mrybinski-live-coding-api/postgres:1.0.0

    container_name: my-postgres

```

  

Natomiast w przypadku postgresa musimy dodać jeszcze jedną rzecz, Bo jak się okazuje żeby nasz kontener z podgrysem poprawnie wstał to on musi mieć określone hasło, Który Jak dobrze pamiętacie my ustawaliśmy na 12345. Ale hasło było podawane w momencie uruchamiania kontenera,  a nie w momencie jego budowy.  co jest okej dlatego że te hasło nigdzie nie zostało zapisane w żadnych plikach.  tutaj w tokarką Żeby ustawić tą zmianą środowiskową z hasłem możemy zrobić w ten sposób:

  

```yaml

    environment:

      POSTGRES_PASSWORD: 12345

```

  

No ale problem jest to że te hasło jest po prostu zapisane plaintextem i w pliku konfiguracyjnym. Sposoby żeby to obejść jest po prostu przekazanie  hasła jako zmiana środowiskowa tak to robiliśmy wcześniej  i docker compos fajnie się tutaj integruje z takim plikiem jak `.env` Czyli plik w którym najczęściej przechowuje się właśnie takie wrażliwe dane i bardzo ważne jest to żeby go nie komentować do repozytorów Ani do kontenerów.  to jest taki nasz wewnętrzny plik z naszym prywatnym środowiskiem.

  

Stwórzmy sobie taki plik jak `.env`

  

```toml

POSTGRES_PASSWORD=12345

POSTGRES_USER=monitoring

```

  

Damy sobie też `POSTGRES_USER`, który zaraz nam sie przyda.

  

I wrócimy sobie do naszego `compose.yaml` i zmienimy na:

  

```yaml

    environment:

      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}

      POSTGRES_USER: ${POSTGRES_USER}

```

  

Czyli te zmienne zostaną zaczytane z pliku z naszym środowiskiem w momencie uruchamiania kontenerów. 

  

Upewnijmy się, że w .dockerignore jest dodany wpis oraz w .gitignore aby to nie przeniknęło ani do kontenera ani do repozytorium.

  

**(DODAJ DO .DOCKERIGNORE i .GITIGNORE WPIS `.env`)**

  

Ok to kończy naszego postgresa.

  

Z API moglibyśmy zrobić podobnie ale nasza obecna wersja którą otrzymałem w repozytorium jest zaimplementowana z zakomentowanym kodem. Ale nic straconego dlatego że docker compose Nie tylko potrafi uruchomić  kilka kontenerów,  ale również daje nam możliwość zbudowania tych kontenerów od zera Jeśli jest taka potrzeba. I z tego skorzystamy w przypadku naszego API.

  
  
  

```yaml

  api:

    build:

      dockerfile: deploy/docker/api/Dockerfile

      context: ../..

    container_name: my-api

  

```

  

I tu musimy wskazać gdzie jest nasz docker File i kontekst,  czyli  baza do budowy kontenera.  wcześniej  podczas budowy obrazów wskazywaliśmy samą kropkę na końcu,  Czyli oznaczało to Zbuduj obraz Na podstawie tutaj tego naszego repozytorium.  w przypadku do gry compose domyślnie ten kontekst wskazuje na miejsce w którym jest nasz plik konfiguracyjny  czyli na `deploy/docker`. Żeby w takim razie działało nam wszystko poprawnie to musimy w tym kontekście wskazać całą nasz folder repozytorium,  czyli cofnąć się po prostu dwa foldery do tyłu. 

  

Okej czyli jakby bazę pliku konfiguracyjnego mamy, ale też nie jest koniec.

  

To co musimy zapewnić to to żeby przed uruchomieniem API uruchomiły się najpierw kontener z redisem i posgresem i w tym przypadku compos ma taką możliwość aby wskazać że nasze API zależy od poprzedniej kontenerów:

  

```yaml

    depends_on:

      redis:

        condition: service_started

      postgres:

        condition: service_started

```

  

Chcę widzieć ustawiłem sobie tutaj warunek logiczny że  że nasze kontenery z redisem oraz postgresem muszą wystartować zanim nasze API się zbuduję. Natomiast z własnego doświadczenia powiem wam że sam start  kontenera jeszcze nie oznacza w pełni to że jest on gotowy do użycia. W szczególności jeśli chodzi o kontenery związane z bazami danych dlatego że inicjalizacja  może być skomplikowana  i  musimy chwileczkę poczekać dosłownie kilka sekund zanim będziemy mogli się z niej korzystać. Jak sobie przejdziemy do naszego skryptu na `run_postgres.sh` lub `run_redis.sh` To zobaczycie że tam miałem taki kroczek związany z tym żeby sprawdzić po 5 sekundach czy nasza baza danych odpowiada. Generalnie bez praktycy jest to żeby zawsze definiować sobie  takie sprawdzenie czy dany serwis odpowiada czyli health check Dla każdego kontenera który używacie. Więc my w naszym przypadku tutaj w compose.yaml my też będziemy musieli takiego healthcheck zdefiniować. A ktoś z was może teraz zapytać czy my musimy też do naszego API definiować healthcheck. Tak jest to bardzo ważna rzecz ale dopiero poznacie ją na następnym zjeździe poświęconym Kubernetesowi,  bo Kubernetes będzie sprawdzał kiedy dany serwis gotowy A kiedy nie I  będziemy musieli zdefiniować odpowiednie healthchecki dla naszych serwisów. Ale na tym etapie jeszcze to pomijamy. 

  

Więc skorzystamy  sobie z tego co jest w tych skryptach basowych  i użyjemy tego po prostu w naszym `compose.yaml`.

  

Zaczniemy od Redisa:

```yaml

    healthcheck:

      test: ["CMD-SHELL", "redis-cli ping"]

      interval: 5s

      timeout: 3s

      retries: 2

```

  

1. czyli definiujemy sobie sobie komendę która musi być uruchomiona w Shellu  i w tym przypadku urzędu po prostu `redis-cli ping`
    
2. Następnie określamy Co jaki czas ma być ta komenda uruchomiona
    
3. Jak długo Ona czeka na to aż twoja odpowiedź
    
4. Jak długo ma próbować dopóki nie uzna że nasz kontener nie działa 
    

  

W przypadku postgresa analogicznie:

  

```yaml

    healthcheck:

      test: ["CMD-SHELL", "pg_isready --username=${POSTGRES_USER}"]

      interval: 5s

      timeout: 3s

      retries: 2

```

  

Tutaj właśnie skorzystamy z zmiennej środowiskowej `POSTGRES_USER`  żeby podać ją do funkcji `pg_isready`

  

I na końcu Musimy zmienić nasze warunek logiczny  z `service_started` na `service_healthy`

  

I teraz jeszcze ostatnia rzecz która została to określenie portów.  natomiast compose odpalimy troszeczkę inaczej,  każdemu z kontenerów podamy argument `network_mode: "host"` Co oznacza że skorzystamy z naszej sieci komputera na której uruchamiamy nasze kontenery - w efekcie czego porty do naszych kontenerów zostaną same otwarte, zgodnie z tym co jest w nich zdefiniowane w Dockerfile.

Przy naszym prostym use case, `host` wystarczy. Ale jeżeli macie bardziej zaawansowaną komunikację sieciową to wtedy ten temat trzeba zgłębić bardziej. Ale w naszym przykładzie API MLowe jest bardzo proste i ten tryb nam wystarczy.

**CAŁOŚĆ**

  

```yaml

services:

  redis:

    image: europe-central2-docker.pkg.dev/<NAZWA_PROJEKTU_NA_GCLOUD>/mrybinski-live-coding-api/redis:1.0.0

    container_name: my-redis

    network_mode: "host"

    healthcheck:

      test: ["CMD-SHELL", "redis-cli ping"]

      interval: 5s

      timeout: 3s

      retries: 2

  postgres:

    image: europe-central2-docker.pkg.dev/<NAZWA_PROJEKTU_NA_GCLOUD>/mrybinski-live-coding-api/postgres:1.0.0

    container_name: my-postgres

    network_mode: "host"

    healthcheck:

      test: ["CMD-SHELL", "pg_isready --username=${POSTGRES_USER}"]

      interval: 5s

      timeout: 3s

      retries: 2

    environment:

      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}

      POSTGRES_USER: ${POSTGRES_USER}

  api:

    build:

      dockerfile: deploy/docker/api/Dockerfile

      context: ../..

    container_name: my-api

    network_mode: "host"

    depends_on:

      redis:

        condition: service_healthy

      postgres:

        condition: service_healthy

```

  

Okej i to kończy naszą definicję docker compose. 

  

I żeby nam się łatwiej jestem pracowało to zdefiniujemy sobie jeszcze krok w `Makefile`  który pozwoli nam uruchomienie `docker compose` i wyłączenie go:

  

```makefile

api-compose-up:

docker compose --file=deploy/docker/compose.yaml --env-file=.env up --detach

  

api-compose-down:

docker compose --file=deploy/docker/compose.yaml --env-file=.env down;

  

api-compose: api-compose-down api-compose-up

```

  

Ci prosto wskazujemy gdzie jest nasz  plikulturacyjny z kompasem i  gdzie jest nasz plik ze środowiskiem.  następnie słówko `up` Żeby uruchomić kontenery  i na końcu flaga `--detach`  dobrze wam znana Czyli po prostu żeby to uruchomić w tle.  Sprawdźmy w takim razie jak to działa:

  

```bash

make api-compose-up

```

  

Mam informację o tym że nasze kontenery wystartowały, a api jest stworzone.  potem to się zmieniło że nasz postgres i Redis jest  Healthy,  a API jest po prostu started.  sprawdźmy czy faktycznie wszystko działa po prostu wysyłając requesta

  

 zobaczmy czy one działają

  

```bash

docker ps

```

  

jak widać tak:

  

```bash

make request

``` 

  

Jak widzimy udało się. Zobaczymy sobie jeszcze Logi naszego kontenera:

  

```bash

docker logs my-api

```

  

Jak widzicie logi wskazują na to,  że faktycznie połączenia z redisem i postgresem działają. 

  

Zanim przejdziemy dalej To musimy sobie zrobić jeszcze jedną rzecz,  jak  Widzicie  w compose budujemy obraz od początku.  ale finalnie chcemy go mieć u nas w repozytorium.

 więc Zbudujemy sobie nasze API  ponownie z nową wersją kodu,  czyli z kodem odblokowanym do interakcji z redisem i postgresem:

  

```bash

docker build -f deploy/docker/api/Dockerfile -t europe-central2-docker.pkg.dev/<NAZWA_PROJEKTU_NA_GCLOUD>/mrybinski-live-coding-api/api:7.0.0 .

```

  
i następnie push:

  

```bash

docker push europe-central2-docker.pkg.dev/<NAZWA_PROJEKTU_NA_GCLOUD>/mrybinski-live-coding-api/api:7.0.0

```

  

I zmodyfikujmy compose, żeby korzystał już z nowego obrazu z repozytorium

  

```yaml

  api:

    image: europe-central2-docker.pkg.dev/<NAZWA_PROJEKTU_NA_GCLOUD>/mrybinski-live-coding-api/api:7.0.0

    container_name: my-api

    network_mode: "host"

    depends_on:

      redis:

        condition: service_healthy

      postgres:

        condition: service_healthy

```

  

Ubijmy compose:

  

```bash

make api-compose-down

```

  

I następnie sprawdźmy czy wszystko działa:

  

```bash

make api-compose-up

```

  

następnie request:

  

```bash

make request

```

  

Zobaczmy logi

  

```bash

docker logs my-api

```

  

Widać, że działa.

  

Na początku wspomniałem o tym że docker compos nie jest używana produkcji.  i dlatego też nie będziemy jemu poświęcać bardzo dużo czasu Przede wszystkim właśnie z tego powodu a po drugie jest on na tyle prosty,  jak widzicie bo to jest tylko i wyłącznie nakładka na uruchamianie komend `docker`  w odpowiedniej kolejności.  tutaj nie ma żadnego Rocket Science.  jedyny temat którego nie poruszyłem to jest ten argument `network_mode` Czyli to jak te kontenery mają się ze sobą komunikować.  w tym przypadku że argumentu “host”  który oznacza żeby skorzystać z sieci komputera,  Ale może też definiować swoje własne sieci i to jest  użyteczne  w przypadku kiedy uruchamiamy wiele `docker compose` na jednym komputerze,  ale my takiego use-case nie mieliśmy i na codzień w pracy też nie będziecie mieli. Dlatego jako prac domową Chciałbym zostawić to żeby poczytać sobie właśnie o tych Network Mode I jak kontenery mogą się ze sobą komunikować.  natomiast przejdźmy teraz na najciekawszego,  dlaczego ten kod docker compose nie jest używany na produkcji i gdzie jest on w ogóle używane.  Dlaczego nie jest używane produkcji - powód jest bardzo prosty: Nie ma takiej funkcjonalności jakie mają inne narzędzia do zarządzania kontenerami - mam na myśli tutaj Kubernetesa głównie. Zresztą nawet w dokumentacji  docker compue znajdziecie takie zdanie [https://docs.docker.com/compose/features-uses/#single-host-deployments](https://docs.docker.com/compose/features-uses/#single-host-deployments) “Compose has traditionally been focused on development and testing workflows” Widzicie głównym zamierzeniem zawsze było to żeby używać go w trakcie developmentu czy w trakcie testów.  do produkcyjnego wdrażania jest dedykowana inna usługa nazywa się Docker Swarm, I swego czasu była ona dużo używana,  ale generalnie teraz używana jest rzadko,  a jeżeli jest używana to tylko i wyłącznie na środowiskach on-prem. Natomiast to co zostało zostało zaadoptowane  przez cały świat  i równiez  przez dostarczyli chmury  jest Kubernetes.  i na następnym  zjeździe powiem wam więcej o tym,  i powiem że wszystkim o tym że ten kubernetes nawet jeżeli korzystacie z usług o nazwie `serverless`,  rzeczywistości nie są one `serverless`  bo na jakim serwerze fizycznie one działają I praktycznie we wszystkich przypadkach te serwery na których te usługi są uruchamiane  są zarządzane przez Kubernetesa. Więc generalnie ten kubernetes będzie wszechobecny o tym powiem więcej na następnym zjeździe. 

Pytanie w takim razie, to do czego jest w takim razie docker-compose używany? Do developmentu czyli  do tego co teraz zrobimy,  zdefiniowaliśmy sobie `compose.yaml` Który uruchamia nam kilka kontenerów naraz  i jeszcze w odpowiedniej kolejności po to aby właśnie nasz Development,  rozwój  kolejnych iteracji modeli/API  był po prostu znacznie przyjemniejszy  i łatwiejszy.  definiuje całą logikę działania kontenerów w jednym pliku  po prostu uruchamiam je za pomocą innej komendy. Możemy to oczywiście samo uzyskać Korzystając bezpośrednio z komend `docker`-a Ale wymagałoby to on nas więcej pracy,  definiowania więcej kroków  i pewnie na końcu i tak byśmy skończyli na jakimś skrypcie baszowym który to w jakiś sposób automatyzuje.  więc żeby sobie tego zaoszczędzić po prostu korzystamy z docker-compose,  w którym jak widzicie Definiowanie takiej logiki uruchamiania kontenerów jest bardzo proste.

  

Natomiast `docker-compose` używany jest również podczas testów,  testów Mam na myśli testów integracyjnych.  Wróćmy sobie na chwileczkę do naszego kodu na testy integracyjne, dokładnie do `tests/integration/fixtures.py` To my w testach integracyjnych korzystaliśmy z techniki zwanej fake’ami albo stub’ami. Na przykład w przypadku redisa używaliśmy takiej biblioteki jak `fakeredis`  która po prostu uruchamia w tle sztucznego redisa dla nas.  podobnie było w przypadku `postgresa` -  tutaj akurat musieliśmy trochę więcej zdefiniować kodu, ale idea jest podobna. My tak to napisaliśmy i to jest jak najbardziej okej  natomiast można też wykorzystać do tego kontenery  i `docker-compose`  który po prostu uruchamiałby wszystkie kontenery potrzebne  wraz z naszym API  a  a w naszych testach integracyjnych po prostu odwołalibyśmy się do baz danych uruchomionych lokalnie  i na nich wykonywane były wszystkie operacje,  a potem po zakończeniu testów kontenery byłyby ubijane  i w ten sposób można by przeprowadzić testy integracyjne. My nie będziemy to nic tutaj zmieniać naszych testach bo teraz nie chcę żeby się poświęcają za dużo czasu.  natomiast na przykład przy swoim projekcie końcowym który będziecie robić, Albo też w przyszłości Jak będziecie pracować  i pisać testy dywersyjne to polecę wam rozważyć tą opcję  żeby Właśnie skorzystać z docker composa żeby se postawić bazy lokalnie za pomocą kontenerów  i wykorzystując te bazy po prostu uruchomić nasze testy integracyjne. 

  

I to w sumie skończ nasz temat tą grę composa,  która chce żebyście wykonali proste ćwiczenie  na naszym projekcie  związane z gpt2 czyli Chciałbym żebyście sami zdefiniowali plik konfiguracyjny pod `docker-compose` w to tamtym projekcie i zobaczyli to wszystko działa zanim pójdziemy dalej.**

## TERAZ POKAŻ IM JAK TESTY INTEGRACYJNE ZADZIAŁAJĄ Z TYM PODEJŚCIEM.