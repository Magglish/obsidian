# 27. Dlaczego rozmiar kontenera ma znaczenie

**

Okej w takim razie Moi drodzy Przechodzimy teraz do najważniejszego tematu który będziemy myślę wałkować do końca naszego zjazdu Czyli rozmiar kontenera.  o rozmiarze kontenera  i o sposobach jego redukcji której będziemy teraz się właśnie uczyć miałem już dwa wystąpienia na konferencjach - Data Science Summit oraz na DevAI, które też organizowane przez Data Science Summit - i generalnie jest to temat bardzo istotny. 

  

Więc to co będziemy robić teraz to poznawać techniki na zredukowanie rozmiaru kontenera.

 to jak na początku wspomniałem wszelkie best practises dotyczące dockera dotyczą dwóch aspektów:

  

1. Po pierwsze to właśnie ułożenie warstw,  czyli wszelkich instrukcji w Dockerfile w taki sposób żeby ten  obraz budował się jak najszybciej.  o tym temacie mówiliśmy wcześniej,  ale nasz Dockerfile był na tyle prosty że to nie było takie trudne I generalnie ułożenie warstw jest tematem dosyć prostym. Po prostu musimy chwilę się zastanowić w jakiej kolejności mogą następować zmiany w naszym obrazie.  później też będziecie mieli takie ćwiczenie które dam wam przykładowy Dockerfile w którym będzie totalny chaos i będę was prosił o to żeby ułożyć te warstwy w takiej kolejności aby ten kontener budował się jak najszybciej, A dodatkowo oprócz tego będę  wymagał od was żebyście  zastosowali Wszystkie techniki i redukujące jego rozmiar. 
    
2. I po drugie bez practises wokół tego aby kontener był jak najmniejszy.
    

  

Spójrzmy sobie w takim razie na początku jak duży jest nasz kontener:

  

```bash

docker images

```

  

I w ten sposób możemy se podejrzeć o jakich rozmiarach mówimy.  teraz Zobaczcie te kontenery mają po kilkaset MB.  Czy to jest dużo czy mało.  generalnie można mieć wrażenie że to jest malutko tak no bo nasze dyski mają po kilka kilkanaście terabajtów,  albo nawet możemy pójść w petabajty. Więc jakby nie ma problemu z ich przechowywaniem żadnego.  tak samo z wysłania tego kontenerów,  to wszystko zależy od sieci w jakiej pracujemy. Generalnie w zależności od tego gdzie pracujecie No to sieć może być wolniejsza bądź szybsza,  Jeśli chodzi o sieć Tutaj możemy zauważyć pewne problemy to znaczy  może nas boleć to że coś się dłużej pobiera bo ściąga.  Tak widzieliście na przykładzie puszowania obrazów do dockerhaba albo do naszego Artifact Registry na chmurze, Że jakiś czas trzeba poczekać,  a są to tylko i wyłącznie kontenery które mają kilkaset MB, Więc ten czas oczekiwania przy większy kontenerach naprawdę  będzie Znacznie większy.  więc jeśli  jeśli chodzi o aspekty sieciowe pobierania wysyłania to tu możemy mieć zarzuty że faktycznie to może długo trwać i chcielibyśmy zredukować rozmiar tego obrazu po to aby te operacje sieciowe wykonywały się znaczy szybciej.  natomiast jeszcze inny aspekt który musicie wiedzieć -  aspekt finansowy i on odgrywa najważniejszą rolę w przypadku redukcji rozmiarów kontenerów.  musi sobie zdawać sprawę z tego że w momencie kiedy korzystacie z chmury to tak naprawdę płacicie za wszystko.  teraz co zaraz wszystko -  w kontekście kontenerów płacicie za storage czyli za każdy  Megabajt  jaki wymagacie żeby po prostu dane kontener był trzymany u nich w chmurze.   jak sobie spojrzymy na ceny na przykład Google to tam koszt za 1 GB to jest zaledwie 10 centów za miesiąc, czyli jakieś 40 groszy. Co to jest 40 groszy można zapytać? Na małej skali,  na przykład gdybyście pracowali tylko i wyłącznie sami na Google cloudzie to to są tak niskie koszty że można sobie to pominąć,  machnąć na to ręką. Kiedy Pracujecie w startupie kilku czy kilkunastoosobowym,  to tam już te koszty będą znacznie większe wiadomo bo więcej osób buduje te kontenery,  więcej jest rzeczy kombinowanych do repozytorium,   zapewne są po definiowane pipeliney CICD które budują kontenery z każdym komitem. Generalnie tam koszt może znacznie wzrosnąć ale wciąż to nie będą aż tak straszne kwoty.  natomiast Problem pojawia się wtedy kiedy pracujecie naprawdę dużej skali,  dużej firmie  i tych kontenerów jest tworzonych bardzo bardzo dużo,  bardzo bardzo dużo jest przy ich przechowywanych  i w takiej sytuacji Każdy taki Cent Jaki płacicie za przechowywanie kontenerów ma naprawdę ogromne znaczenie. Ale wtorek jest jednym kosztem,  który jest  znacznie mniejszy przy drugim koszcie.

  

A drugim kosztem jest transfer. Czyli pobranie kontenera z repozytorium,  i ty mówimy o kontenerze pobieranym na przykład do nas lokalnie na komputer,  tak jak teraz to robiliśmy -  każde uruchomienie  kontenera może się wiązać z jego pobraniem.  w naszym przypadku pobraliśmy tylko  obraz raz,  Potem jest zapisywane na naszym dysku Więc jeżeli stworzymy nasz kontener no to skorzystamy z obrazu który już jest na naszym komputerze,  nie pobieramy go znowu z repozytorium. Ale  tak jest w przypadku naszego komputera stacjonarnego.  dopóki nie wyczyścimy obrazów korzystajac np. z `docker system prune` co używaliśmy wcześniej No to za każdym razem te kontenery będą uruchamiane Korzystając z obrazów dostępnych lokalnie na komputerze.  ale w przypadku wdrażania rozwiązań na chmurę  to nie zawsze będzie prawda.   to znaczy kontenery są bardzo często pobierane  z repozytorium  do tego aby je uruchomić w usłudze w której finalnie zdeployowaliśmy nasz kontener. Tak jest w przypadku klasów Kubernetesowych, czy w przypadku różnych usług serverless które możecie skorzystać: Vertex AI, Cloud Run na GCP, Sagemaker na AWS itd. I na przykład w przypadku gcp  z to 10 za miesiąc za 1 GB. Z kolei transfer kosztuje tylko i wyłącznie 2 centy za 1 GB pobranych danych. Więc wystarczy pobrać kontener sześć razy aby już przekroczyć Koszt storage’y miesięcznego danego kontenera. I 6 razy powiem szczerze to jest bardzo mało.  W przypadku systemu produkcyjnych bardzo często spotkacie się z takim czymś co nazywa się auto skalowaniem my to będziemy definiować na następnym zjeździe poświęconym Kubernetesowi. Krótko mówiąc w autoskalowaniu Chodzi o to aby dostosować liczbę instancji waszego API do ruchu jaki musi obsłużyć. Jest to bardzo fajna rozwiązanie w momencie kiedy po prostu przed zależności od pory dnia na wasze API jest w różny sposób odpytywane,  w W nocy macie znacznie mieli questów,  w ciągu dnia bardzo dużo, Więc taki autoscaler Po prostu w nocy zmniejszy liczbę instancji,  a w ciągu dnia zwiększy liczbę instancji API.  pozwala wam to przede wszystkim na dostosowanie ilości instalacji tak żeby ten ruch obsłużyć,  no  Jest to bardzo fajne pod względem pilnowania kosztów waszej infrastruktury Bo w momencie kiedy do serwisów będzie kierowano małą requestów to po prostu liczba instancji jest w stanie zmniejszona,  więc mniej bedziecie placic za wykorzystanie zasobów CPU i pamięci RAM. Natomiast  przy stosowaniu auto skalowania często  zobaczy się wzrost kosztu związanych z transferem z repozytorów z kontenerami.  dlaczego?  Dlatego że bardzo często jest tak  że dostawienie nowej instancji w naszym API  wiąże się z pobraniem kontenera z repozytorium.  czyli naliczy nam się koszt związany z transferem danych,  czyli z pobraniem kontenera.  zatem Im większych rozmiar tego kontenera tym więcej będziecie płacić za każdego pobranie. Do tego jeszcze fakt że im bardziej zmienne jest wasze środowisko pod względem wykorzystania waszych serwisów, Tym ten autoskaler musi bardziej intensywnie pracować Więc tych instancji  będzie się pojawiać i znikać bardzo dużo  i bardzo często  i to też się  przekłada na koszty transferu. Więc generalnie z własnego doświadczenia koszt transferu jest największy jeśli chodzi o kontenery.  i każdy Megabajt zaoszczędzone na kontenerach Da wam bardzo dużo oszczędności w pieniądzach w przypadku właśnie transferu.

  

 jest jeszcze inny aspekt też związany bezpośrednio z auto skalowaniem,  mianowicie czas pobrania tego kontenera. Już to widzieliście na przykładzie ćwiczeń i live coding mojego,  że im większy rozmiar kontenera tym dłużej go uploadujemy do repozytorium  i dłużej go też pobieramy. I tak wspomniałem przy auto skalowaniu,  bardzo często będzie tak że ten kontener będzie pobierany z repozytorium czyli raz że naliczone są pieniądze,  a dwa  że jest jakiś czas oczekiwania na to aż ta nowa instalacja się pojawi. i w przypadku czas oczekiwania nową instancję bardzo dużo rolę odgrywa czas  pobrania kontenera. Jeżeli Dostawienie instancji brzytwało naprawdę bardzo długo to w zależności oczywiście od usługi A z jakiej korzystacie  finalnie na chmurze,  ale Skupmy się na na klastrze Kubernetesowym, Może dojść do takiej sytuacji że autoskaler Będzie dostawał za dużo instancji niż  finalnie by się potrzebowali  dlatego Że cały czas Nie dostaję odpowiedzi od nowa postawionej instancji  w jakimś określonym czasie, Więc dostawia kolejną **TO JESZCZE POTWIERDŹ W DOKUMENTACJI KUBERNETESA CZY TAK JEST**. W takiej sytuacji  zobaczycie  większe koszty wniosek który No bo powstaje za dużo instancji niż jest to wymagane,  potem auto skaner oczywiście je usunie  bo zobaczy że już ich nie potrzebuje Ale to generalnie generuje mu dodatkową pracę niepotrzebną.  Natomiast z poziomu widzenia klienta  w przypadku zbyt długiego oczekiwania na odpowiedź z API  po prostu mogą być rzucane timeouty, Czyli połączenie jest przerywane w momencie kiedy na przykład trwało za długo. I to trwanie za długo może się właśnie wiązać z tym że jest za mało instalacji żeby obsłużyć tak wzmożony ruch,  robi się kolejka request do naszych serwisów i w końcu pewne requesty będą przerywane bo trwają w tej kolejce za długo. Ja te wszystkie rzeczy będę jeszcze dokładnie umawiał na następnym zjeździe  poświęconym Kubernetesowi,  Ale już teraz chciałem to nakreślić tak żebyście zrozumieli Dlaczego rozmiar jest ważny. I  ten problem można przede wszystkim spróbować rozwiązać właśnie poprzez redukcję rozmiarów kontenerów,  bo im  mniej  tym pobierzemy go z repozytorium I tym szybciej zostanie dostawiona nowa instancja.

  

No to naprawdę jak widzicie rozmiar ma znaczenie -  w kontekście pieniędzy jakie zapłacicie za transfer i za transfer, jak i w przypadku autoskalowania, Czyli dostosowania ilości instancji waszego API do ruchu jaki teraz jest na waszym serwisie.

  

Teraz będziemy sobie przechodzić po kolei podoker File i powoli implementować pewne rzeczy które te rozmiary mogą nam zmniejszyć.

**