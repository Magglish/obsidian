# Własne obrazy

**Wiedza o ENTRYPOINT i CMD zaraz nam się przyda, bo będziemy definiować swoje własne obrazy z pythonem, redisem i postgresem.

  

Słuchajcie jak widzicie do tej pory cały czas pracujemy na Docker Hubie, Czyli w naszym doker falu mamy zdefiniowanego Pythona w wersji 3.11-slim-bullseye I domyślnie  taki obraz jest pobierany z Docker Huba. Tak samo używaliśmy na  poprzednim zjeździe takich komend jak `make redis` oraz `make postgres` - Zaraz dokładnie przejdziemy co te kroki robią - Natomiast mówiąc po kurtce One również pobierały kontener z dockerhaba z redisem lub postgresem, Troszkę je modyfikowały pod nasz Case, i mogli się potem z nich korzystać w API.  Czyli generalnie używałem kontenerów po to żeby postawić sobie lokalną baze redis oraz postgres i móc na niej pracować.

  

Teraz może was zaskoczę tym co powiem ale generalnie dobrym practice jest to żeby nie  nie opierać się w pełni na Docker Hubie podczas wdrażania na systemy produkcyjne. Są  dwie istotne wady korzystania z dockerhaba o których musicie wiedzieć, i o których mało co ktoś mówi albo nawet jak przeglądałem różne tutoriale mało kto na to zwraca uwagę, A na tym można się ostro przejechać na produkcji w szczególności jeśli wasze rozwiązania działają na większą skalę. Teraz o co chodzi.

  

1. Po pierwsze docker Hub ma limity na pobranie obrazów [https://docs.docker.com/docker-hub/download-rate-limit/](https://docs.docker.com/docker-hub/download-rate-limit/) . Jeżeli spojrzymy sobie na limity które wynoszą tutaj 100 lub 200, To pytanie jakie możemy zadać Czy to jest dużo czy mało, to wszystko zależy od tego w jakiej skali pracujecie. Teraz generalnie możesz sobie zapytać kiedy my sięgniemy limitów.  No bo generalnie jak my sobie stworzymy teraz kontener z API,  No to on będzie pobierany  z naszego dedykowanego repozytorium w chmurze. Kontenery z waszymi API nie będą oczywiście trzymane w dockerhabe tylko będą tego dedykowane repozytoria na przykład w chmurze. No i w przypadku naszych repozytorów w chmurze No limitów nie ma więc z tym nie będzie problemu.  więc  Kiedy można trafić na limit:
    

1. w dwóch przypadkach najczęściej to obserwuje -  nie definiowaliśmy jeszcze pipeline CICD,   na to jest poświęcony cały 4-ty zjazd. Natomiast Spojlerując troszeczkę czym będziemy się czym będziemy zajmować się otwartym zjeździe  to Wyobraźcie sobie że z każdym waszym komitem do repozytorium budowany jest kontener od zera.  z każdym komitem,  po to aby uruchomić cały pipeline CICD. A tych komitów może być dziesiątki jak nie setki biorąc pod uwagę to Jak dużo deweloperów może pracować nad danym repozytorium.  więc pipeline CICD jest bardzo łatwo dosięgnąć limitów Dcoker Huba.
    
2. Drugi Case jaki możemy trafić na limit to jest wtedy kiedy nasze rozwiązania na produkcji używają nie customowych obrazów, A obrazów które są już do Docker Hubie  no i ten obraz docker hubie jest w zupełności wystarczający Żeby wykonać jakąś operację.  no i w takiej sytuacji też można bardzo łatwo sięgnąć limitów.  Przykładem tego  Mogło być dedykowane obrazy kontenerów które mają w sobie zainstalowane oprogramowanie do interakcji z Google,  z AWSem, czy z Azure Więc można z nich skorzystać  Bo one już mają wszystko w słabiej poinstalowane  i jedyne co robimy  to definiujemy argumenty z jakimi ma się kontener uruchomić.  to się używa często w takich bardzo prostych zastosowaniach i tam też można sięgnąc limitów.
    

No i co się stanie jeśli się nie dzieli mitów,  no nic, musicie czekać. Może to nie jest jakby jeszcze tragedia tak no bo po prostu poczekacie i wtedy mógł się pobrać kontener,  Ale co jeżeli ten limit trafi naprawdę w takim krytycznym momencie wydarzenia nowej wersji na produkcję,  i ani nie wdrożycie nowej wersji, ani nie zrollbackujecie do poprzedniej Bo są limity i może być duży problem. Więc ja zawsze zalecam Niezależnie od tego W jakiej skali pracujecie  to zawsze warto już myśleć o pewnych problemach  które na pewno wystąpią jak tylko będzie większa skala i po prostu już na wczesnym  zabezpieczyć się przedtem.  a zabezpieczenie przed tym jest bardzo proste,  co zaraz będziemy robić.

  

Natomiast drugi problem który obserwuje to to jak ludzie pushują obrazy do Docker Huba. Wejdźmy sobie jeszcze na Dockerhuba i na obraz pythona, który używamy. WEJDŹ NA DOCKERHUB I WYSZUKAJ

  

Czy mogę sobie nasz obraz  i  tutaj Jest taka informacja na Docker Hubie  kiedy został ten obraz spushowany. Jak widzicie został spushowany niedawno. Więc wy możecie mieć zapisane w Dockerfile że pobieracie obraz `python:3.11-slim-bullseye` I możecie mieć wrażenie że cały czas wybrać się ten sam obraz. tak nie jest. Każdego dnia Ten obraz jest inny, Więc nie macie gwarancji tego że cały czas wasze środowisko, czyli Wasz kontener z API który trafi na produkcję, będzie faktycznie miał cały czas te same środowisko. Jakie jest rozwiązanie tego problemu? Dlaczego te są takie zmiany,  dlatego że  na obraz Python 3.11. Ale po tej 11-stce, zgodnie z wersjonowaniem semantycznym, Jest jeszcze trzecia cyferka oznaczająca patcha.  Więc  ten obraz Python 3.11 oznacza żeby pobrać obraz Python 311 z najnowszym patchem. Zatem można pomyślećpomyśleć żeby skorzystać z innego obrazu który jest bardziej dokładny, to może skorzystajmy z obrazu, który ma też konkretną wersję patcha np. 3.11.2: (WEJDŹ NA DOCKERHUB I WYSZUKAJ) Widzimy że data last pushed Jest naprawdę odległa Więc można powiedzieć że okej ten kontener już się nie będzie zmieniał.  ale pamiętajcie o tym że to jest jakby dobra Wola osoby która ten konto nie stworzyła.  w takich Oficjalny repozytorów jak Python,  czy redis czy postgres  Tam są falowane dobre praktyki  i generalnie Tutaj raczej bym się nie spodziewał tego że ktoś zaktualizuje obraz z Pythona 3.11.2 Ale nie macie gwarancji co do wszystkich obrazów w dockerhabe że każda osoba będzie kierowała się semantycznym wersjonowaniem wszystkich obrazów które pushuje. Bo może korzystacie z jakiegoś niszowego obrazu który ktoś udostępnił,  chcecie z tego skorzystać, A za jakiś czas to osoba spuszowała Nowy obraz pod tym samym Tagiem  i teraz wasze obrazy  nie działają albo inaczej  funkcjonują. Idać dalej - a co jeżeli ten obraz nagle zniknie z Docker Hub i co wtedy jak sobie z tym poradzimy. Okej a jeszcze jest jedna kwestia to taka że chcemy pracować nad najnowszej wersji Pythona,  Ale wiemy że ona się cały czas zmienia.  No bo nawet jeżeli najnowsza wersja Pythona teraz jest 3.11.6 I nawet jeżeli w docker fajnie wskażemy tą wersję konkretną, to zobaczcie że ona cały czas tutaj się zmienia. Generalnie my podczas wdrażania do systemów na produkcję musimy się przed takimi rzeczami zabezpieczyć koniecznie dlatego że no wasze modele będą odpowiedzialne za kluczowe procesy z których Wasza firma będzie po prostu czerpać zyski.

  

Więc generalnie rozwiązanie tych problemów jest dosyć proste i myślę że wam już przychodzić do głowy Co to by było.  warto jest mieć swoje repozytorium w którym przechowujecie obrazy z waszym API ale również wszelkie inne obrazy bazowe na których  budujecie swoje dalsze obrazy.  to rozwiązuje problemy z limitami bo na chmurze na wasz reporterach limitów nie będzie.  to też rozwiąże problemy z konkretną wersją obrazu  oraz będziecie mieli backup tego obrazu u siebie  w repozytorium,  więc nawet Jeżeli ten obraz by zniknął z dockerhaba No to u was będzie,  nawet jeżeli Obraz w dekabie cały czas się zmienia to w waszym repozytorium będziecie mieli tą wersję na której pracujecie,  I dodatkowo będziecie ją sobie wersjonować  tak jak chcecie.

  

Więc to co my będziemy robić teraz to tak naprawdę Przeniesiemy kontenery których używamy do budowy - Python, redis i postgres - Na nasze dedykowana repozytoria w chmurze. W przypadku redisy i postgresa my dodatkowo jeszcze zmodyfikujemy je pod nasz case. 

  

Więc jak teraz będzie wyglądała nasza konfiguracja:

  

(PRZYGOTUJ SLAJD Z RYSUNKIEM POD TO KONIECZNIE)

  

1. Na początku mamy nasze obrazy Python, Redis i Postgres dostępne w Dockerhubie.
    
2. Aby mieć pewność nie dosięgnięcia limitów oraz pewność stałego niezmienialnego środowiska, Na początku musimy pobrać te obrazy do naszego repo.  i pobierzemy te obrazy w troszeczkę inny sposób. 
    
3. Następnie przeanalizujemy sobie zawartość skryptów `make redis` oraz `make postgres` I stworzymy swoje własne kontenery  z redisem i postgresem które są specyficzne dla naszego API - W trakcie ich tworzenia Wyjaśnię dlaczego tak   warto zrobić. 
    
4. No i na końcu cały proces budowy naszego kontenera z API oprzemy na naszych kontenerach które są w naszym repozytorium.
    
5. A w dalszych etapach naszych zjazdów będziemy już korzystać tylko z tego co jest nasza repozytorium
    

  

Jeszcze bardzo ważna rzecz,  Przeważnie jest tak że te kontenery bazowe które tutaj widzicie one są trzymane w zupełnie oddzielnym repozytorium  dedykowanym pod takie kontenery,  No bo one są generalnie używane później we wszystkich innych projektach  z którymi pracujecie więc dobrze jest sobie zrobię takie dedykowane repozytorium  przez które zarządzacie tymi wersjami basowymi. A potem w odziele repozytoriach są konkretne implementacje konkretnych rzeczy i one sobie korzystają z tych kontenerobazowych.   natomiast my na naszych zajęciach Będziemy trzymać wszystko w jednym repo  bo Nie chcę żebyście teraz się przeklikiwali między repozytoria i raz tutaj raz tam mam obawy że się po prostu wszyscy pogubimy  więc zakładamy że po prostu  każda swoje własne potrzeby będzie robił  swoje obrazy z pythonem, redisem i postgresem I po prostu będziemy trzymać to w jednym rapo żeby łatwiej po prostu na tym potem pracować i na tym zjeździ następnym. Natomiast po prostu w codziennej pracy  te  te bazowe obrazy na Kontenery będą po prostu w oddzielnym repozytorium, żeby łatwiej tym zarządzać.**