# Cacheowanie

1. Zakończyliśmy część podstawową, fundamentalną. Zaczynamy przechodzić do kwestii troche bardziej zaawansowanych, określiłbym je jako średnio zaawansowane. Zaczniemy sobie od bardzo ważnego tematu, jak cacheowanie.
2. Ale zanim to zaczniemy to najważniejsza rzecz moim zdaniem: implementując API, moim zdaniem powinny przyświęcać Wam dwa główne cele:
	1. proste: ogólnie API MLowe nie jest aż tak duże jak API np. serwisu typu CRUD bo obecnie mamy zdefiniowane w sumie 3 endpointy, na tylko 3 metody typu POST i to będzie w tym przypadku maksimum, więcej nie będzie. Natomiast niezależnie od ilości endpointów i reprezentacji jakie zdefiniujecie to moim zdaniem, z własnego doświadczenia, za prostotę API odpowiada w większości jakość dokumentacji. Możemy też API skomplikować samą implementacją użycia końcowek jak np. pokazywałem Wam ten sposób z jedną reprezentacją `predictions`, dla której odpowiedzi sterowaliśmy parametrami w `query`. Jeżeli ktoś jednak zdecyduje się na takie podejście, to aby było to proste w korzystaniu, ważna jest bardzo dobra, najlepiej łopatologiczna dokumentacja. Jeżeli dokumentacja będzie jasna i przejrzysta i nie będziemy mieli wątpliwości jak skorzystać z API, to API dla nas będzie po prostu proste i przyjemne. Fajne w FastAPI jest to, że dokumentacje generuje na podstawie naszego kodu. Będziemy jeszcze do niej wracać i modyfikować je ręcznie aby jeszcze lepiej je usprawnić, ale to później.
	2. szybkie: Z drugim aspektem, czyli szybkość, jest zdecydowanie trudniej. To już wymaga od nas dużej ilości pracy z naszym własnym kodem i zrozumienia jak on działa: ale też takich pojęć jak złożoność obliczeniowa - pojęcie najważniejsze w kontekście pisania szybkiego kodu, czy też wektoryzacja działań, w szczególności kiedy operujemy na wektorach. Są też, ja je określam jako "przyspieszacze kodu" czyli kompilatory JIT (Just In Time) jak np. [numba](https://numba.pydata.org/). My w tym zjeździe nie będziemy tych aspektów poruszać, bo to już bardziej tematyka zaawansowana, dotycząca zajęć związanych z optymalizacją kodu. Natomiast My w API możemy przyśpieszyć jego działanie, nie zmieniając kodu. Po prostu dołączając do API możliwość cacheowania.
3. O Cacheowanie wspomniałem przy okazji omawiania założeń architektury REST. Dzisiaj zaimplementujemy to sobie w naszym API.
4. Czym jest cachoewanie? No myślę, że każdy z Was się z tym terminem spotkań, tłumacząc na polski - trzymanie w pamięci. Za każdym razem kiedy przeglądarcie internet, w waszych przeglądarkach są cachoewane odpowiedzi/response zwracane przez konkretne strony.
5. Dlaczego warto cacheować? Dlatego, że to znacznie przyśpiesza, dlatego, że łatwiej jest po prostu sięgnąc do pamięci podręcznej i odczytać coś co już jest tam przechowywane niż ponownie renderować stronę i jej zawartość. (Pokaż na przykładzie np. stackoverflow.com - z cachem i bez cachea. Jest spadek z 500 ms na jakieś 300 ms.) Ktoś może powiedzieć, że co to te 500 ms i 300 ms. Nie odczuwalne dla użytkownika. Tak to prawda, dla nas to jest wręcz niezauważalne. Ale dla systemów, na których wdrożony jest stackoverflow z których korzysta setki tysięcy ludzi codziennie każda zaoszczędzona milisekunda to mniejsze obciążenie dla systemu. W dodatku schemat cachoewania może być zaimplementowany w troche innej warstwie systemu, tzn. requesty nawet mogą nie dochodzić bezpośrednio do API, a są one obsługiwany w warstwie przed w tak zwanym proxy, o którym wspominałem. O tym gdzie najlepiej cachoewanie zaimplementować powiem później.