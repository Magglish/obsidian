# Testy integracyjne

**ABY WYKONAĆ TE ĆWICZENIA TRZEBA DOINSTALOWAĆ BIBLIOTEKI:**
```bash
sudo apt-get install postgresql postgresql-common libpq-dev
```

Przechodzimy sobie teraz do testów integracyjnych które określone są również jako testy end-2-end. Zapewne domyślacie się o co może chodzić w testach integracyjnych, ale zacznijmy od tego żeby sobie to wyjaśnić. Jak sama nazwa testu wskazuje będziemy sprawdzać pewną integrację albo nawet interakcje. Generalnie w testach integracyjnych chodzi o to aby sprawdzić to jak nasze API zachowuje się podczas korzystania z innych serwisów z których korzysta - w naszym przypadku są to serwisy związane z bazami danych Redis oraz Postgres. Czyli Innymi słowy chcemy sprawdzić czy API poprawnie zapisuje wczytuje dane z tych dwóch baz danych których używamy. Ten Case nasz będzie dosyć prosty jak na testy integracyjny. ale w waszych API która będzie implementować może dojść inna usługa nie-bazodanowa. Ja na przykład w pracy dodatkowo zabezpieczam dokumentacja naszego API w taki sposób że można ją wyświetlić tylko po zalogowaniu się i korzystam z naszych wewnętrznych serwisów odpowiedzialnych za autoryzację. W takiej sytuacji pisanie testów integracyjnych jest znacznie trudniejsze.  

W zależności od tego z jakich serwisów dodatkowe będzie wasza API korzystać będzie zależeć trudność pisania testów integracyjnych i w zależności od tej trudności będzie musieli decydować o wyborze konkretnych metod testowania, tak żeby te testy integracyjne przyniosły wam jakąś wartość.

Tak jak wspomniałem na poprzednim slajdzie możemy wyróżnić trzy metody:

1. mockowanie - Czy symulowanie działania
2. stubs/fakes - czyli sztuczne implementacje które pozwalają na interakcje z tymi serwisami Tak jakby one naprawdę były u nas  zaimplementowane
3. kontenery - Wykorzystanie kontenerów do tego aby zdeployować sobie lokalnie te serwisy i wykonać na nie testy.

W przypadku testów integracyjnych w zależności od trudności można wykorzystać wszystkie te trzy metody. 

Na przekładzie testów integracyjnych Chciałbym wam pokazać jak działa podejście  drugie związane z stubsami bądź fakeami i przedsmak trzeciego sposobu czyli wykorzystania kontenerów do uruchamiania testów integracyjnych Natomiast co do trzeciego sposobu wrócimy jeszcze na następnym zjeździe jak poznacie technologię docker compose.

W folderze integration stwórzmy sobie dwa pliki,  pierwszy oczywiście `fixtures.py` i drugi `test_decisions.py` bo ciągle będziemy operować cały czas na endpoincie decisions.

Przejdźmy do `fixtures.py` I zacznijmy od zaimportowania niezbędnych  obiektów:

```python
import pytest
import fakeredis
from pathlib import Path
import psycopg2

from fastapi.testclient import TestClient

from pytest_postgresql.janitor import DatabaseJanitor
from src.service.main import app
from src.databases.redis.connection.connector import RedisConnector
from src.databases.postgres.connection.connector import PostgresConnector
```

Skopiujmy sobie nasze `initiliazed_app` z `fixtures.py` z unit testów. 

W przypadku testów integracyjnych musimy zmienić kilka rzeczy 

Każdy test integracyjny będzie będzie wchodził interakcje z bazami danych. Dlatego też chciałbym żebyśmy ustawili `scope` `fixtures` na `function`. Co to oznacza? Oznacza to że z każdym wywołaniem testu nasz klient testowy z API oraz wszelkie obiekty które zaraz do niego dodamy będą się na nowo inicjować co każdy test. Jest bardzo ważne bo nie chcielibyśmy żeby wyniki jednego testu wpłynęły na wyniki kolejnych testów - one muszą być od siebie niezależne. To też oznacza że musimy zmienić `package_mocker` na zwykłego `mocker`.  a z tego mockowania zostawmy sobie dwie linijki tylko związane z tworzeniem połączenia.  

```python
@pytest.fixture(scope="function")
def initialized_app(mocker):
   mocker.patch.object(RedisConnector, "_create_connection", return_value=None)
   mocker.patch.object(PostgresConnector, "_create_connection", return_value=None)
   with TestClient(app=app, raise_server_exceptions=False) as client:
       yield client
```

Teraz zobaczycie połączenie mockowania z tym drugim podejściem czyli użycia subs bądź fake’ów. To co musimy zrobić to po prostu stworzyć sztuczną implementację Redisa i Postgresa, ale oczywiście nie będziemy wynajdywać koła na nowo ,dlatego że to zostało zrobione przez twórców bibliotek specjalnie stworzonych pod testy integracyjne.

Zacznijmy sobie od redisa.

Na potrzeby testów integracyjnych, mamy bibliotekę `fakeredis`. To co my zrobimy to zrobimy sobie sztuczny `fixture` z tą bazą i podamy ją do naszej testowego API:


```python
@pytest.fixture(scope="function")
def fake_redis():
   return fakeredis.FakeRedis()
```

I wprowadźmy ją sobie do   naszego testowego API:

```python
@pytest.fixture(scope="function")
def initialized_app(mocker, fake_redis):
   mocker.patch.object(RedisConnector, "_create_connection", return_value=fake_redis)
   mocker.patch.object(PostgresConnector, "_create_connection", return_value=None)
   with TestClient(app=app, raise_server_exceptions=False) as client:
       yield client
```

I tak naprawdę robota jest z głowy. Biblioteka `fakeredis`  dostarcza sztucznej implementację Redisa wraz z głównymi jej funkcjonalnościami. Niestety są też pewne ograniczena, natomiast w naszym przypadku one nie będą zbyt istotne dlatego, że My korzystamy z redisa bardzo w podstawowym zakresie,  więc nie będzie z tym żadnego problemu.

To co tam zostało to teraz zrobienie podobnej rzeczy ale dla Postgresa. Niestety z Postgresem i w sumie jakąkolwiek inną bazą danych która jest w jakiś sposób ustrukturyzowana, np. poprzez tworzenie schematów tabel i tak dalej będzie więcej pracy Bo w momencie jej stworzenia musimy ją skonfigurować tak jak ona działa na produkcji. W tym celu wykorzystuje bibliotekę `pytest_postgres` która już jest w importach. Generalnie nie lubię tej biblioteki bo ona jest po prostu ciężko napisana i używanie jej jest dosyć nieprzyjemne ale niestety nie ma lepszej jestem w wypadku skorzystamy z niej.  Niestety stworzenie fejkowego postgresa nie jest już takie proste jak tutaj jeden linijką A tu trzeba będzie kilka kilkanaście napisać.

Zacznijmy sobie od początku:

```python
@pytest.fixture(scope="function")
def fake_postgres(postgresql_proc):
   table_schemas_paths = list(Path(Path(Path.cwd(), "scripts", "postgres", "schemas", "tables")).glob("*.sql"))
```

Ten obiekt `table_schemas_paths` to są po prostu ścieżki do naszych skryptów które tworzą tabele. Będą tam ona teraz potrzebne dlatego że w momencie inicjalizacji bazy będziemy chcieli je podać aby te tabele zostały utworzone. 

Ten argument `postgresql_proc` który został dany funkcji to właśnie jest jeden z pytestowych fixtures który dostarcza nam biblioteka `pytest_postgresql` I ten fixture już z kolei działa tak że on nam w tle uruchomi bazę danych postgres. 

W naszych kodach musimy zdefiniować w jaki sposób będziemy wchodzić w nią w interakcje oraz połączenie z nią. 
  

```python
    with DatabaseJanitor(
        user=postgresql_proc.user,
        host=postgresql_proc.host,
        port=postgresql_proc.port,
        dbname="monitoring",
        version=postgresql_proc.version,
        password="12345",
    ) as janitor:
        for schema_path in table_schemas_paths:
            janitor.load(schema_path.as_posix())
        yield psycopg2.connect(
            dbname="monitoring",
            user=postgresql_proc.user,
            password="12345",
            host=postgresql_proc.host,
            port=postgresql_proc.port,
        )
```

Ta klasa `DatabaseJanitor` to jest implementacja która wchodzi w interakcję z naszą bazą danych. Następnie chcę żeby `janitor` załadował nasze sql-ki więc korzystam z `janitor.load`. I następnie zwracam połączenie z postgresem. 

Słuchajcie wiem że to może nie być jeszcze do końca jasne ale niestety właśnie Każda biblioteka która pozwala wam na tworzenie takich sztucznych baz danych no ma swoją własną logikę działania i niestety trzeba się i wszystkich uczyć na nowo. 

Teraz po zdefiniowaniu w ten sposób `fake_postgres`  możemy go to sobie dorzucić  naszego testowego API


```python
@pytest.fixture(scope="function")
def initialized_app(mocker, fake_redis, fake_postgres):
   mocker.patch.object(RedisConnector, "_create_connection", return_value=fake_redis)
   mocker.patch.object(PostgresConnector, "_create_connection", return_value=fake_postgres)
   with TestClient(app=app, raise_server_exceptions=False) as client:
       yield client
```  

Czy Reasumując użyliśmy mockowania do tego żeby zasymulować połączenie z sztuczną bazą danych która zostanie uruchomiona tylko na potrzeby testów integracyjnych. I tak mówiłem `scope` jest ustawion na `function`. Dlatego że testy integracyjne będą wchodzić w interakcje z różnymi bazami danych,  `scope="function"` w tym przypadku będzie oznaczać to że za każdym razem te bazy będą odtwarzane,  dzięki temu unikniemy  że testy będą od siebie zależne. Po prostu każdy test będzie rozpoczynał swoje działanie na pustych bazach danych.

A teraz  Zobaczmy na własne oczy czy to w ogóle działa. Przejdźmy sobie do `test_decisions.py` Zaimportujmy sobie nasze `fixture` które służyć będą do przeprowadzania testów:

```python
from tests.fixtures import request_body, request_headers, request_endpoint, decision_request
from tests.integration.fixtures import initialized_app, fake_postgres, fake_redis
from pandas.testing import assert_frame_equal

from src.databases.redis.clients.base import BaseRedisClient
from src.databases.postgres.clients.base import BasePostgresClient
from src.service.schemas.responses import DecisionResponse
from src.models.credit_score import CreditScoringModel

import json
```

I zdefiniujmy sobie prosty test żeby tylko zobaczyć czy w to faktycznie działa:

```python
def test_decisions(initialized_app, request_body, request_headers, request_endpoint, decision_request, mocker):
   # first request = prediction generated by model
   first_response = initialized_app.post(url=request_endpoint, headers=request_headers, json=request_body)
   assert first_response.status_code == 200
   assert first_response.headers.get("content-type") == "application/json"
   first_response_json = first_response.json()
```

I następnie puśćmy testy tylko wyłącznie integracyjne:

```bash
python tests/integration/ -v
```

Jak widzicie udało się wszystko dostaliśmy responsa ze statusem 200, ale to oczywiście dopiero początek naszego testowania, dlatego że teraz musimy upewnić czy faktycznie te dane w Redisie i w Postgresie są. Ten test będzie troszkę rozbudowany jak sami zaraz zobaczycie dlatego że w testach integracyjnych trzeba sprawdzić sporo rzeczy.

Zaczne może od tego, że nie będziemy sprawdzać już zawartości responsa, dlatego że wiemy, że ona jest poprawna bo mamy po to testy jednostkowe, które to sprawdzają dlatego. Tutaj tylko i wyłącznie upewniamy się że status jest równy 200, jest jsonem. To znaczy że Response są poprawnie przetworzony i dalej możemy sprawdzać teraz nasze bazy danych.

Wróćmy do `main.py` i spójrzmy jeszcze raz na logikę działania naszego endpointu. Mamy zczytanie danych z redisa, jeśli Tych danych nie ma to wtedy wykonywana jest predykcja modelu i następnie mamy zapisywanie do redisa i zapisywanie do postgresa. Teraz te spanie nam pomogą upewnić się że faktycznie tak się zadziało. Wróćmy do naszych testów i teraz zobaczycie o co chodzi. 

Żeby przetestować naszą logikę działania stworzymy obiekty typu `spy` na początku testu:

```python

def test_decisions(initialized_app, request_body, request_headers, request_endpoint, decision_request, mocker):
redis_read_spy = mocker.spy(BaseRedisClient, "read")
redis_write_spy = mocker.spy(BaseRedisClient, "write")
postgres_write_spy = mocker.spy(BasePostgresClient, "write")
predict_decision_spy = mocker.spy(CreditScoringModel, "predict_decision")
   # first request = prediction generated by model
   first_response = initialized_app.post(url=request_endpoint, headers=request_headers, json=request_body)
   assert first_response.status_code == 200
   assert first_response.headers.get("content-type") == "application/json"
   first_response_json = first_response.json()
```

Startujemy z pustych baz danych zatem jeżeli wyślemy teraz requesta i otrzymamy odpowiedź to oznacza to że nie było odpowiedzi w redisie dlatego że baza jest pusta i powinna stać wykonana predykcja z modelu następnie powinno być zapisane do redisa i zapisane do podkresa, I możemy to sprawdzić Korzystając ze spy. 

Zaczniemy od Redisa:

```python
assert redis_read_spy.called is True
assert redis_read_spy.call_count == 1
assert redis_read_spy.call_args.args[1] == decision_request
assert redis_read_spy.spy_return is None
```

Upewniamy się że nasza funkcja została wywołana,  że została wywołana tylko raz,  że próbujemy odczytać redisa dla tego requesta, a wartość którą zwróciła jest None.

Dalszy krok możemy robić z modelem

```python
assert predict_decision_spy.called is True
assert predict_decision_spy.call_count == 1
assert_frame_equal(predict_decision_spy.call_args.args[1], decision_request.to_dataframe())
decision_from_model = predict_decision_spy.spy_return[0]
decision_response = DecisionResponse(decision=decision_from_model)
```

 dalej mamy zapisane do redisa:

```python
assert redis_write_spy.called is True
assert redis_write_spy.call_count == 1
assert redis_write_spy.call_args.args[1] == decision_request
assert redis_write_spy.call_args.args[2] == decision_response
```

i zapisanie do postgresa:

```python
assert postgres_write_spy.called is True
assert postgres_write_spy.call_count == 1
assert postgres_write_spy.call_args.args[1] == decision_request
assert postgres_write_spy.call_args.args[2] == decision_response
```

Okej udało nam się  rozpatrzeć ścieżkę tą pierwszą czyli wtedy kiedy odpowiedź z API jest związana z predykcją z modelu. Teraz musimy jeszcze rozpatrzeć tą drugą ścieżkę czyli wtedy kiedy odpowiedź dostaniemy z cachea z Redisa. To proponuję sobie w ramach tego samego testu bo mamy już obiekty z zainicjowane odpowiednio łatwiej nam to będzie przetestować niż robić to w oddzielnym teście. 

```python
# second request = predictions readed from cache
second_response = initialized_app.post(url=request_endpoint, headers=request_headers, json=request_body)
assert second_response.status_code == 200
assert second_response.headers.get("content-type") == "application/json"
second_response_json = second_response.json()
```

Teraz sprawdzenie Czy mamy Response z cache’a będzie inne:

```python
assert redis_read_spy.call_count == 2
assert redis_read_spy.spy_return == decision_response
```

Tu wystarczy Sprawdzimy tylko że read został wywołany po raz drugi w tym teście i Dostałeś odpowiedź `decision_response`. 

W przypadku modelu musimy się upewnić teraz że wciąż `call_count`  wynosi 1 to znaczy że funkcja `predict_decision` nie została po raz drugi użyta. 

```python
assert predict_decision_spy.call_count == 1
```

Tak samo w przypadku `redis.write`:

```python
assert redis_write_spy.call_count == 1
```

W przypadku postgresa będzie `call_count` równy. 2 No bo tutaj ponownie zapisujemy tą odpowiedź do bazy danych:

```python
assert postgres_write_spy.call_count == 2
```

I na sam koniec zostało nam najważniejsze rzeczy, czyli sprawdzenie czy po wzroście też się wszystko odłożyło:

```python
data_from_postgres = initialized_app.app.state.decision_postgres_client.read()
assert data_from_postgres is not None
assert len(data_from_postgres) == 2
assert all([row.request == decision_request for row in data_from_postgres])
assert json.loads(data_from_postgres[0].response.json()) == first_response_json
assert json.loads(data_from_postgres[1].response.json()) == second_response_json
```

Teraz może troszkę wyjaśnienia ja w swoim implementacji RedisClienta zawarłem już kody które przekształcają wynik z Postgresa ze zwykłych słowników na obiekt, którzy trzyma w sobie informacje o  `metadata`, o `request` oraz o `response`.

Okej włączmy sobie testy:

```bash
python tests/integration/ -v
```

Udało się zakończyliśmy nasz pierwszy test integracyjny. Oczywiście to co rozpatrzyliśmy to są nasze ścieżki pozytywne, czyli trzeba by rozpatrzeć jeszcze oczywiście ścieżki negatywne - ale to chciałbym, żebyście zrealizowali w ramach swoich ćwiczeń, na API który tworzyliście do tej pory. 

**PRZED ETAPEM Z KONTENERAMI MOŻE BYĆ POTRZEBNE UBICIE BAZY POSTGRES**

```bash
ps aux | grep postgres
```

Znajdź proces który wygląda mniej więcej tak:

  ```bash
/usr/lib/postgresql/14/bin/postgres -D /var/lib/postgresql/14/main -c config_file=/etc/postgresql/14/main/postgresql.conf
```

Ubij go

```
sudo kill -s SIGKILL <<NUMER_PID>>
```

Chciałbym jeszcze pokazać na koniec wykorzystanie kontenerów do testowania. To co my tutaj użyliśmy to fejkowe sztuczne bazy danych. W przypadku kontenerów, które poznacie na kolejnym zjeździe sprawa jest prostsza teoretycznie w taki sposób że możemy lokalnie zdeployować sobie prawdziwe bazy danych.  i nie musimy wtedy w ogóle nic smakować.

Wróćmy sobie teraz do integration fixtures.py. I zakomendujmy sobie nasze mokowanie 

A następnie korzystając z `make redis` oraz `make postgres`, czyli komendy które używaliśmy tej pory cały czas Postawimy sobie właśnie te bazy danych.

```bash
make redis
```
oraz

```bash
make postgres
```

I włączmy nasze testy:

```bash
python tests/integration/ -v
```

I zobaczcie udało się. Czyli tak naprawdę nawet nie musiałbym definiować tych wszystkich fejków które tutaj zrobiłem. Ale jest jedno ale, włączmy je drugi raz. Niestety trzeba byłoby zadbać o to żeby te bazy się restartowały, ale to dopiero poznamy w następnym zjeździe kiedy zapoznacie się z technologią Dockera. 

Generalnie widzicie napisanie testów integracyjnych jest dosyć czasochłonne, wymagające ale tak wam powiedziałem to jest inwestycja w przyszłość, bo później podczas jakichkolwiek zmian w waszym API to takie testy naprawdę wyłapie Wam sporob błędów i bugów które możecie popełnić, a jesteśmy ludźmi i takie błędy cały czas będziemy popełniać.

Niestety Powiem wam szczerze że te testowanie było łatwe dlatego że mieliśmy implementację gotowe na sztuczne bazy danych i poszło sprawnie ale nie zawsze tak jest niestety ale nie wszystkie usługi mają takie implementacje sztuczne jak Redis i postgres w tym przypadku. I jeszcze nawet są takie  bazy danych  które nie mają nawet swoich własnych obrazów kontenerów stworzonych. Problem dotyczy wszelkich baz danych które są w chmurze nie wiem jakie jest aws-ie azurze ale na przykład na Google cloudzie Big QR nie ma fejkowej bazy danych i nie ma też obrazu kontenera.  tak samo Big Table. Jak sobie w tej sytuacji poradzić niestety jest ciężko i trzeba tak naprawdę mocować wszystkie odpowiedzi  która baza danych zwraca i jest to dosyć trudne bo trzeba mockować wewnętrzne funkcje które zostały zaimplementowane przez inżynierów Google żeby wasze testy po prostu były dobre. 

  

 kolejne wyzwanie w testach integracyjnych które dopiero poznacie na czwartym zjeździe poświęconym cia.cd jest taki że lokalnie jesteśmy w stanie uruchomić testy integracyjne ale w pipelanach clcd bywa to czasami niemożliwe albo wręcz bardzo trudne i pracowite. Przykład: Biblioteka `pytest_postgresql` Zakłada że mamy zainstalowanego postgresa u nas na laptopie/maszynce Na której pracujecie i pod spodem taka baza danych Jest uruchomiona. Natomiast w CICD może nie być w ogóle dostępna w zależności od tego jak tam będzie jak będą skonfigurowane maszynki na której te pipeline’y będą uruchomione. Generalnie jeszcze do testów integracyjnych wrócimy jeszcze na kolejnych zjazdach. 

  

Czy macie jakieś pytania do testów integracyjnych?

CAŁY TEST

  

```python

from tests.fixtures import request_body, request_headers, request_endpoint, decision_request

from tests.integration.fixtures import initialized_app, fake_postgres, fake_redis

from pandas.testing import assert_frame_equal

  

from src.databases.redis.clients.base import BaseRedisClient

from src.databases.postgres.clients.base import BasePostgresClient

from src.service.schemas.responses import DecisionResponse

from src.models.credit_score import CreditScoringModel

  

import json

  

  

def test_decisions(initialized_app, request_body, request_headers, request_endpoint, decision_request, mocker):

   redis_read_spy = mocker.spy(BaseRedisClient, "read")

   redis_write_spy = mocker.spy(BaseRedisClient, "write")

   postgres_write_spy = mocker.spy(BasePostgresClient, "write")

   predict_decision_spy = mocker.spy(CreditScoringModel, "predict_decision")

  

   # first request = prediction generated by model

   first_response = initialized_app.post(url=request_endpoint, headers=request_headers, json=request_body)

   assert first_response.status_code == 200

   assert first_response.headers.get("content-type") == "application/json"

   first_response_json = first_response.json()

  

   assert redis_read_spy.called is True

   assert redis_read_spy.call_count == 1

   assert redis_read_spy.call_args.args[1] == decision_request

   assert redis_read_spy.spy_return is None

  

   assert predict_decision_spy.called is True

   assert predict_decision_spy.call_count == 1

   assert_frame_equal(predict_decision_spy.call_args.args[1], decision_request.to_dataframe())

   decision_from_model = predict_decision_spy.spy_return[0]

   decision_response = DecisionResponse(decision=decision_from_model)

  

   assert redis_write_spy.called is True

   assert redis_write_spy.call_count == 1

   assert redis_write_spy.call_args.args[1] == decision_request

   assert redis_write_spy.call_args.args[2] == decision_response

  

   assert postgres_write_spy.called is True

   assert postgres_write_spy.call_count == 1

   assert postgres_write_spy.call_args.args[1] == decision_request

   assert postgres_write_spy.call_args.args[2] == decision_response

  

   # second request = predictions readed from cache

   second_response = initialized_app.post(url=request_endpoint, headers=request_headers, json=request_body)

   assert second_response.status_code == 200

   assert second_response.headers.get("content-type") == "application/json"

   second_response_json = second_response.json()

  

   assert redis_read_spy.call_count == 2

   assert redis_read_spy.spy_return == decision_response

  

   assert predict_decision_spy.call_count == 1

   assert redis_write_spy.call_count == 1

   assert postgres_write_spy.call_count == 2

  

   data_from_postgres = initialized_app.app.state.decision_postgres_client.read()

   assert data_from_postgres is not None

   assert len(data_from_postgres) == 2

   assert all([row.request == decision_request for row in data_from_postgres])

   assert json.loads(data_from_postgres[0].response.json()) == first_response_json

   assert json.loads(data_from_postgres[1].response.json()) == second_response_json

```**