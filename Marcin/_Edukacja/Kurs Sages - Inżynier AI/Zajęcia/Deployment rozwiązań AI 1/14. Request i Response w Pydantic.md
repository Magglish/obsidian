# Request i Response w Pydantic

1. Ok zatem wiemy jakie są rodzaje endpointów i do czego one służą. Rozpracujmy sobie teraz środek endpointa `predict_decision` czyli naszą funkcję `async def predict_decision`. Ustawmy sobie breakpoint np. na moment gdzie jest generowana decyzja z modelu. Uruchomimy nasze API w opcji debugera, czyli obok `if __name__ == "__main__"` kliknijmy `Run in debugger` i wyślijmy zapytanie poprzez `make request`.
2. Debuger zatrzymał nam działanie kodu i teraz spójrzmy co mamy. Tak jak Wam powiedziałem na początku, FastAPI działa tak, że zapytanie/żądanie, czyli request który otrzymuje odpowiednio przetwarza na obiekt, który został określony w type hincie. W tym przypadku `request` jest typu `Request` - w ten sposób otrzymujemy surowe żądanie, które wysłaliśmy do API. I jeżeli spojrzymy sobie w to co otrzymaliśmy to jak widzicie jest tutaj cała masa informacji i różnych obiektów. 
	1. Jest obiekt `app` - to jest dodatkowy obiekt wstrzykiwany przez FastAPI, tego nie ma w requeście. To jest ten obiekt, który zdefiniowaliśmy u góry `app` jest też zawarty w requeście, ale to jest specyfika działania FastAPI - później to wykorzystamy, ale nie teraz. 
	2. Mamy bazowe informacje o `base_url`, czyli gdzie ten request został wysłany. 
	3. `client` czyli skąd został wysłany
	4. `cookies` czyli ciasteczka
	5. `headers` czyli nagłówki, jak widzicie jest ich więcej niż zdefiniowaliśmy w naszym `send_example_request.py` i jeszcze wiele innych obiektów. W tej chwili nie będę wchodził w szczegóły, bo wszystkie te informacje jakie są w żądaniu warto jest znać, ale to będzie omawiane później, nie teraz. To co teraz chce pokazać to to, że tych informacji jest tutaj bardzo dużo. Ale my de facto do wykonania predykcji potrzebujemy tylko i wyłącznie danych do modelu - nic więcej. Więc cały szereg tych informacji jest po prostu nam niepotrzebny. W dodatku zobaczcie, że muszę te dane wyciągnąć korzystając ze słowa `await`, które zapewne widzicie po raz pierwszy, potem zamienić słownik na `pd.DataFrame`. Pytanie czy można to uprościć? 
3. I tutaj na pomoc przychodzi biblioteka `pydantic`, na której FastAPI w pełni się opiera i tiangolo, czyli twórca FastAPI, jest w bardzo dobrych relacjach z twórcami `pydantic` i wspierają się w rozwijaniu tych bibliotek. `pydantic` to bilbioteka, która nie tylko jest używana w FastAPI, ale również [poza](https://docs.pydantic.dev/latest/why/#ecosystem), ponieważ pozwala na definiowanie bardzo rozbudowanych i zaawansowanych customowych struktur danych - innymi słowy to jest taki `dataclass`, ale [na sterydach](https://docs.pydantic.dev/latest/#pydantic-examples). 
4. Ja na tym kursie nie będę omawiał całego pydantica bo biblioteka dostarcza naprawdę ogromnych możliwości i na omówienie tego co można w niej zrobić ze strukturami danych możnaby poświęcić cały dzień. Natomiast co jest podstawowym wyróżnikiem jej i powoduje, że jest lepsza niż pythonowa, wbudowana biblioteka `dataclasses`? To, że w pełni opiera się na type hintach. Jakie to ma konsewkencje? Że automatycznie te struktury danych mają zaimplementowaną w sobie walidacje parametrów wejścia. Jeżeli my zdefiniujemy sobie, że nasze `id` ma być `int` a podamy mu `stringa`, tak jak w tym przykładzie, automatycznie otrzymuje informacje w postaci błędu, że wartość `id` powinna być `int`-em a nie `string`. Plusem jest też to, że jeżeli zdefiniujemy sobie swoje własne customowe typy, to też Pydantic jest w stanie zwalidować to co podamy do tej klasy - za chwilę się o tym sami przekonacie. W dodatku My możemy definiować swoje własne customowe [walidacje wejścia](https://docs.pydantic.dev/1.10/usage/validators/). Tak jak widzimy w tym przykładzie, sam type hint jest nie wystarczający, możemy chcieć zwalidować jeszcze dodatkowo w jakiś sposób `name`, `password` i `username`. Ok. Wiemy mniej więcej czym pydantic jest - mówiąc krótko: są to dataclassy na sterydach. Zostawiam Wam, jako forma ćwiczeń/zadania w domu żebyście sami zgłębili tą bibliotekę w wolnej chwili i polecam korzystać z niej nie tylko podczas budowy API, ale również na codzień, kiedy spotkacie się z sytuacją, że lepiej będzie Wam coś zaimplementować, jeśli stworzycie customową strukture danych - wtedy polecam siegnąc nie po `dataclass` a po `pydantic`-a.
   Jeszcze bardzo ważna rzecz - ten kurs został przygotowany w oparciu o Pydantic v1. Nie korzystamy z wersji 2 - u góry na stronie można wybrać wersję. Różnice pomiędzy Pydantic v2 a v1 są ogromne. Pydantic v1 bedzie się trzymał bardzo długo zanim całkowicie zostanie wycofany. To troche tak jak sytuacja z Pythonem 2.7 i Python 3. Python 2.7 był utrzymywany jeszcze przez 10 lat, zanim przestali go wspierać. Z biblioteką pydantic oczywiście tak nie będzie, ale chodzi mi o to, że jest mnóstwo zmian niekompatybilnych wstecz. Dlaczego kurs został przygotowany pod werzje v1 a nie v2? Z kilku powodów:
   1) Pydantic v2 ma mniej niż rok - cały czas są robione bugfixy i wypuszczane nowe wersje. V2 nie jest jeszcze stabilna na tyle aby móc w pełni oprzeć swoją produkcyjne API na nim. Ja generalnie przyjmuje zasadę, że jeżeli wprowadzana jest nowa wersja apki, ale nie drobna zmiana tylko duża. Jak np. przejście z Tensorflow 1 na 2, Pytorch z 1 na 2 zmigrował, czy właśnie pydantic z v1 na v2 - i widze w release notesach, ze zmiany są ogromne i niekompatybilne wstecz, to po prostu czekam minimum 1 rok żeby nowa wersja się "wygrzała" - naprawione zostały błędy, ludzie nauczyli się z tego korzystać więc już pewne problemy napotkane jako pierwsze zostaną rozwiązane. Dopiero po roku czasu rozważam, czy przechodze na nową wersję czy nie. W pydanticu v2 np. cała ta [walidacja](https://docs.pydantic.dev/1.10/usage/validators/) parametrów się zmieniła - kod z v1 w ogóle nie działa v2.
   2) Drugi argument jest taki, że mnóstwo tutoriali w sieci, czy rozwiązań na stackoverlow są na pydantic v1. V2 jest jeszcze młoda i nie ma za dużo rozwiązań i tutoriali jak coś zrobić. Więc ogólnie jak bedziecie szukać czegoś w sieci trzeba zwrócić uwagę na to czy kod jest na v1 czy na v2.
   3) I trzeci argument - jeżeli spojrzymy sobie na [biblioteki, które korzystają z pydantica](https://docs.pydantic.dev/latest/why/#ecosystem). Jest ich bardzo dużo. Jak wygląda ich migracja na v2? Nie wiem. Wiem tylko, że FastAPI od wersji `0.100.0` wspiera Pydantica v2 - ma pracujemy na wersji `0.99.1` czyli przed migracją na v2. Natomiast jak pozostałe bilbioteki? Kiedy np. `transformers` przejdzie na v2? Nie mam pojęcia. To może zająć im długo, tym bardziej, że jest to biblioteka z open sourceowymi modelami, transformerami stworzonymi w Pytorchu. Chodzi o to, że możecie mieć konflikty w repo, jeżeli chcecie korzytać z Pydantica v2, a biblioteki które macie w repo korzystają jeszcze z v1. 
      Podsumowując:  dla własnej wygody i bezpieczeńśtwa, trzymajmy się na razie z dala od v2 i czekajmy aż to się przyjmie, przetrawi i większość bibliotek, które z tego korzystają zmigrują swój codebase na v2.
1. Ok wróćmy do naszego kodu i spróbujmy to zaimplementować. Wyłączamy breakpointa i zatrzymujemy API. Teraz to co będziemy robić to skorzystamy z pydantica, żeby pozbyć się tego surowego `Requesta` i zamienić na customową strukturę danych. Żeby sobie zączać strukturyzować nasz kod, chce żebyśmy stworzyli sobie nowy folder o nazwie `schemas`. A w nim dwa skrypty: `requests.py` oraz `responses.py`.



1. W kodzie `requests.py` zaimportujmy sobie podstawowy obiekt z Pydantica, który tworzy trzon naszych struktur danych.

```python
from pydantic import BaseModel
```

Następnie stwórzmy klase PredictRequest, która dziedziczy po tym obiekcie.

```python
class PredictRequest(BaseModel):
```
Rzućmy okiem na to jakie dane wysyłaliśmy do modelu w `send_example_requests.py`

Mamy nasze dane wejściowe, to przekopiujmy sobie ich nazwy i określmy typy.

```python
    installment_rate_in_percentage_of_disposable_income: float
    age_in_years: int
    foreign_worker: str
    present_employment_since: str
    personal_status_and_sex: str
```

2. Przejdźmy teraz do `responses.py` i stwórzmy odpowiedź

```python
from pydantic import BaseModel


class PredictDecisionResponse(BaseModel):
    decision: str
```


3. Wróćmy do naszego `main.py` i użyjmy naszych obiektów teraz w naszym endpoincie

```python
from src.service.schemas.requests import PredictRequest
from src.service.schemas.responses import PredictDecisionResponse
```

Zmieńmy nasze typehinty w endpoint tak aby wskazywały na nowe obiekty 

```python
async def predict_decision(request: PredictRequest) -> PredictDecisionResponse:
```

oraz 

```python
return PredictDecisionResponse(decision.name)
```

Jak widzicie troche PyCharm mi podpowiada kolorkami, że coś się nie zgadza - on już wie co przyjdzie tutaj, dlatego rzuca mi warningiem.

Poprawmy nasz return na to aby wskazać wprost nazwe argumentu - Pydantic wymaga od nas abyśmy parametry nie przekazywali pozycyjnie, a wprost po nazwach argumentów. Dlaczego? Dlatego, żeby kod był bardziej czytelny.

```python
return PredictDecisionResponse(decision=decision.name)
```

słowem `await` zajmiemy się później.

Ustawmy breakpointa właśnie na `await` i uruchommy API w trybie debugera, zobaczmy co dostaliśmy. Wysyłamy requsta z `make request` i zobaczmy co dostaliśmy.
Spójrzmy teraz w strukturę `requesta` i widzimy, że jest to nasz `PredictRequest` zdefiniowany wcześniej. Mamy wszystkie wartości, które stanowić będą wejście do modelu.

Przejdźmy do `console` w debugerze i zobaczmy, co możemy z tym obiektem zrobić. Przedewszystkim jest to obiekt taki sam jak bazowy `dataclass`, więc po te dane możemy sięgac bezpośrednio po nazwach. Mamy też metody `.json()` oraz `.dict()`, które przekształcą nam ten obiekt w to co chcemy. W naszym przypadku będzie potrzebny `dict()`. 

Ok widzimy co przyszło, więc zmodyfikujmy kod na to aby teraz skorzystać z nowej struktury danych. Tak na prawdę linijkę 
```python
data = await request.json()
```

Możemy się pozbyć, a w dict comprehension zamienić `data.items()` na `request.dict().items()`

```python
features = pd.DataFrame({key: [value] for key, value in request.dict().items()})
```

Zatrzymajmy debugera i spróbujmy uruchomić API i zobaczmy czy działa i co otrzymaliśmy.

I działa: mamy odpowiedzi. I teraz spójrzcie co zwraca `response.json()`- zwraca w końcu `json`-a czyli `response.json()={'decision': 'DECLINE'}` a nie jak wcześniej sam string `response.json()='DECLINE'`, więc od razu też nasza odpowiedź z API poprawiła swoją strukturę na właściwą.

I teraz bardzo fajna rzecz - wejdźmy sobie na dokumentację naszego API -> http://0.0.0.0:8080/docs i zobaczmy co mamy. Otrzymaliśmy szereg informacji na temat tego co może wejść do API i jaki jest z niego output z przykładowymi wartościami. Ja osobiście wole redoca -> http://0.0.0.0:8080/redoc 

Jak widzicie, my tylko zdefiniowaliśmy kod w Pythonie a magia dzieje się sama za nas. Dokumentacja naszego API jest rzeczą bardzo istotną i bardzo fajne w FastAPI jest to, że my tak naprawdę nie musimy się na niej skupiać - ona sama się generuje na podstawie tego jak to wszystko zaimplementowaliśmy.

To był pierwszy kontakt z Pydantic. Ale wróćmy do naszych requestów i response i czas je zrobić porządnie...

Wróćmy teraz do `requests.py` i zaimportujmy dodatkowo z `pydantic`a jeszcze obiekt `Field`:

```python
from pydantic import BaseModel, Field
```

Klasa `Field`, jak sama nazwa wskazuje, pozwala nam zdefiniować konkretne pola, które wchodzą w ramach struktury danych. Ale klasa sama w sobie pozwala nam jeszcze dokładniej zdefiniować to co stanowi wejście do tego obiektu.

Zacznijmy od `installment_rate_in_percentage_of_disposable_income`. Jak sobie spojrzymy na `help(Field)` to jest wiele pól, które można ustawić, ale najważniejszych w kontekście API będzie w sumie kilka.
1. `default` - ustawiony na `...` oznacza, że wypełnienie tego pola jest wymagane. Jeśli ustawilibyśmy tutaj jakąś wartość to wtedy gdy brakować bęðzie tego pola w żądaniu, to te pole przyjmie naszą wartość domyślną
2. `title` oraz `description`, które opiszą nasze pole. W naszym przypadku nasze pola są na tyle proste i jasne, że praktycznie `title` i `description` mogą być wręcz takie same jak opis zmiennych. Ale warto to zrobić, dlatego, że tak jak się można domyślić - wszystkie te pola, które ustawiamy będą odpowiednio wyświetlane w dokumentacji.
3. I ostatnie dwa parametry, które są dla nas bardzo istotne w kontekście tej zmiennej czyli `ge`, czyli greater or equal than - w naszym przypadku to bedzie wartosc 0.0. Ktoś może być zadłużony ponad tyle ile zarabia, ale nie może być ktoś zadłużony na minusie.

Całość wygląda tak:

```python
    installment_rate_in_percentage_of_disposable_income: float = Field(
        default=...,
        title="Installment rate in percentage of disposable income",
        description="Installment rate in percentage of disposable income",
        ge=0.0,
    )
```

Rozpracujmy sobie dalej pozostałe zmienne