# Background tasks

1. Niestety ale z zapisywaniem danych do baz - czy to Redis czy to Postgres wiąże się pewne wyzwanie. Ale zanim do tego przejdziemy to... tak jak Wam mówiłem - podczas projektowania API powinny nam przyświecać dwa cele - prostota i szybkość. Jak widzieliście, dodanie cache zwiększyło szybkość naszego API. Ale czy na pewno?
2. Spójrzmy prosze w kod na ten endpoint i zastanówmy się, które elementy w nim spowalniają nasze API. Czy ktoś z Was widzi takie elementy?
3. Podzielmy to na dwie części:
	1. Uzyskujemy odpowiedź z cachea - to co nam spowalnia działanie naszego API to zapisanie do bazy postgres `decision_postgres_client.write(request, response)`.
	2. Uzyskujemy odpowiedzi z modelu - to co nam spowalnia działanie naszego API to:
		- czytanie z bazy Redisa: `decision_redis_client.read(request)`
		- zapisanie do Redisa: `decision_redis_client.write(request, response)`
		- zapisanie do Postgresa: `decision_postgres_client.write(request, response)`
4. W naszym przypadku zapisywanie do baz Redisa czy do Postgresa trwa dosłownie kilka milisekund, wręcz niezauważalne. Ale na produkcji może to być znacznie dłuższy czas - to może być uzależnione od wielu różnych czynników: wielkość danych które chcemy zapisać do bazy, jej obłożenie, w jakiej lokalizacji znajduje się baza danych np. nasze serwisy działają w Warszawie, a baza danych jest w Belgii.

![[GCP Latencies.png]]

Jak sobie spojrzymy jakie są opóźnienia na Google Clud w zależności od regionów to można zobaczyć, że serwis działający w Warszawie (europe-central) a baza danych w Belgii (europe-west1) to już jest 20 ms opóźnienia na samej sieci. A gdybyśmy chcieli wysłać dane do Ameryki to mamy ponad 100 ms. To jest znacznie, znacznie więcej niż same wykonanie predykcji przez nasz model - bo nasz model zwraca predykcje w 2 ms. 

5. To teraz jak ten problem rozwiązać? FastAPI przychodzi nam z pomocą i możemy w nim użyć tak zwanych Background Tasks, czyli po prostu możemy zdefiniować co ma być wykonane w tle.  
6. Zaimplementujmy to, a potem omówie dokładnie jak to działa.

Zaimportujmy obiekt Background Tasks

```python
from fastapi import BackgroundTasks
```

Do naszego endpointa musimy dodać parametr `background_tasks: BackgroundTasks`

```python
@app.post("/decisions")  
async def decisions(  
    request: DecisionRequest,  
    background_tasks: BackgroundTasks,  
) -> DecisionResponse:
```

Aby dodać coś do działania w tle, musimy zakodzić to jako funkcję. Zatem ja w `src/service` dodam nowy folder `tasks` a w nim dwa pliki `redis.py` oraz `postgres.py`

W `postgres.py` zapiszemy sobie funkcje:

```python
def write_to_postgres(postgres_client, request, response):  
    postgres_client.write(request, response)
```

A w `redis.py` zapiszemy sobie funkcje:

```python
def write_to_redis(redis_client, request, response):
    redis_client.write(request, response)
```

Teraz jedna uwaga: te funkcje zasługują na dokumentację oraz type hinty, ale musicie mi wybaczyć za to, że ich nie będzie, bo chce żebyśmy mieli więcej czasu na omówienie rzeczy związanych z API, więc chce te rzeczy pominąć.

Następnie zaimportujmy je do `main.py`:

```python
from src.service.tasks.redis import write_to_redis  
from src.service.tasks.postgres import write_to_postgres
```

I teraz sprawa jest bardzo prosta, bo w nasze wszystkie miejsca w których mieliśmy zapisanie do Redisa i do Postgresa, będziemy dodawać taski do tła:

Sprawa jest prosta: `background_tasks` ma metode `add_task`, gdzie pierwszym argumentem jest funkcja, a pozostałe parametry to argumenty do niej:

```python
@app.post("/decisions")
async def decisions(
    request: DecisionRequest,
    background_tasks: BackgroundTasks,
) -> DecisionResponse:
    response = decision_redis_client.read(request)
    if response is not None:
        background_tasks.add_task(
            func=write_to_postgres,
            postgres_client=decision_postgres_client,
            request=request,
            response=response,
        )
        return response

    decision = model.predict_decision(request.to_dataframe())[0]
    response = DecisionResponse(decision=decision)
    background_tasks.add_task(
        func=write_to_postgres,
        postgres_client=decision_postgres_client,
        request=request,
        response=response,
    )
    background_tasks.add_task(
        func=write_to_redis,
        redis_client=decision_redis_client,
        request=request,
        response=response,
    )
    return response
```

Ale zanim wytłumacze jego działanie to jeszcze zrefactoruje go delikatnie, bo tak jak widzicie wydłużył się nam oraz mamy powielony kod w dwóch miejscach, tam gdzie jest zapisanie do postgresa.

Zrefactorujemy do:

```python
@app.post("/decisions")  
async def decisions(  
    request: DecisionRequest,  
    background_tasks: BackgroundTasks,  
) -> DecisionResponse:  
    response = decision_redis_client.read(request)  
    if response is None:  
        decision = model.predict_decision(request.to_dataframe())[0]  
        response = DecisionResponse(decision=decision)  
        background_tasks.add_task(  
            func=write_to_redis,  
            redis_client=decision_redis_client,  
            request=request,  
            response=response,  
        )  
    background_tasks.add_task(  
        func=write_to_postgres,  
        postgres_client=decision_postgres_client,  
        request=request,  
        response=response,  
    )    return response
```

Ok to na koniec jeszcze sprawdźmy czy to faktycznie działa 
Sprawdz czy:
1. request jest przetworzony
2. dane sa w bazie sql

Ok to teraz co my zaimplementowaliśmy? Jak już wspomniałem i też sama nazwa tego obiektu wskazuje, to Background Tasks odpowiada za uruchamianie kodu w tle. ALE nie w momencie wywołania tej funkcji, a dopiero po zwróceniu odpowiedzi z API.

Żeby Wam to pokazać, dodajmy sobie proste printy do naszego kodu żebyśmy zobaczyli jaki jes tflow - dodaje printy ponieważ jeszcze nie mieliśmy lekcji o logowaniu.

1. Dodam sobie printy na poczatek i koniec endpointa:

```python
@app.post("/decisions")  
async def decisions(  
    request: DecisionRequest,  
    background_tasks: BackgroundTasks,  
) -> DecisionResponse:  
    print("Starting processing request")
	...
	...
	...
	print("Returning response")
	return response
```
1. Oraz wewnatrz tych tasków

```python
def write_to_redis(redis_client, request, response):  
    print("Starting writing to redis")  
    redis_client.write(request, response)  
    print("Finished writing to redis")
```

```python
def write_to_postgres(postgres_client, request, response):  
    print("Starting writing to postgres")  
    postgres_client.write(request, response)  
    print("Finished writing to postgres")
```

Zrestartujmy nasze API i wyślijmy requesta ze zmieniona wartoscia w zmiennej.

To co powinniśmy zobaczyć to to, że request został przetworzony i odpowiedź zostałą zwrócona, a dopiero później uruchamiane są nasze background taski. I to jest to co nas w tej chwili interesuje i wręcz ratuje. Background taski pozwalają API na zwrócenie odpowiedzi do klienta/osoby odpytującej API tak szybko jak odpowiedź jest już gotowa - natomiast a wszelkie inne operacje, które dodamy do background tasks ZAWSZE uruchamiają się po zwróceniu odpowiedzi - i do nich dodajemy wszelkie zadania/operacje które są długie i mogą po prostu wydłużyć nasz czas odpowiedzi. W naszym przypadku takimi operacjami są zapisy do bazy danych. 

Sprawdźmy jak to działa gdybyśmy jednak do API wysłali więcej requestów.

Założmy, że zapisanie danych do naszej bazy postgres `write_to_postgres.py` trwa 10 sekund

```python
import time


def write_to_postgres(postgres_client, request, response):
    print("Starting writing to postgres")
    time.sleep(10)
    postgres_client.write(request, response)
    print("Finished writing to postgres")
```

Zresetujmy API i odpytajmy je najpierw raz, a potem kilka razy. Widać, że dostajemy odpowiedzi z API od razu, a procesy w tle po prostu kończą się w swoim czasie.

Pytanie jakie można zadać: jak to jest możliwe? Na to pytanie odpowiem dopiero w sekcji poświęconej przetwarzaniu asynchronicznemu.

Ok to usuńmy sobie te printy i sleep'y, które tutaj mamy. No i pytanie do Was czy macie jakieś pytania do tego tematu?