# Statusy

Zanim przejdziemy dalej chce Wam pokazać jeszcze jedną rzecz. Wróćmy do bazowych wartości, włączmy API `make api` i wyślijmy requesta `make request`.
	1. Wysyłając poprawne dane otrzymujemy odpowiedź i `status_code = 200`
	2. Jeżeli teraz coś popsuje w danych wejściowych to otrzymuje odpowiedź z błędem i `status_code = 422`
	3. Co się stanie jeżeli popsuje coś w środku API? Zmieńmy w odpowiedzi decision na `xxx` czyli `PredictDecisionResponse(decision="xxx")`. Zresetujmy API i spróbujmy wysłać `requesta`. Przejdźmy na widok logi API i zobaczmy co się stało. Ok widzimy, że mamy teraz `status_code = 500` - logi API wskazują, że, to co się spodziewaliśmy, przekazaliśmy złą wartość do `PredictDecisionResponse`. To na co my patrzymy to widzimy My, developerzy. Natomiast co widzi klient, będzie w drugim oknie. Na początku widzimy `status_code=500`, na dole jest traceback z błędem, ale to błąd po naszej stronie, bo `response` nie ma metody `.json()`. Delikatnie zmienimy to na:

```python
# print(f"Received {response.json()=}")  
print(f"Received {response.content=}")
```

Teraz jest OK. Spójrzmy jeszcze raz na okno API i na okno z requestem. Tutaj zakomentowałem na chwilę tą linijkę kodu, bo odpowiedź, która przyszła z API jest na tą chwilę zwykłym stringiem, dlatego `request.json()` nie zadziałała, bo odpowiedź nie jest `JSON`. To później zacznie działać jak w API zaimplementujemy poprawną obsługę błędów - to będzie temat na później. Natomiast widzimy, że mamy teraz `status_code=500` oraz informacje `Internal Server Error`. 

Z poziomu klienta/serwisu, który będzie korzystał z Waszego API są najważniejsze dwie informacje, które ze sobą istnieją i jedna bez drugiej nie ma sensu
1. To są oczywiście dane zwrotne z API, które otrzymamy jeżeli nasze żądanie zostanie poprawnie przetworzone. Albo treść błędu jeżeli coś jest nie tak - teraz widzimy treść `Internal Server Error`, natomiast wczesniej były informacje, że dane cechy albo źle przekazaliśmy, albo przekazaliśmy za dużo.
2. Natomiast drugą informacją, która jest bardzo istotna to jest `status_code`, która jak widzieliście przyjmuje różne wartości w zależności od odpowiedzi - widzieliśmy `200`, `422` oraz teraz `500`. 
3. Treść wiadomości nie ma sensu bez status code'a i tak samo sam status_code nie ma sensu bez treści wiadomości - to są dwie nierozerwalne rzeczy i zarówno treść wiadomości musi być jasna i precyzyjna, oraz status code musi przyjąć odpowiednią wartość.
4. Weźmy w takim razie na warsztat status code. Z kolei treścią wiadomości o błędzie zajmiemy się później, kiedy będziemy w API implementować tzw. exception handlery, ale to później.

Sprawa ze statusami jest bardzo prosta:

Istnieje [5 rodzajów statusów](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status). Otworze sobie dokumentację tych statusów, które stworzyła Mozzila, żeby łatwiej Wam to wytłumaczyć. 

Przy okazji uruchomimy sobie przeglądarke z opcją Networking żeby móc podejrzeć jak nasze zapytania są przetwarzane.

1. 1xx - Pierwsza grupa statusów to statusy informacyjne, informujące o tym, że zapytanie zostało otrzymane i jest przetwarzane. W rzeczywistości praktycznie nie zauważalne statusy. Powiem szczerze, że nawet nie wiem jak utworzyć zapytanie żeby móc mieć wgląd w nie. Te statusy można określić jako techniczne. Wasze API nigdy takich statusów nie zwróci.
2. 2xx - Druga grupa statusów informuje o tym, że zapytanie zostało poprawnie przetworzone. W zależności od kodu odpowiedzi wynik tego przetwarzania może być różny. 
	1. `200` - Jeżeli spojrzymy sobie jakie mamy statusy to pierwszym statusem jest 200 - to już widzieliśmy w naszym API, w momencie kiedy zapytanie wysłane do niego zostało poprawnie przetworzone. Otrzymywaliśmy decyzje z modelu oraz `status_code = 200`.
	2. `201` - Created czyli dany zasób został stworzony. Np. gdybyśmy stworzyli API, które przetwarza dane i coś tworzy np. zapisuje nowy obiekt w bazie danych to wtedy nasze API powinno zwrócić `status_code = 201`
	3. `202` - Zapytanie zostało zaakceptowane, przetworzone, ale tak na prawdę nasze API nie ma co zwrócić. To jest specjalny case, który też możecie spotkać się w momencie projektowania API do modeli MLowych, które bardzo długo przetwarzają zapytania - wtedy serwis opiera się o schemat kolejkowania. To jest znacznie bardziej zaawansowany case, z którym rzadziej się spotkacie, ale omówie go później przy tematach zaawansowanych.

Nie będę oczywiście omawiał wszystkich statusów bo to jest ich za dużo i podczas budowy API do serwisu MLowego będzie używać naprawde tylko kilku z nich. Natomiast omówie tylko kilka z nich z każdej grupy tak żebyście mogli złapać kontekst czego dana grupa statusów dotyczy.

4. 3xx - Trzecia grupa informuje o tym, że musi być podjęta dodatkowa akcja w celu skończenia przetwarzania zapytania. Statusy te wykorzystywane są do ustawiania przekierowań. Z tym się już częściej spotkacie, w szczególności gdy ktoś Wam udostępni skrócony link np. tinyurl albo bit.ly (np. https://bit.ly/42Ex9oZ). Jak widzimy pierwsze zapytanie ma 301, czyli `301 Moved Permanently`. W nagłówkach w `Location` widzimy informacje gdzie nas przekierowuje. I ten link nas przekierował na stronę docelową. A następnie zapytanie ma już status `200` co oznacza, że poprawnie zostało przetworzone zapytanie skierowane już do tej strony docelowej. Czy my w API MLowym się z tym spotkamy? To zależy od implementacji. My na naszym kursie będziemy je używać w momencie kiedy będziemy zabezpieczać nasze API przed dostępem z zewnątrz.
5. 4xx - Czwarta grupa - statusy z tej grupy informują o błędzie **po stronie wysyłającego żądanie.** Czyli po stronie osoby czy innego systemu, który korzysta z naszego API. 
	Mamy np. `400`, że w ogóle nasze zapytanie było błędne. 
	Dalej `401`, że nie mamy uprawnień żeby odpytać dane API.
	Dalej `403`, czyli zastrzeżone, nie można odpytać.
	Dalej `404` nie znalezione
	Dalej `405` to już widzieliśmy przy okazji odpytywania naszego API - kiedy chcieliśmy odpytać endpoint `predict_decision` ale poprzez żadanie typu `GET`, a nie `POST` i otrzymywaliśmy `405: Method not allowed`.
	Jak widzicie, statusów z tej grupy jest sporo. Nie sposób jest ich wszystkich zapamiętać, ale nie musimy też wszystkich pamiętać. Tylko kilka z nich będzie istotne w naszym przypadku zastosowaniu.
1. 5xx - No i na koniec ostatnia grupa, piąta, która informuje, że o błędzie po stronie serwera, które uniemożliwiają przetworzenie zapytania. Czyli to oznacza problem z naszym API. 
   Mamy naszą `500`, którą widzieliście czyli `Internal Server Error`- błąd wewnętrzny. Rzucany w momencie kiedy w naszym API jest jakiś wyjątek Pythonowy rzucany, to osoba odpytująca oczywiście nie zobaczy całego Tracebacka z naszym kodem, a po prostu `status_code=500` wraz z informacja o `Internal Server Error` czyli błąd w środku serwera.
   Dalej `501`, która informuje, że dany endpoint nie przetwarza danego rodzaju zapytania. 
   Dalej jest `502: Bad Gateway` ten błąd będzie mi trudno wytłumaczyć, bo jeszcze nie mamy wiedzy czym jest  `proxy`, a to dopiero bedzie na zajęciach z Kubernetesa. Natomiast to jest ciekawy błąd, bo to może być wina po stronie serwisu jak i po naszej stronie. Wrócimy do niego na zjeździe 3-cim.
   Dalej `503` czyli serwis jest po prostu niedostępny. 
   No i `504` czyli Gateway Timeout - chodzi o to, że dane zapytanie nie zostało przetworzone w skońćzonym czasie. Defaultowo jak wysyłamy requesta z pythonowej paczki `request` to jest to ustawione na 300 sekund. Można to oczywiście zmienić parametrem `timeout`. Jeżeli w ciągu tego czasu nie otrzymamy odpowiedzi, to przetwarzanie jest przerywane i zwracany błąd `504`. Teraz ten błąd jest istotny w kontekście serwisów MLowych. Teraz tego nie zobaczycie na tym zjeździe, ale na zjeździe poświęconym Kubernetesowi, gdzie będziemy uczyć się skalować nasz serwis do wielu instancji po to aby obsłużyć wzmożony ruch do naszego serwisu, ten błąd `504` będzie oznaczał, że mamy za mało instancji w stosunku do ruchu, przez co jest tak dużo zapytań do przetworzenia, że pewne zapytania, które czekają w kolejce, czekają tak długo (ponad 300 sekund), że same się przerywają ze statusem `504`. To co powiedziałem może być nie do końca jasne, ale to wszystko wyjaśni się na zjeździe 3-cim.

Podsumowując:

1. Statusy 1xx - czysto informacyjne, nie zobaczymy ich.
2. Statusy 2xx - przetwarzanie żadania zakończyło się pomyślnie.
3. Statusy 3xx - nasze żądanie zostało przekierowane w inne miejsce.
4. Statusy 4xx - nasze żądanie jest błędne
5. Statusy 5xx - nasz serwis miewa problemy

Pytanie jakie można sobie zadać - czy ja musze znać wszystkie te statusy? I które z tych statusów potrzebuje do stworzenia serwisu do modelu? Te najważniejsze warto zapamiętać, bo z nimi będzie spotykać się często korzystając z różnych serwisów w trakcie swojej pracy czy też po prostu korzystając z internetu:

Wskaże teraz statusy, z których korzystamy w trakcie tworzenia serwisu MLowego i co one oznaczają w naszym kontekście:

1. 2xx:
	1. `200 Ok` - zapytanie zostało poprawnie przetworzone, w odpowiedzi zwróciliśmy wynik z modelu. 
	2. `201 Created` oraz `202 Accepted` - Rzadziej spotykane, ale spotykane. Spotkacie się z nimi w dwóch sytuacjach:
		1. Są to statusy zwracane przez serwisy MLowe, które np. pozwalają na zlecenie pewnego rodzaju Joba, żeby przetworzył bardzo dużą ilość danych. W takiej sytuacji serwis zwraca `201 Created` i np. ID Joba. W takiej sytuacji, dobrą praktyka jest zaimplementować inny endpoint typu GET, który przyjmuje w żądaniu ID Joba i zwraca nam odpowiedź jaki jest status tego joba - czy jeszcze trwa, czy jest zakończony z sukcesem lub błędnie.
		2. Druga sytuacja jest wtedy kiedy chcemy wykonać jakąś predykcję, która długo trwa, możemy tak zaprojektować serwis, że przyjmie on nasze żądanie, w tle uruchomi joba, który rozpocznie pracę, a w odpowiedzi od razu zwróci nam `202 Accepted` wraz znowu z ID joba, żeby móc sprawdzić jego status.
		3. Jeśli chodzi o Nas to My na tym kursie skupiamy się na tym co w 90% przypadków spotkacie, czyli serwis oparty o model MLowy, który odpowiedź ma zwrócić natychmiast. Natomiast w trakcie szkolenia będziemy implementować pewne rozwiązania, których umiejętność implementowania wykorzystać można przy projektowaniu serwisów które pozwalają na przetworzenie czegoś batchowo albo właśnie wykonują bardzo długie predykcje. Takim przykładem wykonywania długich predykcji mogą być wszelkie rodzaje serwisów przetwarzających obraz czy wideo. Dajmy na to serwis wyciąga różne dane z obrazu używając przy tym wielu różnych modeli i cały taki pipeline może trwać długo, więc dostaniemy ID Joba z serwisu i możemy sobie podglądać jaki jest status. W przypadku wideo mogłoto by być Comixify które już nie działa (http://narzedziaetwinning.blogspot.com/2020/03/comixify.html). Pierwsza wersja tylko brała niektóre momenty z filmu, a druga wersja potrafiłą już całe wideo zrenderować w takim formacie. To jest dobry przykład serwisu, który długo wykonuje predykcje, no bo analiza całego wideo troche może trwać. Niestety już nie działa.
2. 3xx
	1. Jeśli chodzi o 3xx to raczej ich nie spotkacie, bo serwisy MLowe są bardzo proste w swych założeniach. A nawet jeżeli one występują, to nie zobaczycie ich bezpośrednio, tylko pośrednio analizując ruch sieciowy np. poprzez narzedzie Networking. My natomiast

Natomiast statusy, które wykorzystacie w serwisie MLowym to:

1. ...
2. ...
3. ...
4. ...