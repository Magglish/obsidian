1. Chciałbym Wam przedstawić po krótce co będziemy omawiać na tych 4 zjazdach i trochę przedstawić konteksty dlaczego akurat to. Teraz będzie ogólniej, natomiast na początku każdego zjazdu pokaże więcej szczegółow odnośnie danego zjazdu.
2. Jak widzicie mamy 4 zjazdy: pierwszy z nich, na którym obecnie jesteśmy jest to zjazd poświęcony stworzenia serwisu API dla naszego modelu. Czym jest serwis, czym jest API i wszelkie takie magiczne słowa jeśli ktokolwiek z tym spotyka się po raz pierwszy oczywiście będzie później wyjaśnione w trakcie zjazdu. Następnie mamy zjazd poświecony konteneryzacji i technologii Docker. Trzeci zjazd, mój ulubiony, poświęcony całkowicie klastrom zarządzanym przez Kubernetesa. No i na końcu mamy wisienkę na torcie czyli CICD, które krótko mówiąc będzie spajało wszystko co robimy na zjazdach 1-3 z deploymenty w pewien pipeline/potok, w pełniu zautomatyzowany i będzie działą się w nim cała magia - co zobaczycie na tym zjeździe. Spójrzmy sobie troche na to co będziemy robić na poszczególnych zjazdach, ale na razie ogólnie.
3. Na każdy zjazd przewidziany jest weekend, 16 godzin. Czy to dużo czy mało? Trudno mi ocenić. Powiem Wam szczerze, że ja cały czas w trakcie pracy odkrywam kolejne niuanse, kruczki czy to w trakcie projektowania API, czy wystawianiu kontenerów, czy deployowaniu modeli na klastrze, czy budowaniu automatycznych pipelineów. I tak każdy z Was będzie miał - te frameworki się non stop rozwijają, pojawiają się nowe problemy, a jak nie nowe problemy to ktoś wymyśla lepszy sposób na rozwiązanie starego problemu, zatem nie ma nudy. Natomiast, z racji tego, że mamy po 16 godzin na moduły i to, że macie już za sobą doświadczenie zawodowe, dzięki temu te prostsze tematy będą dla Was łatwiej i szybciej przyswajalne. Dzięki temu oprócz idei/zagadnień fundamentalnych bedziemy również poruszać zagadnienia bardziej zaawansowane, trudniejsze i po prostu wyciągnięte z produkcji, problemy z którymi będziecie się napotykać, wraz z rozwiązaniami. 
4. Zaczniemy od początku, czyli udostępnieniu naszego modelu w sieci. Powiem Wam też jak oczywiście inaczej można model udostępnić, ale w rzeczywistości spotkacie się praktycznie w 90% przypadków z REST API. Powiem też oczywiście jakie są inne rodzaje API, ale jako ciekawostke, bo są rzadko spotykane. Z rzeczy podstawowych to oczywiście bęðziemy implementować nasze API do modelu, zatem poznacie wszelkie rodzaje endpointów, które wykorzystacie w projektowaniu. Powiemy sobie o dokumentacji naszej aplikacji, czym jest te słówko REST i jakie to ma komplikacje - wszystko to co o API powinniście wiedzieć. Oprócz tego poruszymy także zagadnienia znacznie bardziej zaawansowane, bo nie bęðziemy budować tutaj aplikacji hello-world tylko podejdziemy do tematu poważnie. Powiemy sobie o logowaniu aktywności API, o middleware, czyli czymś pomiędzy naszymi endpointami a klientem który korzysta z naszego modelu, powiemy sobie o zabezpieczeniu API przed dostępem z zewnątrz, obsługa wyjątków, o bebechach FastAPI - jak wygląda w ogóle przetwarzanie zapytań do naszego modelu, co jest bardzo istotne. Powiemy również o asynchroniczności co będzie tematem dla Was trudnym, bo tak na prawde jeśli zapytamy Data Scientista o przetwarzanie równoległe, to pomyśli on o multiprocessingu, czyli przetwarzaniu na wielu procesorach jednocześnie. I to jest zrozumiałem, bo my możemy bardzo łatwo to użyć, scikit-learn daje parametr n_jobs podczas uczenia modeli. Podczas optymalizacji hiperapametrów głupio jest uruchamiać optymalizacje na jednym procesorze. Natomiast jeśli zapytamy Backend czy Frontend developera to o przetwarzaniu równoległym myśli bardziej w kontekście przetwarzania wielowątkowego, czyli multithreading. Tutaj powiemy sobie o tym dokładnie, ponieważ w Fast API można zrobić to i tak, i tak, czyli zastosować i wielowątkowość i wieloprocesorowość. A jeszcze można zrobić to jednocześnie. Tylko pytanie powstaje - kiedy co stosować? No i jak? Powiemy sobie również o testowaniu, bardzo istotnej rzeczy przy tworzeniu wszelkiego rodzaju software, ale o testowaniu w 3 wymiarach: oprócz testowania samej poprawności implementacji, będziemy również testować... dokumentację, czyli tzw. testy kontraktowe. To będzie ciekawe. No i najważniejsze w serwisach opartych o ML - testy obciążeniowe. Jak szybko przetwarzamy nasze zapytania, przy różnych scenariuszach. To też będzie dla Was bardzo ciekawe, ponieważ będziemy generować sobie hipotetycznych użytkowników, którzy korzystać będą z naszego API i patrzyć czy nasze API jest w stanie obsłużyć duży ruch. Ale oprócz samych takich rzeczy w kodzie będziemy również mówić o tym jak komunikują się ze sobą dwa różne systemy w sieci. Wiecie dlaczego? Dlatego, że nie chciałbym żebyście wyszli stąd z wiedzą tylko o tym, jak dobrze stworzyć serwis do modelu. Chciałbym żebyście wiedzieli jak w ogóle wygląda komunikacja pomiędzy chociażby moim laptopem a waszym serwisem który bęðzie sobie działał w chmurze. Czyli omówimy sobie czym jest protokół do komunikacji w sieci - HTTP. Czym są te ciasteczka, nagłówki, requesty, czyli żądania, response czy odpowiedzi, czym jest Port, w ogóle z czego skłąda się URL, czym jest DNS i wiele innych rzeczy. Dodatkowo poznacie też komendy w bashu które pozwolą Wam zobaczyć jak ruch wygląda między waszym laptopem a serwisem. Dlaczego jest to omawiane? Dlatego, że bardzo często jest tak, że to że Wasz serwis nie działą nie oznacza, że macie problem w kodzie. Problem może być w sieci. Oczywiście my jako Data Scientisci, Machine Learning Engineerowie czy Inżynierowie AI nie bęðziemy ekspertami od spraw sieciowych - broń boże. Natomiast podstawowy wachlarz umiejętnosci i zrozumienia jest wymagany. Chociażby z tego powodu, że gdy bęðziecie rozmawiać z np. DevOpsem albo Administratorem Systemu, który bęðzie Was wspierał w ustawianiu konfiguracji sieciowych to będziemy mogli z nim rozmawiać i rozumieć się nawzajem i nie padniecie na prostym pytaniu: na jakim porcie słucha Twój serwis? 
5. Jak już mamy serwis to fajnie byłoby go jakoś wystawić na świat. Zatem przejdziemy sobie w kolejnym zjeździe do pojęcia konteneryzacji i tutaj bęðziemy w pełni wykorzystywać i uczyć się technologii Dockera. Standardowe komponenty to oczywiście: poznamy komendy, czym są warstwy, jak docker cacheuje podczas budowy, Dockerfile, CMD vs. ENTRYPOINT - na czym strasznie dużo osób odpada na rozmowach rekrutacyjnych a to podstawowa rzecz. Będzie też Docker-compose, chociaż w mniejszym stopniu, bo na produkcji nie jest wykorzystywany, aczkolwiek można wykorzystać go do przetestowania naszych aplikacji czy w ogóle będą w stanie się miedzy sobą komunikować. Będą też kwestie sieciowe, czyli jak dwa dockery mogą się ze sobą zkomunikować - to będzie potrzebne zarówno w Docker-compose jak i przede wszystkim do Kubernetesa, w kolejnym zjeździe. Ale zobaczycie, że te kwestie sieciowe będą proste, po tym co nauczycie się na zjeździe poświęconym Fast API. Dlaczego kwestie sieciowe? No dlatego, że tak jak wspominałem, musicie rozumieć jak to w ogóle działa i jak dochodzi do komunikacji pomiędzy Wami a serwisem z modelem. No i z bardziej zaawnsowanych rzeczy to: problemy z kontenerami MLowym czyli przedewszystkim ich gargantuiczne rozmiary, które bezpośrednio przekłądają się na koszty oraz autoscalowanie, o czym będzie na zjeździe poświęconym Kubernetesowi. I jak sobie z nimi walczyć: czyli poznamy to jak odpowiednio budować Dockerfile, powiemy sobie o bardzo zaawansowanej rzeczy jak multi-stage building ale wysoce skutecznej jeśli chodzi o redukowanie rozmiarów obrazu. Smoke testy - czyli czy w ogóle to co mamy w konterze działa, no i na koniec wisienka: czyli kiedy nie potrzebujesz konteneryzacji?
6. Potem czas na Kubernetesa. Czyli przez cały weekend zamienimy się w tzw. "YAML Developerów" - sami zobaczycie. Oczywiście bęðiemy omawiać wszelkie elementy tej technologii, Pod, Deployment, Service itd. itd. nie chce Was zanudzać tym bo jeszcze nigdy nie mieliście z tym styczności. Oczywiście kwestie sieciowe, czyli o komunikacji wewnątrz klastra - no i najważniejsze tematy czyli Proxy i NAT. Natomiast z najciekawszych rzeczy, to temat autoskalowania naszych serwisów, czyli dostosowywanie ilości instancji naszych serwisów API do ich wykorzystania. Tutaj bedziemy mówili o różnych metrykach, które mogą posłużyć do decydowania o tym ile ich powinno być i tutaj też przeprowadzimy testy obciążeniowe naszej aplikacji na szeroką skalę. Czyli wrócimy do tego co poznaliśmy w ten weekend na temat testów obciążeniowych, natomiast w tym zjeździe po prostu zobaczymy na własne oczy jak Kubernetes będzie starał się dostosować do wzmożonego ruchu naszej aplikacji, tak aby wszyscy zainteresowani mogli skorzystać z modelu.
7. I ostatni zjazd poświęcony automatyzacji wszystkiego - czyli pipeline CI/CD, które wraz z kolejną zmianą w naszym kodzie, wraz z pushem do repo będą budowały nowy kontener z nową wersją naszego API, uruchamiały wszystkie testy, jeśli przejdą pomyślnie to wystawiały na Kubernetesa itp. Ale oprócz samego pipelineu wdrożeniowego, będzie również pipeline MLowy, który zautomatyzuje nam stworzenie modelu - od pobrania danych, po nauke, po optymalizację, po zapisanie do jakiegoś storage itd. i to też będzie można wpiąc w pipeline CICD. Czyli tutaj będziemy automatyzować zautomatyzować prawie wszystkie, ale niestety ale w pewnym obszarach jednak człowiek jest wymagany, o czym bede wspominał.
8. To jest tyle co chciałem powiedzieć, na razie ogólnie - szczegółowo bęðziemy mówić sobie o nich na konkretnych zjazdach.