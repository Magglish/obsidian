1. Chciałbym Wam przedstawić po krótce co będziemy omawiać na tych 4 zjazdach i trochę przedstawić konteksty dlaczego akurat to. Teraz będzie ogólniej, natomiast na początku każdego zjazdu pokaże więcej szczegółow odnośnie danego zjazdu.
2. Jak widzicie mamy 4 zjazdy: pierwszy z nich, na którym obecnie jesteśmy jest to zjazd poświęcony stworzenia serwisu API dla naszego modelu. Czym jest serwis, czym jest API i wszelkie takie magiczne słowa jeśli ktokolwiek z tym spotyka się po raz pierwszy oczywiście będzie później wyjaśnione w trakcie zjazdu. Następnie mamy zjazd poświecony konteneryzacji i technologii Docker. Trzeci zjazd, mój ulubiony, poświęcony całkowicie klastrom zarządzanym przez Kubernetesa. No i na końcu mamy wisienkę na torcie czyli CICD, które krótko mówiąc będzie spajało wszystko co robimy na zjazdach 1-3 z deploymenty w pewien pipeline/potok, w pełniu zautomatyzowany i będzie działą się w nim cała magia - co zobaczycie na tym zjeździe. Spójrzmy sobie troche na to co będziemy robić na poszczególnych zjazdach, ale na razie ogólnie.
3. Na każdy zjazd przewidziany jest weekend, 16 godzin. Czy to dużo czy mało? Trudno mi ocenić. Powiem Wam szczerze, że ja cały czas w trakcie pracy odkrywam kolejne niuanse, kruczki czy to w trakcie projektowania API, czy wystawianiu kontenerów, czy deployowaniu modeli na klastrze, czy budowaniu automatycznych pipelineów. I tak każdy z Was będzie miał - te frameworki się non stop rozwijają, pojawiają się nowe problemy, a jak nie nowe problemy to ktoś wymyśla lepszy sposób na rozwiązanie starego problemu, zatem nie ma nudy. Natomiast, z racji tego, że mamy po 16 godzin na moduły i to, że macie już za sobą doświadczenie zawodowe, dzięki temu te prostsze tematy będą dla Was łatwiej i szybciej przyswajalne. Dzięki temu oprócz idei/zagadnień fundamentalnych bedziemy również poruszać zagadnienia bardziej zaawansowane, trudniejsze i po prostu wyciągnięte z produkcji, problemy z którymi będziecie się napotykać, wraz z rozwiązaniami. 
4. Zaczniemy od początku, czyli udostępnieniu naszego modelu w sieci. Powiem Wam też jak oczywiście inaczej można model udostępnić, ale w rzeczywistości spotkacie się praktycznie w 90% przypadków z REST API. Powiem też oczywiście jakie są inne rodzaje API, ale jako ciekawostke, bo są rzadko spotykane. Z rzeczy podstawowych to oczywiście bęðziemy implementować nasze API do modelu, zatem poznacie wszelkie rodzaje endpointów, które wykorzystacie w projektowaniu. Powiemy sobie o dokumentacji naszej aplikacji, czym jest te słówko REST i jakie to ma komplikacje - wszystko to co o API powinniście wiedzieć. Oprócz tego poruszymy także zagadnienia znacznie bardziej zaawansowane, bo nie bęðziemy budować tutaj aplikacji hello-world tylko podejdziemy do tematu poważnie. Powiemy sobie o logowaniu aktywności API, o middleware, czyli czymś pomiędzy naszymi endpointami a klientem który korzysta z naszego modelu, powiemy sobie o zabezpieczeniu API przed dostępem z zewnątrz, obsługa wyjątków, o bebechach FastAPI - jak wygląda w ogóle przetwarzanie zapytań do naszego modelu, co jest bardzo istotne. Powiemy również o asynchroniczności co będzie tematem dla Was trudnym, bo tak na prawde jeśli zapytamy Data Scientista o przetwarzanie równoległe, to pomyśli on o multiprocessingu, czyli przetwarzaniu na wielu procesorach jednocześnie. I to jest zrozumiałem, bo my możemy bardzo łatwo to użyć, scikit-learn daje parametr n_jobs podczas uczenia modeli. Podczas optymalizacji hiperapametrów głupio jest uruchamiać optymalizacje na jednym procesorze. Natomiast jeśli zapytamy Backend czy Frontend developera to o przetwarzaniu równoległym myśli bardziej w kontekście przetwarzania wielowątkowego, czyli multithreading. Tutaj powiemy sobie o tym dokładnie, ponieważ w Fast API można zrobić to i tak, i tak, czyli zastosować i wielowątkowość i wieloprocesorowość. A jeszcze można zrobić to jednocześnie. Tylko pytanie powstaje - kiedy co stosować? No i jak? Powiemy sobie również o testowaniu, bardzo istotnej rzeczy przy tworzeniu wszelkiego rodzaju software, ale o testowaniu w 3 wymiarach: oprócz testowania samej poprawności implementacji, będziemy również testować... dokumentację, czyli tzw. testy kontraktowe. To będzie ciekawe. No i najważniejsze w serwisach opartych o ML - testy obciążeniowe. Jak szybko przetwarzamy nasze zapytania, przy różnych scenariuszach. To też będzie dla Was bardzo ciekawe, ponieważ będziemy generować sobie hipotetycznych użytkowników, którzy korzystać będą z naszego API i patrzyć czy nasze API jest w stanie obsłużyć duży ruch. Ale oprócz samych takich rzeczy w kodzie będziemy również mówić o tym jak komunikują się ze sobą dwa różne systemy w sieci. Wiecie dlaczego? Dlatego, że nie chciałbym żebyście wyszli stąd z wiedzą tylko o tym, jak dobrze stworzyć serwis do modelu. Chciałbym żebyście wiedzieli jak w ogóle wygląda komunikacja pomiędzy chociażby moim laptopem a waszym serwisem który bęðzie sobie działał w chmurze. Czyli omówimy sobie czym jest protokół do komunikacji w sieci - HTTP. Czym są te ciasteczka, nagłówki, requesty, czyli żądania, response czy odpowiedzi, czym jest Port, w ogóle z czego skłąda się URL, czym jest DNS i wiele innych rzeczy. Dodatkowo poznacie też komendy w bashu które pozwolą Wam zobaczyć jak ruch wygląda między waszym laptopem a serwisem. Dlaczego jest to omawiane? Dlatego, że bardzo często jest tak, że to że Wasz serwis nie działą nie oznacza, że macie problem w kodzie. Problem może być w sieci. Oczywiście my jako Data Scientisci, Machine Learning Engineerowie czy Inżynierowie AI nie bęðziemy ekspertami od spraw sieciowych - broń boże. Natomiast podstawowy wachlarz umiejętnosci i zrozumienia jest wymagany. Chociażby z tego powodu, że gdy bęðziecie rozmawiać z np. DevOpsem albo Administratorem Systemu, który bęðzie Was wspierał w ustawianiu konfiguracji sieciowych to będziemy mogli z nim rozmawiać i rozumieć się nawzajem i nie padniecie na prostym pytaniu: na jakim porcie słucha Twój serwis? 
5. Jak już mamy serwis to fajnie byłoby go jakoś wystawić na świat. Zatem przejdziemy sobie w kolejnym zjeździe do pojęcia konteneryzacji i tutaj bęðziemy w pełni wykorzystywać i uczyć się technologii Dockera. Standardowe komponenty to oczywiście: poznamy komendy, czym są warstwy, jak docker cacheuje podczas budo