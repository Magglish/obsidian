# Logowanie

1. Słuchajcie, przechodzimy teraz do bardzo ważnego tematu jakim jest logowanie. Czym jest logowanie? To każdy z Was myślę, że wie, więc jednym zdaniem można to ująć jako: zapisywanie wszelkich zdarzeń zachodzących w aplikacji.
2. Moim zdaniem istnieją dwie rzeczy, bez których nawet prosty projekt, czy Proof of Concept po 3/6 miesiącach nie może wejść na produkcję:
	1. Logi - o czym teraz będziemy o tym rozmawiać
	2. Testy - o czym będziemy rozmawiać później
3. Część z Was może jeszcze pomyśleć o monitoringu, jako o trzecim elemencie niezbędnym - tutaj nie jestem przekonany czy jest to niezbędny element. To zależy też oczywiście od stadium rozwoju aplikacji - jeżeli jest to początek, to moim zdaniem może jeszcze wejść jeszcze bez monitoringu, bo często monitoring oprócz takich fundamentalnych, podstawowych metryk musi też monitorować "specyficzne" metryki dla danego API, które po pierwszych iteracjach dopiero będą znane. Później jak już aplikacja jest bardziej dojrzała to oczywiście monitoring musi być. Natomiast mówiąc o takich niezbędnych elementach - niezależnie od tego w jakim jest stadium, czy to sam początek, czy już coś bardziej rozwiniętego, to jednak logowanie i testy jest must-have. Ja osobiście nie wdrażam nic na produkcję bez tych dwóch rzeczy - nie ma opcji.
4. Dlaczego? Dlatego, że naprawa bugów i debugowanie czegoś bez tych dwóch rzeczy to ISTNY KOSZMAR, zajmujący strasznie dużo czasu. Ja wole sobie tego zaoszczędzić.
5. Teraz porozmawiamy sobie o logowaniu w API. Od razu na wstępie powiem tak: 
	1. Pierwsza sprawa najważniejsza moim zdaniem -  chciałbym na tym zjeździe przekazać Wam najważniejsze punkty - ideę logowania: chciałbym żebyśmy mogli odpowiedzieć sobie na pytanie: KIEDY logować? CO logować? jak POWIĄZAĆ logi? Nie będziemy omawiać tutaj jak zbudowana jest pythonowa biblioteka logging i jak definiować w niej te wszystkie formattery, filtery itd. Nie nie. Chce się skupić na najważniejszych punktach - idei logowania. A to jaką bibliotekę finalnie użyjecie, to będzie to Wasza indywidualna preferencja. Z tym powiązaniem chodzi o to, że każdy log to będzie oddzielny wpis. Biorać pod uwagę fakt, że Wasze API będzie działało na wielu instancjach a zapytań wykonywach będzie wiele, to sami się przekonacie, że ilość logów jest ogromna. Zatem trzecie pytanie dotyczy w sumie jak się połapać w gąszczu tych wszystkich logów. O samym logowaniu można naprawdę pisać i wygłaszać elaboraty. Jak sobie sami spojrzycie np. w dyskusje na Stackoverflow oraz na Reddicie, każdy ma swoje zdanie na ten temat, są różne punkty widzenia. Ja przedstawie Wam tą wiedzę jaką zebrałem na bazie swojego doświadczenia + wzbogaconą o mieszanką wiedzy i doświadczeń innych developerów, czy to w trakcie rozmów czy właśnie analizy dyskusji na różnych forach. Najważniejsze moim zdaniem w logowaniu jest to, żeby Wam pomogło to w pracy - więc jeżeli będziecie uważać, że pewne rzeczy zrobilibyście inaczej i uważacie, że Wam się to lepiej sprawdzi - to jest ok, to to zróbcie.
	2. Druga sprawa - do logowania jest sporo bibliotek, znacznie lepszych niż zbudowany w pythonie moduł `logging`, który ma swoje wady - jedną z nich jest jego troche dziwna konfiguracja, przez co nie jest łatwa. Jest to bardzo stary moduł. Tych bibliotek jest sporo, ale moim zdaniem na największą uwagę zasługuje [logguru](https://github.com/Delgan/loguru) który znacznie upraszcza korzystanie z podstawowego `loggingu` oraz [structlog](https://www.structlog.org/en/stable/why.html), który skupia się na tworzeniu logów w formacie JSON. Niemniej jednak, każdy z nich korzysta pod spodem z pythonowego, podstawowego `logging`, więc warto poznać najpierw tą podstawową bibliotekę. Ja na naszym zjeździe zostanę przy podstawowym pythonowym `logging`-u - nie chce Wam wprowadzać nowych bilbiotek, które są kolejną warstwą nałożoną na podstawowy `logging`. I tak jak mówiłem, chce Wam przekazać ideę logowania - później w trakcie swojej pracy jak już oswoicie się z logowaniem to zdecydujecie, którą ostatecznie bibliotekę chcecie wykorzystywać.
	4. Trzecia sprawa - w sieci znajdziecie wiele różnych implementacji jak logować pewne zdarzenia. Bardzo często spotykanym patternem w temacie logowania jest decorator i przykładów decoratorów znajdziecie wiele - np. [ten](https://ankitbko.github.io/blog/2021/04/logging-in-python/). On jest wielki i troche brzydki - na pewno można go zapisać lepiej. Nie mniej jednak one będą tak wyglądać - jeżeli będziecie chcieli zrobić decorator, który będzie służył Wam zawsze i wszędzie, aby logował Wam to co chcecie, to będzie on skomplikowany. Ja Wam powiem z własnego doświadczenia, że... bawiłem się takimi decoratorami, które mogłyby logować wszystko co chce... i w moim przypadku się to nie sprawdza. Do logowania prostych funkcji tak, ale z bardziej skomplikowaną logiką już nie. Zawsze powstawał mi taki kolos, który ciężko było utrzymać i rozwijać gdy pojawiały się jakieś funkcje, które wyjątkowo inaczej musiałem zlogować. Ja porzuciłem ten pomysł i robie to prosto... po prostu dodając logowanie jako kolejne linijki kodu. Jeżeli natomiast Wy macie lepsze doświadczenia z tym związane i uważacie decoratory za fajny pattern do użycia w logowaniu i Wam się sprawdza... to jak najbardziej z tego korzystajcie. Natomiast ja nie będę ich używał na naszym zjeździe - pójdę w prostotę.


Ok to zacznijmy od początku:

### Kiedy warto logować? 

Generalnie sprawa z pytaniem KIEDY warto logować jest stosunkowo prosta:

1. Na początku wywołania funkcji - aby mieć informacje zwrotną, że faktycznie rozpoczęło się jej wykonanie
2. Oraz na końcu wywołania funkcji - aby mieć informację zwrotną, że faktycznie funkcja zakończyła się. Z logowaniem na końcu funkcji jest jeszcze jedna istotna właściwość - oznacza to, że funkcja wykonała się prawidłowo. 
3. Natomiast jeżeli istnieje jakiś element w środku wywołania funkcji, który naszym zdaniem jest istotny i warto wiedzieć, że coś się wtedy zadziało, to także warto to logować.
4. I oczywista, oczywistość - logowanie każdego wyjątku/błędu, który wystąpi w funkcji - to jest najważniejsze.

Dodajmy sobie pierwsze logi do naszego API. Wróćmy do `main.py` i spójrzmy jak wygląda wywołanie kodu.

Dodajmy do maina taki kawałek kody:

```python
import logging  
from src.utils.logging import setup_logging  
```

A następnie na samym początku skryptu dodajmy:

```python
setup_logging()
```
Powiem później co to robi.

Mamy wywołanie `app = FastAPI()` - czy tutaj można dodać logi? Można. Ale zajmiemy się tym na końcu.

Dalej mamy wywołanie naszego modelu `model = CreditScoringModel(path=Path("models/classifier.pkl"))`.  Czy mamy tutaj logi? Nie mamy. Czy według nas jest to istotna rzecz, żeby zlogować? Moim zdaniem tak. Model w API to podstawowy komponent działania naszego modelu, jeżeli nie moglibyśmy go załadować, to chcielibyśmy wiedzieć dlaczego.

W takim razie dodajmy sobie logowanie do naszego modelu.
Zaimportujmy sobie moduł `logging`

```python
import logging
```

I do ładowania modelu dodajmy sobie logowanie:

Tak jak wspominałem: ważny jest początek i koniec. Zatem:

```python
logging.info(f"Loading Credit Scoring Model from {path} location")
```

Na początku wywołania funkcji. Oraz:

```python
logging.info(f"Successfully loaded Credit Scoring Model")
```
Na końcu wywołania funkcji. Jeżeli logowania dojdzie do tego momentu, mamy również gwarancję tego, że bez problemu udało się nam załadować model. 

Dodatkowo wspomniałem o tym, że istotne jest również zastanowienie się czy w środku wywołania funkcji, innymi słowy pomiędzy startem logowania i końcem logowania jest coś istotnego. W tym przypadku oczywiście, że jest - sam proces załadowania obiektu. Co się może tutaj zdarzyć? Oczywiście fakt taki, że dany obiekt nie istnieje i to jest ten istotny element, o którym warto byłoby wiedzieć. W przypadku braku obiektu dostaniemy błąd, więc musimy go sobie zlogować: Zatem dodajmy sobie

```python
try:  
    with path.open(mode="rb") as file:  
        model = pickle.load(file)  
except FileNotFoundError as e:  
    logger.exception(f"Credit Scoring Model not found.")  
    raise e
```
Teraz ktoś z Was może się zastanowić po co dodajemy do kodu takiego try excepta i logging.exception, skoro w Pythonie gdy pojawi się błąd to otrzymamy w konsoli jego treść? 

Zobaczmy na przykładzie: w `main.py` popsujmy lokalizacje naszego modelu i zobaczmy co otrzymamy. Jak widzicie pojawił się log:

```
Credit Scoring Model not found in models/classifier.pklxxx location.
```

I wraz z nim jest Traceback. `logging.exception` działa tak, że jeżeli zawrzemy go w klauzuli `try except` to domyślnie dołączony będzie traceback z błędem.

Ale zobaczcie co jest na dole: Znowu jest traceback... Czyli widzicie, informacja jest jakby powielona. Ten drugi błąd wynika, z tego, że tak działa pythonowy interpreter, który będzie printował nam w konsoli błąd jeżeli taki napotkamy. No właśnie i teraz powtarzając pytanie - ktoś z Was może się zastanowić po co dodajemy do kodu takiego try excepta i logging.exception, skoro w Pythonie gdy pojawi się błąd to otrzymamy w konsoli jego treść? Powody są dwa:
1. Na produkcji nie będziecie mieli takiej konsoli, która Wam printuje to na żywo. Logi będą wysyłane gdzieś do jakiegoś systemu - Google Cloudzie jest to Stackdriver, na AWS jest to CloudWatch, na Azurze jest to Azure Logs Monitor, jeśli będzie Wasze API stało na jakimś systemie on-premise to na pewno będzie jakiś serwis z logami. Biblioteki, które będą wysyłały logi do tych usług będą zintegrowane z podstawowym pythonowym `logging`, więc użycie ich będzie bardzo proste i bardzo często nawet nie będziecie musieli zmieniać swojego kodu.
2. Ten traceback, który teraz zaznaczam i który został wyprintowany przez pythonowy interpreter - nie macie żadnej gwarancji, że on zostanie wysłany do tego systemu obsługujący logi. Tak może być, ale nie musi. Np. na Google Cloudzie tak jest, że to co wyprinuje pythonowy interpreter to pojawi sie tam w logach, ale problem jest taki, że będzie to bardzo źle sformatowane i nie do przeczytania. Natomiast to co teraz zaznaczam, będzie JEDNYM wpisem w waszym systemie do analizy logów i będzie on poprawnie sformatowany. 
Więc najlepiej jest przyjąć takie założenie: na produkcji będziecie widzieć tylko to co sami sobie zlogowaliście - nic więcej. 

Teraz ktoś z Was może sobie zadać pytanie: A co jeżeli wystąpi tutaj inny błąd niż `FileNotFoundError`, jak powinniśmy ten błąd obsłużyć? To jest bardzo dobre pytanie. Generalnie obsługujemy te błędy, których się spodziewamy z samego działania kodu - zobaczcie, ja tutaj mam `pickle.load(...)` ja wiem co ta funkcja ma zrobić - wczytać plik, więc spodziewam się, że jak tego pliku nie będzie to po prostu rzuci wyjątkiem `FileNotFoundError` dlatego go wyłapałem i zlogowałem. A co jeżeli sam `pickle.load` rzuci w sobie jakiś błąd - dajmy na to ktoś spartolił implementacje tej metody i np. dostaliśmy błąd `AttributeError` - czy powinniśmy to zlogować? Oczywiście, że tak. Ale jak? Sposób jaki może przychodzić do głowy to to aby zastąpić `FileNotFoundError` najbardziej szerokim wyjątkiem czyli `Exception`. To jest jakieś rozwiązanie, ale jest to generalnie uznawane za bad practise. Dlaczego? Dlatego, że w takim przypadku Wasze logi będą nieprecyzyjne - każdy błąd który wystąpi w kodzie odpowiedzialnym za wczytanie modelu będzie traktowany tak samo, z tą samą treścią. I za każdym razem będziecie otrzymywać to samą wiadomość - niezależnie od tego czy faktycznie model jest w tej lokalizacji czy np. właśnie w `pickle.load(...)` jest jakiś bug. 
Ok, to ktoś może teraz pomyśleć - to może napiszmy ten log tak bardziej ogólnie, nie logujmy `Credit Scoring Model not found in {path} location.`, tylko np. napiszmy "Theres a problem with loading scoring models: {path=}.". To powiem Wam od razu, że takie generalne logi nie powiedzą Wam nic. Logi muszą być precyzyjne, zawierać w sobie wszelkie niezbędne informacje żebyście nie mieli żadnych wątpliwości co się zadziało, one mają Wam pomóc w Waszej pracy - natomiast takie generalne logi i łapanie szerokich wyjątków są niezbyt precyzyjne i w efekcie nie dadzą Wam żadnych korzyści. 

Wróćmy zatem do `FileNotFoundError` oraz do treści jaka była. Ok to co w sytuacji kiedy kod będzie rzucał więcej wyjątków niż jeden? To wtedy tych `exceptów` oraz `logging.exception` w naszym kodzie będzie znacznie więcej, tyle aby móc spokojnie te błędy obsłużyć i je odpowiednio zlogować. 

Ok ale co z błędami których w `exceptach` nie będzie, jak je wyłapać? To Wam pokaże później, FastAPI dostarcza nam bardzo fajne mechanizmy aby móc się zabezpieczyć przed takimi caseami.

Wróćmy do `main.py` i obsłużmy sobie jeszcze połączenia z bazami danych. Połączenia z bazami danych też są istotne, bo Redis przyśpiesza nam działanie naszego API a Postgres pozwala nam na zapisanie inputów i outputów z API, które potem stanowić będą baze do monitoringu.

W kodzie na redis w metodzie `_create_connection` brakuje sprawdzenia, czy udało nam się z tym Redisem połączyć. Akurat biblioteka do Redisa nie sprawdza połączenia z baza w momencie tworzenia tego połączenia, trzeba ją pingnąć:

Importujemy logging
```python
import logging
```
I dodajmy logowanie:

```python
logging.info(f"Creating connection to Redis database on {host=}, {port=}.")  
try:  
    connection = redis.Redis(host=host, port=port)  
    connection.ping()  
except redis.exceptions.ConnectionError as e:  
    logging.exception(f"Unable to connect to Redis database.")  
    raise e  
logging.info(f"Successfully created connection to Redis database.")  
return connection
```

Został nam jeszcze postgres. 

Zaimportujmy logging a następnie w metodzie `_create_connection` dodajmy logowanie:

```python
logging.info(f"Creating connection to Postgres database on  {database=}, {user=}, {host=}, {port=}.")  
try:  
    connection = psycopg2.connect(  
        database=database,  
        user=user,  
        password=password,  
        host=host,  
        port=port,  
    )except psycopg2.OperationalError as e:  
    logging.exception(f"Unable to connect to Redis database.")  
    raise e  
logging.info("Successfully created connection to Postgres database.")  
return connection
```

W postgresie tworzony jest jeszcze cursor i tam też warto byłoby dodać logi... ale słuchajcie... umówmy się, że na potrzeby naszego spotkania nie będziemy dodawać logowania wszędzie OK? Zaraz oczywiście powiemy sobie CO warto logować. Natomiast nie chce dodawać logów wszędzie, bo spędzimy na tym za dużo czasu i spotkanie dobiegnie końca a jest wiele rzeczy jeszcze do omówienia. Aczkolwiek troche logów musimy dodać żebyśmy mieli w ogóle co analizować. Więc w przypadku Postgresa zostane na razie przy samym połączeniu, bez cursora.

I teraz ubijmy sobie `redis`a i `postgres`a -> znajdźmy je `docker ps` i zabijmy `docker kill <<PIERWSZE_ZNAKI_CONTAINER_ID>>` i sprawdźmy czy działa.

Pierwszy błąd powinien być związany z połączeniem z Redisem. Dobra to teraz stwórzmy go `make redis`. Spróbujmy jeszcze raz. Teraz wywaliło się na `Postgresie`. A teraz powinno zadziałać. Dobra, to było szybkie sprawdzenie czy faktycznie nasze logowanie zadziałało. 

**Pytanie**: Dlaczego zwykłe printy nie zadziałają?
Powodów jest wiele:
Odp: 
1. Formatowanie będzie kiepskie - np. logging.exception ma w sobie to aby sformatować cały traceback razem z nowymi liniami, znakami tabulacji itd.
2. Biblioteki do logowania pozwolą Ci na stworzenie struktury - np. JSON, który później łatwiej jest 
3. Jeżeli masz strukture JSONa to można łatwo dodać wszelkie metadane pozwalające na jeszcze łatwiejsze zdebugowanie kodu
5. Printy piszą do konsoli, która na produkcji nie zawsze może być dostępna
6. Logging pozwala Ci na definiowanie poziomu logów - DEBUG, INFO, WARNING, ERROR itd.
7. I najwazniejsz argument - na produkcji logi będą wysyłane do jakiegoś systemu: np. na Google Cloudzie jest to Stackdriver, na AWS jest to CloudWatch itd. I biblioteki, które wysyłają logi do tych usług są zintegrowane z podstawowym modułem `logging`, ale nie ze zwykłymi `print`
8. Prawdę powiedziawszy, gdybyś się uparł to mógłbyś napisać swój własny kod do logowania oparty o printy, pewnie byłoby to trudne ale możliwe - ale po co implementować koło na nowo? 


Ok to podsumowując wariant KIEDY:

1. Początek wywołania funkcji - informacja, że działanie się rozpoczęło
2. Koniec wywołania funkcji - informacja, że się zakończyło ORAZ że działanie zakończyło się sukcesem
3. W istotnych elementach działania naszego kodu - na pewno logowanie wyjątków oraz opcjonalnie, jeśli uznamy to za istotne, informacja, że do danego etapu działani funkcji doszliśmy. Akurat w tym repo nie ma żadnych kodów robiących coś skomplikowanego, więc logowanie przeważnie będzie takie jak tutaj widzicie. 

### Co warto logować?

Teraz drugie ważne pytanie - CO warto logować? Tutaj odpowiedź jest już znacznie trudniejsza niż w przypadku KIEDY. Dlaczego? Dlatego, że nie ma generalnych zasad co warto logować, a co nie - to wszystko zależy od inżyniera i to jaką aplikację stworzył. 
Odpowiedź na CO logować jest moim zdaniem odpowiedzią mocno subiektywną. Dlaczego? Ponieważ logi, które dodajecie są dla WAS i mają pomóc Wam w waszej pracy i naprawianiu ewentualnych błędów jeśli wystąpią. Na pytanie CO warto logować można pomóc sobie odpowiadając na przykładowe pytania:
1. CO pozwoli mi naprawić ewentualne błędy? 
2. CO moim zdaniem jest istotne dla mnie abym wiedział? 
3. CZEGO w ogóle nie potrzebuję? 

Jeżeli uznacie, że jakiś element pozwoli Wam na łatwiejsze debugowanie, naprawianie błędów, po prostu informacja ta pozwoli Wam lepiej pracować, czy nawet spać - to ją zlogujcie. 

Jeśli chodzi o mnie - ja jestem osobą, która bardzo dużo rzeczy loguje, dlatego, że kieruje się zasadą, że logi mają być jak dobrze opowiedziana historia. Ma mieć początek, ma mieć wstęp, ma mieć rozwinięcie i, mam nadzieję, dobre zakończenie. Jedyne co mnie ogranicza w dodawaniu logów to fakt, że analiza logów np. na usługach w chmurze może Was kosztować jakieś pieniądze - więc pomimo moich chęci logowania dużo, staram się jednak ograniczać logi w takim zakresie, aby po prostu nie narażać firmy na niewiadomo jakie koszta, bo Marcinowi zachciało się poczytać historie logów. 

Czasami spotykam się z opiniami, że takie podejście, czyli logowania dużo, może wprowadzić szum w logach i może być logowanych tam za dużo informacji, które ostatecznie mogą się nie przydać. Cały czas nie zgadzam się z tą opinią - wychodzę z założenia, że jeżeli developer uważa informacje za istotną dla niego, która pozwoli mu spokojnie pracować i debugować, to to nie jest szum. Tym bardziej, że ja jeszcze mam trochę niepopularną opinie na temat tego jaki poziom logów ustawiać na produkcji - ale o tym zaraz.

Ok, ale wróćmy do naszego `main.py` - mamy na razie logi na poziomie naszego modelu, oraz połączeń z bazami danych. Czyli mamy te 3 linijki, które zaznaczyłem.
Teraz pytanie, a co z tymi naszymi klientami Redisowymi i Postgresowymi? Czy My też powinniśmy to zlogować? I to jest właśnie ten moment odpowiedzi na pytanie CO logujemy? Czy to co tam się dzieje w tych funkcjach jest dla nas istotne, aby ułatwić nam później debugowanie? Spójrzmy na inicjalizacje tych klas. Weźmy `DecisionRedisClient`. Dziedziczy po `BaseRedisClient` to przejdźmy tam dalej. Zobaczmy na inita: tak na prawdę, jedyne co tutaj się dzieje to zapisanie connectora w atrybutach danej klasy. Czy to jest potrzebne aby to zlogować? Moim zdaniem nie - to jest tylko przypisanie obiektu do danego atrybutu. Ta informacja akurat mi w niczym nie pomoże w przyszłości. Tymbardziej, że w naszym `RedisConnector`-ze mamy już zdefiniowane logowanie, zatem jeżeli `RedisConnector` nie zadziała, to nie zadziała również wszystkie `RedisClient`. Czyli stwierdzamy na tej podstawie, że logowanie tutaj jest niepotrzebne.

Wracamy do `main.py`... i od razu Wam powiem, że w przypadku klientów Postgresowych jest identycznie jak teraz z Redisem. Tam logowanie w inicie jest niepotrzebne. Ok czyli mamy załatwione inicjalizację naszych głównych obiektów, które służą nam do działania naszego API. 

Zatem teraz musimy przejść do naszego endpointa i zacznijmy dodawanie logów aby zobaczyć co się w nim dzieje. 

Kiedy logujemy? Na początku i na końcu:

```python
@app.post("/decisions")  
async def decisions(  
    request: DecisionRequest,  
    background_tasks: BackgroundTasks,  
) -> DecisionResponse:  
    logging.info(f"Received {request=}")  
	...
	...
	... 
	logging.info(f"Returning {response=}")
    return response
```

Teraz w endpoincie dużo się dzieje - chcielibyśmy mieć informacje o tym.

Dodajmy logi do Redisa w metodzie `read`:

```python
logging.info(f"Getting response from Redis for {request=}")  
key = self._create_key(request)  
value = self.connector.connection.get(key)  
if value:  
    response = self._create_response(value)  
    logging.info(f"Returning response from Redis {response=}")  
    return response  
else:  
    logging.info("Response not available in Redis")  
    return None
```

oraz w metodzie `write`:

```python
logging.info(f"Saving {response=} for {request=} to Redis")  
key = self._create_key(request)  
value = self._create_value(response)  
self.connector.connection.set(key, value)  
logging.info(f"Successfully saved response in Redis")
```

Dodamy sobie logi jeszcze w pozostałych etapach. Zależy mi na tym żebyśmy widzieli troche tych logów, bo potem jak przejdziemy do etapu pozwiązywania logów, to chciałbym żebyśmy mieli co analizować.

Zróbmy to też w Postgresowym kliencie - przejdźmy do `DecisionPostgresClient`, a potem do `BasePostgresClient` po którym dziedziczy i dodajmy logi tylko w metodzie `write`, bo ona obecnie w API jest tylko używana.

```python
logging.info(f"Writing {request=} and {response=} to Postgres database")  
query = self._prepare_insert_query(request, response)  
data = self._prepare_insert_data(request, response)  
self.connector.cursor.execute(query, data)  
self.connector.connection.commit()  
logging.info(f"Successfully written request and response to Postgres database")
```

Przejdźmy teraz do metody `predict_decision` i dodajmy tam logi:

```python
logging.info(f"Predicting decision for {features.to_dict()=}")  
probabilities = self.predict_proba(features)  
decision = [  
    Decision.ACCEPT if probability <= self.decision_threshold else Decision.DECLINE  
    for probability in probabilities  
]  
logging.info(f"Returning {decision=}")  
return decision
```

Zostały nam jeszcze background taski `write_to_redis` oraz `write_to_postgres` - to jest bardzo ważne żeby zlogować. Zobaczycie potem dlaczego.

`write_to_redis`:

```python
def write_to_redis(redis_client, request, response):  
    logging.info(f"Started background task to write to Redis for {request=} and {response=}")  
    redis_client.write(request, response)  
    logging.info(f"Successfuly ended background task to write to Redis.")
```

`write_to_postgres`:

```python
def write_to_postgres(postgres_client, request, response):  
    logging.info(f"Started background task to write to Postgres for {request=} and {response=}")  
    postgres_client.write(request, response)  
    logging.info(f"Successfuly ended background task to write to Postgres.")
```

Ok, mamy te logi które chciałem. Zobaczmy teraz jak to działa.

Uruchomimy API i zobaczmy co nam zwróci. 

(Omów to co widzimy w logach)

Czyli mamy całą historię działania naszego API w logach wraz z istotnymi danymi, które przydadzą się później na wypadek błędów i potrzeby debugowania. Te logi, jak widzicie, są dosyć spore - bo jest to zwykły tekst. Na samym końcu omawiania logowania powiem Wam jak można te logi usprawnić i czy w ogóle nie zmienić ich formy na coś bardziej przystępnego.

Ok dodaliśmy sobie logowanie do elementów, które są moim zdaniem na pewno są istotne w działaniu API. Jak spojrzymy sobie w logi to mamy informacje właśnie o tym jaki request przyszedł, jakie odpowiedzi zwracamy + dodatkowe logi z konkretnych funkcji, czy metod, które raportują to co robią i czy udaje im się to zrobić z sukcesem. Ale jeszcze tym logom trochę brakuje. Brakuje im istotnych metadanych abyśmy wiedzieli więcej o naszym API oraz mogli się połapać w tych logach.

Jest dużo dostępnych metadanych jakie możemy dodać do naszych logów, zaraz Wam pokaże co jest dostępne, natomiast w logach muszą znaleźć się na pewno dwa podstawowe metadane:

1. Rodzaj logów: czy mamy styczność ze zwykła informacją, czy może z ostrzeżeniem, czy może z błędem w naszej aplikacji
2. Oraz czas kiedy dane zdarzenie nastąpiło.

Bez tych dwóch rzeczy naprawdę analiza logów jest niemożliwa:

Wróćmy do początku `main.py` i zmieńmy import `setup_logging` na coś innego:

```python
from src.utils.logging import setup_logging_with_formatters

setup_logging_with_formatters()
```

Zresetujmy nasze API i zobaczmy co otrzymamy.

Widzimy, że mamy teraz dodatkowe informacje o czasie logów oraz o ich poziomie - w tym przypadku jest to INFO, bo skorzystaliśmy z `logging.info`. Wykonajmy request i zobaczmy teraz logi z działania endpointa. 

No teraz to już zdecydowanie lepiej wygląda i możemy analizować historię tego co się zadziało w naszym endpoincie.

Jest sporo metadanych jakie możemy dodać: (omów kruciutko)

https://docs.python.org/3/library/logging.html#logrecord-attributes

W zależności od tego co uznacie za istotne w waszym API, można te metadane dorzucić do logowania i one zawsze będą wypisywane z każdym logiem. Teraz jak te metadane są dodawane do logów? Tak jak mówiłem, nie chce omawiać dokładnie jak działa moduł `logging`, bo chce sie skupić maksymalnie na samej idei logowania, a nie na konkretnym narzędziu - ale krótko mówiąc, biblioteki do logowania dostarczają tzw. Formaterów, które odpowiednio zdefiniowane po prostu dodają metadane do każdego naszego logu, który wypisujemy. Niezależnie od tego jakie metadane wybierzecie, czas oraz rodzaj logu to dwie podstawowe, bez których analiza logów jest wręcz niemożliwa.

Teraz krótko o rodzajach logów. Tutaj nie będę się rozwodził na ten temat, bo każdy z Was na pewno je widział, czyli mamy 
1. `DEBUG` -  można to określić jako "niskopoziomowe" detale, które przydają się głównie podczas debugowania aplikacji - `logging.debug`
2. `INFO` - podstawowy poziom informujący o zdarzeniu/stanie naszej aplikacji - tak jak tutaj używaliśmy aby przekazać informacje, że rozpoczęło się przetwarzanie funkcji i zakończyło się sukcesem wraz z danymi wejściowymi i wyjściowymi - `logging.info`
3. `WARNING` -  poziom wyżej niż INFO, który informuje, że coś się zadziało w aplikacji co może nie do końca było spodziewane, albo spodziewamy się, że coś się może wydarzyć - w naszym mozna by było zrobić tak, że akceptujemy fakt, że bazy Redis nie ma i w momencie próby połączenia z Redisem i rzucienia wyjątkiem, my tak na prawdę nie zatrzymujemy API, tylko pozwalamy działać dalej i np. rzucamy sobie warningiem, że połączenie z Redisem było niemożliwe do nawiązania. Trzeba by też zrefactorować kod na read i write aby takie coś obsłużyć - nie mniej jednak brak Redisa mógłby być takim przypadkiem na warning, dlaczego? Dlatego, że bez niego nasze API działało by poprawnie, po prostu wszystkie requesty byłyby przetwarzane przez model. Oczywiście działałoby wolniej, ale wciąż mogłoby przyjmować requesty - `logging.warning`
4. `ERROR` - sprawa banalna - wszelkie wystąpienia błędów i wyjątków `logging.exception`
5. `CRITICAL` - rzadko używane, ale używane w kontekście naprawdę istotnych rzeczy w API jak np. autoryzacja do API nam padła i tak na prawdę nikt nie może z niego skorzystać. Albo nawet brak dostępnego modelu w API (czyli tam gdzie wczytujemy model) też może służyć nam jako coś krytycznego - brak w API jakiegoś istotnego elementu, jak w naszym przypadku modelu.

Najczęściej używane są oczywiście `INFO` oraz `ERROR` - natomiast nie zapomnijcie o pozostałych poziomach, jeżeli uznacie że informacja jest mniej istotna - wrzućcie ją do `DEBUG`, jeżeli są jakieś zachowania API o których powinniśmy być ostrzeżeni, ale nie przeszkadzają w działaniu API - użyjcie `WARNING`

I teraz porozmawiajmy sobie trochę o tym poziomie `DEBUG`. Jak poczytacie sobie w swojej wolnej chwili o poziomie `DEBUG` w logowaniu i to co inni developerzy sądzą o tym poziomie logowania, to często możecie spotkać się z dwoma informacjami na ten temat:

1. Że jest to najniższy poziom, w którym umieszczane są bardzo szczegółowe informację, które, jak sama nazwa może wskazywać, byłyby potrzebne w procesie debugowania.
2. I drugi punkt - że na produkcji nie powinny pojawiać się logi z poziomem `DEBUG` - w tym przypadku nie wiem czy wspomniałem wcześniej, ale w momencie ustawiania logowania można wskazać od jakiego poziomu logi będą pokazywane, więc tutaj nie chodzi o to, żeby w ogóle w kodzie nie pojawiały się żadne `logging.debug`.

Niestety ale nie do końca zgadzam się z drugim punktem. To co powiem jest moją prywatną opinią, ale chciałbym Wam przedstawić swój punkt widzenia, abyście mieli też inne spojrzenie i sami w swojej pracy zdecydowali się na to czy na produkcji umieszczać logi z poziomem `DEBUG`. Skąd wynika mój sceptycyzm co do drugiego punktu? Z powodu pewnego błędu, z którym napotkałem się w swojej codziennej pracy

![[GCP Unkown Error.png]]

To co widać na zdjęciu to treść błędu z jednego z naszych serwisów działających na produkcji na chmurze Google'a, która jak widzicie brzmi: "There was a problem opening a stream. Try turning on DEBUG level logs to see the error". I jeszcze bardzo ważne jest to, jaka biblioteka to rzuciła: `google.api_core`, która stanowi trzon wszystkich bibliotek Pythonowych, które pozwalają wam na interakcje z usługami w Google'u. Ten log który Wam pokazuje wystąpił wystąpił podczas zapisywania danych do BigQuery. Ale spotkałem się z nim jeszcze potem w kilku innych miejscach. Co możemy zrobić w takiej sytuacji? Błąd proponuje włączenie poziomu DEBUG, ale ja go na produkcji nie mam włączonego. Zatem jedyne co nam zostaje w takiej sytuacji to przeniesienie tego na środowisko developerskie i ustawienie tam sobie poziomu logowania na DEBZdeployowałem sobie tą implementację na środowisku DEVowym i zacząłem wysyłać do niego dane, ale nie udało mi się go w ogóle odtworzyć


Ok, podsumowując część CO logować: 
1. Logi mają Wam pomóc w naprawie błędów - jeżeli dane działanie funkcji/metody/kodu jest dla Was istotne i uważacie, że dzięki wiedzy o działaniu tego kawałka kodu będzie w stanie lepiej śledzić działanie Waszego API i naprawić ewentualne błędy, to jak najbardziej dodajcie logowanie tego miejsca. 
No dobrze... czy macie jakieś pytania do tej części, zanim przejdziemy dalej?



### Jak powiązać logi?


https://guicommits.com/how-to-log-in-python-like-a-pro/