# Protokół HTTP.

1. Wiem, że jest sporo teorii i troche mniej kodzenia, ale zapewniam Wam, że później się to zmieni. Na ten moment omawiamy fundamenty. Wiemy jakie mamy rodzaje endpointów, wiemy jak zdefiniować odpowiednie klasy w pydantic żeby móc przychodzące dane przetworzyć, wiemy też w jakim przypadku, które status codey zostaną zwrócone. Mamy podstawową wiedzę, natomiast żeby pójść dalej i implementować coraz bardziej skomplikowane rzeczy i przedewszystkim zrozumieć dlaczego to robimy w taki sposób. Musimy sobie omówić dwie najważniejsze rzeczy w całym naszym programie. Co to jest protokół HTTP, który służy do komunikacji pomiędzy dwoma serwisami, oraz co oznacza REST API... czyli te słówko REST, bo to ma bezpośrednie implikację na to jak implementujemy nasze API. Zatem żeby móc ruszyć dalej z kolejnymi implementacjami, musimy omówić te dwa zagadnienia - czym jest HTTP i czym jest REST.
2. Zacznijmy od początku - na pewno każdy z Was słyszał o skrócie HTTP - czyli Hypertext Transfer Protocol - jest to protokół, na którym bazuje cała komunikacja w internecie. 
3. Protokół HTTP istnieje od 1990 roku, czyli od momentu kiedy tak na prawdę istnieje World Wide Web, początkowo stworzony do odczytywania dokumentów HTML na stronach czyli właśnie Hypertext Markup Language. Ale od momentu jego powstania minęło już ponad 30 lat i przez ten czas ewoluował. Tak na prawdę mamy aż 4 rożne wersje HTTP - powiem o nich więcej później. Obecnie służy do wymiany danych pomiędzy dwoma obiektami w sieci i nie tylko już wymieniamy się samymi dokumentami HTML, ale również samym tekstem, zdjęciami, video, skryptami itd.
4. HTTP jest bardzo prostym protokołem - opiera się o żądania (requesty), czyli np. prośby pobranie danego zasobu, wysłanie danych i przetworzenie ich np. wykonanie predykcji, czy stworzenie nowego rekordu w bazie i odpowiedzi (response), które zwracają informację zwrotną czy dana operacja, opisana w żądaniu się wykonała i z jakim skutkiem. Czyli to co właśnie do tej pory analizowaliśmy i zaimplementowaliśmy - naszym żądaniem jest prośba o wygenerowanie predykcji i w odpowiedzi otrzymujemy status (sukces, czy porażka) wraz z tą predykcją bądź informacją zwrotną co jest nie tak na wypadek jakichś problemów.
5. Protokół HTTP jest protokołem tekstowym, co oznacza dla nas, że jest human-friendly, tzn. my możemy zobaczyć jakie wiadomości wysyłamy do serwisu oraz my możemy też zobaczyć jaką odpowiedź otrzymamy serwisu w formacie tekstowym (*trzeba teraz odpalić Mozille i pokazać Network bo tam można zobaczyć surowy response*). To co my widzimy w Networku jest ładnie wyświetlane nam przez GUI przeglądarki, ale w rzeczywistości jak klikniemy sobie opcję "Raw" w prawym górnym rogu, zobaczymy surową odpowiedź jaką otrzymaliśmy ze strony (albo [tutaj możemy pokazać](https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview#http_flow). I jak widzimy to jest po prostu czysty tekst z masą różnych informacji, o których powiem więcej później. Sprawdźmy też jak to wygląda w naszym przypadku: 
Uruchomimy API. Potem **treść `send_example_request.py` skopiować do pythonowej konsoli żeby mieć obiekt response** i następnie:

```python
from requests_toolbelt.utils import dump
data = dump.dump_all(response)
print(data.decode('utf-8'))
```

Spójrzmy na to co widzimy: Te znaczki większości, mniejszości oznaczają czy to jest żadanie czy odpowiedź. Zaznaczony obszar przeze mnie to żądanie, a ten niżej to odpowiedź
1. Mamy informację jakiego typu żądanie wysyłamy - widzimym że jest to `POST`
2. Następnie jest informacja o endpoincie `/predict_decision` gdzie wysyłamy nasze żądanie
3. Potem jest informacja o wersji protokołu, w tym przypadku `HTTP 1/1` - o różnych wersjach HTTP powiem później.
4. Następnie mamy tzw. nagłówki (czyli `headers` po angielsku) czyli krótko mówiąc metadane o naszym zapytaniu. I spójrzmy jakie metadane wysyłamy do naszego API.  
5. Pierwszym z nim jest `host` - ciężko jest mi mówić o czym jest `host`, bo jeszcze nie omówiliśmy tematu czym jest IP, Port, czym jest URL, URI, domeny itd. więc wrócę do tego później. Natomiast na ten moment przyjmijmy, że `host` to po prostu informacja o tym gdzie konkretnie te żądanie ma trafić. 
6. Dalej mamy informacje o `User-Agent` czyli kto wysyła żądanie. W naszym przypadku mam informacje, że przyszło to z pythonowej bilbioteki `request`. Jeżeli wrócimy do networkingu w naszej przeglądarce to `User-Agent` będzie po prostu informacją o przeglądarce.
7. `Accept-Encoding: gzip, deflate` to są algorytmy, które API może użyć do tego aby skompresować naszą wiadomość, po prostu aby mniej ważyła.
8. `Accept` informuje o tym w jakim formacie zaakceptujemy odpowiedź. W naszym przypadku mamy ustawione na `*/*` - co to oznacza? Gdyby nasz endpoint mógł zwrócić informacje w różnych formatach, np. nie tylko JSON, ale również obrazek czy zwykły tekst, to tym nagłówkiem możemy sterować jakiego formatu odpowiedzi się spodziewamy. Defaultowo ustawiane jest na `*/*`. Natomiast jak spojrzymy sobie na networking to tutaj różne żądania mają ustawione różne wartości w tych nagłówkach, właśnie w zależności od tego czego spodziewają się wysłać.
9. `Connection` - nagłówek mówiący o nawiązaniu połączenia z serwisem - może przyjąć dwie wartości, albo `keep-alive` czyli połączenie jest cały czas otwarte i kolejne requesty, które będziemy wysyłać do API korzystają już z tego samego połączenia albo `close`, do którego wysyłaliśmy żądanie. To jest już temat bardzo zaawansowany, dlatego, że w komunikacji pomiędzy dwoma serwerami działa jeszcze również protokół TCP i to jest nagłówek używany przez protokół TCP. Krótko mówiąc - dla własnego bezpieczeństwa nie dotykamy tego nagłówka. Jeżeli tutaj będzie `keep-alive` to jest OK, wtedy korzystamy z połączenia który już nawiązaliśmy. Jeżeli byśmy tutaj ustawiali `Connection: closed` to z każdym wysłanym żadaniem musielibyśmy utworzyć połączenie z API na nowo. Ale to już jest temat zaawasowany i nie chce tutaj wnikać w szczegóły działania protokołu TCP.
10. Bardzo ważny nagłówek dla Nas czyli `Content-Type: application/json` - określa jakiego typu dane wysyłamy - w naszym przypadku jest to informacja, że dane przyjdą w schemacie `JSON`. 
I tutaj muszę wrócić na chwilę do `send_example_request.py` bo jeżeli ktoś z Was już tą bibliotekę zna, to wie o tym, że tutaj jest jedna rzecz za dużo, nie potrzebna. Jak spojrzymy sobie na `requests.post(url=url, headers=headers, json=data)` to mamy url, do którego wysyłam żądanie, nagłówki w `headers` oraz parametr `json=data`. Jeżeli skorzystamy z argumentu `json` w bibliotece `request` to nie musimy ustawiać nagłówków na `"Content-Type": "application/json"`  (zakomentuj, zmień i pokaż im). Dlatego ,że ten argument automatycznie dodaje nagłówek `"Content-Type": "application/json"`. Natomiast request mamy parametr `data` i wtedy taki nagłówek jest potrzebny. Tylko dodatkowo `data` wymaga danych w formacie czystego `stringa` a my mu podajemy `dict` i na pewno rzuci nam błędem: zobaczmy `make request`. To wtedy trzeba zaimportować bibliotekę `json` i użyć `json.dumps` -> 
```python
response = requests.post(url=url, headers=headers, data=json.dumps(data))
```
I teraz ten dict zamieniony na tekst zostanie odpowiednio przetransformowany na JSON, zgodnie z nagłówkiem, który ustawiliśmy. Ale żeby sobie pracę ułatwić to wracamy do argumentu JSON. Natomiast te `headers` zakodziłem po prostu z przyzwyczajenia oraz z tego faktu, że w przyszłości będziemy jeszcze dodawać tutaj nagłówki. 
Teraz ktoś może zapytać - dlaczego wysyłamy dane do API w formacie JSON? Czy nie moglibyśmy danych do naszego API wysłać inaczej? Odpowiedź brzmi tak, można wysłać dane w każdym formacie np. tekstowym, ale po prostu praca na JSONa w pythonie jest bardzo łatwa i przyjemna, bo JSON to po prostu pythonowy `dict` a `dict` można bardzo łatwo rozpakować np. podczas inicjalizacji klas (pokaż na przykładzie `PredictRequest`, zainicjuj klase w konsoli na przykładzie dicta `data` z `send_example_request`. Dlatego najwygodniej jest pracować na JSONach. Nie wiem jak jest w innych językach, ale domyślam się, że praca na JSON-owo analogicznych obiektach jest po prostu przyjemna. A suchy tekst trzeba odpowiednio parsować itd. bez sensu.
11. Dalej na końcu mamy `Content-Length` - czyli długość naszych danych w sensie ile znaków tekstowym to zajmuje
12. No i podspodem `body` czyli zawartość requesta - nasze dane do predykcji.

No i otrzymujemy mamy odpowiedż z podobnymi danymi, protokół, status code, treść i nagłówki oraz payload.

Jak widzicie struktura jest jak ot się mówi `human-friendly`, jesteśmy w stanie przeczytać to co wysyłamy i to co otrzymujemy normalnie jako tekst, a nie jako jakieś binarne 0 i 1. Chociaż niestety taka reprezentacja tekstowa może się w przyszłości zmienić, ale o tym powiem za chwilę.

3. Dzięki strukturze nagłówków, protokół HTTP przez te wiele lat był i wciąż jest cały czas rozszerzany. Rozszerzalność zastosowania protokołu HTTP może odbywać się właśnie poprzez dodawanie nowych nagłówków. Temat jest spory i nie bede tutaj przynudzał - zainteresowanych jak się protokół HTTP rozwijał odsyłam do bardzo fajnego artykułu [o historii ewolucji HTTP](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP) i tam też można zobaczyć jakie nowe nagłówki pojawiały się na przestrzeni czasu . Natomiast to co jest istotne w kontekście dodawania swoich własnych nagłówków to struktura jaką muszą przyjąć: wszelkie customowe, nowe nagłówki, które będziemy chcieli dodać na potrzeby działania naszego serwisu muszą zaczynać od `X-` i potem nasza nazwa. Zobaczmy na networking. Nagłówki bez `X-` to są nagłówki "oficjalne", spotykane wszędzie i wspierane przez wszystkie serwisy, strony internetowe itd. Natomiast nagłówki z `X-` - tak jak tu widzicie - to są customowe nagłówki dodawane przez serwis `stackoverflow.com`. W jakim celu są one stosowane - zastosowania mogą być różne - inne serwisy, które korzystają z danych ze stackoverflow mogą uzależniać swoje działanie właśnie od wartości w nagłówkach.

4. My na naszym kursie będziemy korzystać zarówno z nagłówków oficjalnych, przy temacie zabezpieczania API i autoryzowania się do niego oraz ze swoich własnych nagłówków przy tematach logowania tego co się w API dzieje.

5. I ostatni temat bardzo ważny w protokole HTTP to to, że protokół HTTP z definicji jest `stateless` czyli `bezstanowy`, ale nie jest `sessionless` czyli `bezsesyjny`. O co chodzi? 
	1. HTTP jest `stateless` - Chodzi o to, że każde kolejne żądania wysyłane do API są po prostu niezależne od siebie. Protokół HTTP **nie wymaga**, aby nasze API/serwis przechowywał jakiekolwiek informacje o użytkowniku, który właśnie teraz wysyła żądania, po to aby móc przetwarzać kolejne zapytania wysyłane przez niego.
   


[Dokumentacja HTTP](https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview)
https://blog.bytebytego.com/p/how-does-https-work-episode-6#%C2%A7how-does-https-work
https://blog.bytebytego.com/p/ep62-why-does-google-use-monorepo#%C2%A7important-things-about-http-headers-you-may-not-know
https://blog.bytebytego.com/p/ep21-is-https-safe-also#%C2%A7is-https-safe
[Usage stats of HTTP/2](https://w3techs.com/technologies/details/ce-http2)
[Usage stats of HTTP/3](https://w3techs.com/technologies/details/ce-http3)

