# Zapisywanie do bazy danych inputów i outputów

1. Zostaniemy jeszcze przy kwestiach bazodanowych, ponieważ w serwisach MLowych oprócz cachea, który jak widzicie znacznie może przyśpieszyć Wasze API istotne jest również przechowywanie informacji o tym jakie dane zostały wysłane do naszego API oraz jakie odpowiedzi nasze modele zwróciły. Dlaczego mamy zapisywać te dane? Odpowiedź jest bardzo prosta - jedną z najważniejszych rzeczy przy systemach opartych o ML jest monitoring ich jakości. A żeby monitorować nasz model pod względem jakości, potrzebujemy danych. Czyli w API, tymi danymi są po prostu requesty, które zawierają w swoim ciele inputy do modeli oraz response, który w swoim ciele zawiera predykcje z modelu. Dlatego istotne jest to aby każdy request i każdą odpowiedź z naszego API gdzieś zapisać. W ten sposób, w trakcie działania Waszego modelu na produkcji, gromadzicie dane, które później możecie porównać z Waszymi zbiorami testowymi, na których wykonywaliśmy ewaluację modelu i sprawdzić czy faktycznie jego jakość wciąż jest na poziomie takim, jaki była w momencie wdrożenia. Oprócz tego można te dane również porównać z danymi treningowymi i sprawdzić czy rozkłady cech, które wchodzą w skład modelu mają wciąż ten sam rozkład. Nie wiem czy słyszeliście o takich pojęciach jak Data Drift, Concept Drift czy Covariate Shift albo Drift Detection. Nie będziemy wchodzić w tematy Data Driftów na tym zjeździe, temu będzie poświęcony zjazd 4 w którym mówić będziemy o monitoringu (**DO REDAKCJI TE ZDANIE. BO MOŻE MONITORINGU NA 4 ZJEŹDZIE NIE BĘDZIE??**). Natomiast bazą całego Waszego monitoringu modeli są - dane. Musimy je mieć i gromadzić.
2. W przypadku przechowywania danych z requestów i response, tutaj już nie ma tak dużych rozkmin jak z Redisem