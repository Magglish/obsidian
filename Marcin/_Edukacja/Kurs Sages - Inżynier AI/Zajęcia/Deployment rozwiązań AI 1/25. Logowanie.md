# Logowanie

1. Słuchajcie, przechodzimy teraz do bardzo ważnego tematu jakim jest logowanie. Czym jest logowanie? To każdy z Was myślę, że wie, więc jednym zdaniem można to ująć jako: zapisywanie wszelkich zdarzeń zachodzących w aplikacji.
2. Moim zdaniem istnieją dwie rzeczy, bez których nawet prosty projekt, czy Proof of Concept po 3/6 miesiącach nie może wejść na produkcję:
	1. Logi - o czym teraz będziemy o tym rozmawiać
	2. Testy - o czym będziemy rozmawiać później
3. Część z Was może jeszcze pomyśleć o monitoringu, jako o trzecim elemencie niezbędnym - tutaj nie jestem przekonany czy jest to niezbędny element. To zależy też oczywiście od stadium rozwoju aplikacji - jeżeli jest to początek, to moim zdaniem może jeszcze wejść jeszcze bez monitoringu, bo często monitoring oprócz takich fundamentalnych, podstawowych metryk musi też monitorować "specyficzne" metryki dla danego API, które po pierwszych iteracjach dopiero będą znane. Później jak już aplikacja jest bardziej dojrzała to oczywiście monitoring musi być. Natomiast mówiąc o takich niezbędnych elementach - niezależnie od tego w jakim jest stadium, czy to sam początek, czy już coś bardziej rozwiniętego, to jednak logowanie i testy jest must-have. Ja osobiście nie wdrażam nic na produkcję bez tych dwóch rzeczy - nie ma opcji.
4. Dlaczego? Dlatego, że naprawa bugów i debugowanie czegoś bez tych dwóch rzeczy to ISTNY KOSZMAR, zajmujący strasznie dużo czasu. Ja wole sobie tego zaoszczędzić.
5. Teraz porozmawiamy sobie o logowaniu w API. Od razu na wstępie powiem tak: 
	1. Pierwsza sprawa najważniejsza moim zdaniem -  chciałbym na tym zjeździe przekazać Wam najważniejsze punkty - ideę logowania: chciałbym żebyśmy mogli odpowiedzieć sobie na pytanie: KIEDY logować? CO logować? jak POWIĄZAĆ logi? Nie będziemy omawiać tutaj jak zbudowana jest pythonowa biblioteka logging i jak definiować w niej te wszystkie formattery, filtery itd. Nie nie. Chce się skupić na najważniejszych punktach - idei logowania. A to jaką bibliotekę finalnie użyjecie, to będzie to Wasza indywidualna preferencja. Z tym powiązaniem chodzi o to, że każdy log to będzie oddzielny wpis. Biorać pod uwagę fakt, że Wasze API będzie działało na wielu instancjach a zapytań wykonywach będzie wiele, to sami się przekonacie, że ilość logów jest ogromna. Zatem trzecie pytanie dotyczy w sumie jak się połapać w gąszczu tych wszystkich logów. O samym logowaniu można naprawdę pisać i wygłaszać elaboraty. Jak sobie sami spojrzycie np. w dyskusje na Stackoverflow oraz na Reddicie, każdy ma swoje zdanie na ten temat, są różne punkty widzenia. Ja przedstawie Wam tą wiedzę jaką zebrałem na bazie swojego doświadczenia + wzbogaconą o mieszanką wiedzy i doświadczeń innych developerów, czy to w trakcie rozmów czy właśnie analizy dyskusji na różnych forach. Najważniejsze moim zdaniem w logowaniu jest to, żeby Wam pomogło to w pracy - więc jeżeli będziecie uważać, że pewne rzeczy zrobilibyście inaczej i uważacie, że Wam się to lepiej sprawdzi - to jest ok, to to zróbcie.
	2. Druga sprawa - do logowania jest sporo bibliotek, znacznie lepszych niż zbudowany w pythonie moduł `logging`, który ma swoje wady - jedną z nich jest jego troche dziwna konfiguracja, przez co nie jest łatwa. Jest to bardzo stary moduł. Tych bibliotek jest sporo, ale moim zdaniem na największą uwagę zasługuje [logguru](https://github.com/Delgan/loguru) który znacznie upraszcza korzystanie z podstawowego `loggingu` oraz [structlog](https://www.structlog.org/en/stable/why.html), który skupia się na tworzeniu logów w formacie JSON. Niemniej jednak, każdy z nich korzysta pod spodem z pythonowego, podstawowego `logging`, więc warto poznać najpierw tą podstawową bibliotekę. Ja na naszym zjeździe zostanę przy podstawowym pythonowym `logging`-u - nie chce Wam wprowadzać nowych bilbiotek, które są kolejną warstwą nałożoną na podstawowy `logging`. I tak jak mówiłem, chce Wam przekazać ideę logowania - później w trakcie swojej pracy jak już oswoicie się z logowaniem to zdecydujecie, którą ostatecznie bibliotekę chcecie wykorzystywać.
	4. Trzecia sprawa - w sieci znajdziecie wiele różnych implementacji jak logować pewne zdarzenia. Bardzo często spotykanym patternem w temacie logowania jest decorator i przykładów decoratorów znajdziecie wiele - np. [ten](https://ankitbko.github.io/blog/2021/04/logging-in-python/). On jest wielki i troche brzydki - na pewno można go zapisać lepiej. Nie mniej jednak one będą tak wyglądać - jeżeli będziecie chcieli zrobić decorator, który będzie służył Wam zawsze i wszędzie, aby logował Wam to co chcecie, to będzie on skomplikowany. Ja Wam powiem z własnego doświadczenia, że... bawiłem się takimi decoratorami, które mogłyby logować wszystko co chce... i w moim przypadku się to nie sprawdza. Do logowania prostych funkcji tak, ale z bardziej skomplikowaną logiką już nie. Zawsze powstawał mi taki kolos, który ciężko było utrzymać i rozwijać gdy pojawiały się jakieś funkcje, które wyjątkowo inaczej musiałem zlogować. Ja porzuciłem ten pomysł i robie to prosto... po prostu dodając logowanie jako kolejne linijki kodu. Jeżeli natomiast Wy macie lepsze doświadczenia z tym związane i uważacie decoratory za fajny pattern do użycia w logowaniu i Wam się sprawdza... to jak najbardziej z tego korzystajcie. Natomiast ja nie będę ich używał na naszym zjeździe - pójdę w prostotę.


Ok to zacznijmy od początku:

### Kiedy warto logować? 

Generalnie sprawa z pytaniem KIEDY warto logować jest stosunkowo prosta:

1. Na początku wywołania funkcji - aby mieć informacje zwrotną, że faktycznie rozpoczęło się jej wykonanie
2. Oraz na końcu wywołania funkcji - aby mieć informację zwrotną, że faktycznie funkcja zakończyła się. Z logowaniem na końcu funkcji jest jeszcze jedna istotna właściwość - oznacza to, że funkcja wykonała się prawidłowo. 
3. Natomiast jeżeli istnieje jakiś element w środku wywołania funkcji, który naszym zdaniem jest istotny i warto wiedzieć, że coś się wtedy zadziało, to także warto to logować.
4. I oczywista, oczywistość - logowanie każdego wyjątku/błędu, który wystąpi w funkcji - to jest najważniejsze.

Dodajmy sobie pierwsze logi do naszego API. Wróćmy do `main.py` i spójrzmy jak wygląda wywołanie kodu.

Dodajmy do maina taki kawałek kody:

```python
import logging  
from src.utils.logging import setup_logging  
```

A następnie na samym początku skryptu dodajmy:

```python
setup_logging()
```
Powiem później co to robi.

Mamy wywołanie `app = FastAPI()` - czy tutaj można dodać logi? Można. Ale zajmiemy się tym na końcu.

Dalej mamy wywołanie naszego modelu `model = CreditScoringModel(path=Path("models/classifier.pkl"))`.  Czy mamy tutaj logi? Nie mamy. Czy według nas jest to istotna rzecz, żeby zlogować? Moim zdaniem tak. Model w API to podstawowy komponent działania naszego modelu, jeżeli nie moglibyśmy go załadować, to chcielibyśmy wiedzieć dlaczego.

W takim razie dodajmy sobie logowanie do naszego modelu.
Zaimportujmy sobie moduł `logging`

```python
import logging
```

I do ładowania modelu dodajmy sobie logowanie:

Tak jak wspominałem: ważny jest początek i koniec. Zatem:

```python
logging.info(f"Loading Credit Scoring Model from {path} location")
```

Na początku wywołania funkcji. Oraz:

```python
logging.info(f"Successfully loaded Credit Scoring Model")
return model
```
Na końcu wywołania funkcji. Jeżeli logowania dojdzie do tego momentu, mamy również gwarancję tego, że bez problemu udało się nam załadować model. 

Dodatkowo wspomniałem o tym, że istotne jest również zastanowienie się czy w środku wywołania funkcji, innymi słowy pomiędzy startem logowania i końcem logowania jest coś istotnego. W tym przypadku oczywiście, że jest - sam proces załadowania obiektu. Co się może tutaj zdarzyć? Oczywiście fakt taki, że dany obiekt nie istnieje i to jest ten istotny element, o którym warto byłoby wiedzieć. W przypadku braku obiektu dostaniemy błąd, więc musimy go sobie zlogować: Zatem dodajmy sobie

```python
try:  
    with path.open(mode="rb") as file:  
        model = pickle.load(file)  
except FileNotFoundError as e:  
    logging.exception(f"Credit Scoring Model not found in location {path}.") 
    raise e
```
Teraz ktoś z Was może się zastanowić po co dodajemy do kodu takiego try excepta i logging.exception, skoro w Pythonie gdy pojawi się błąd to i tak i tak otrzymamy w konsoli jego treść? 

To jest bardzo dobre pytanie - pokaż im uruchomienie API bez logging.exception (bedzie 1 traceback), a drugi z logging.exception (bedą 2 tracebacki)

Zobaczmy na przykładzie: w `main.py` popsujmy lokalizacje naszego modelu i zobaczmy co otrzymamy. Jak widzicie pojawił się log:

```
Credit Scoring Model not found in models/classifier.pklxxx location.
```

I wraz z nim jest Traceback. `logging.exception` działa tak, że jeżeli zawrzemy go w klauzuli `try except` to domyślnie dołączony będzie traceback z błędem.

Ale zobaczcie co jest na dole: Znowu jest traceback... Czyli widzicie, informacja jest jakby powielona. Ten drugi błąd wynika, z tego, że tak działa pythonowy interpreter, który będzie printował nam w konsoli błąd jeżeli taki napotkamy. No właśnie i teraz powtarzając pytanie - ktoś z Was może się zastanowić po co dodajemy do kodu takiego try excepta i logging.exception, skoro w Pythonie gdy pojawi się błąd to otrzymamy w konsoli jego treść? Powody są dwa:
1. Na produkcji nie będziecie mieli takiej konsoli, która Wam printuje to na żywo. Logi będą wysyłane gdzieś do jakiegoś systemu - Google Cloudzie jest to Stackdriver, na AWS jest to CloudWatch, na Azurze jest to Azure Logs Monitor, jeśli będzie Wasze API stało na jakimś systemie on-premise to na pewno będzie jakiś serwis z logami. Biblioteki, które będą wysyłały logi do tych usług będą zintegrowane z podstawowym pythonowym `logging`, więc użycie ich będzie bardzo proste i bardzo często nawet nie będziecie musieli zmieniać swojego kodu.
2. Ten traceback, który teraz zaznaczam i który został wyprintowany przez pythonowy interpreter - nie macie żadnej gwarancji, że on zostanie wysłany do tego systemu obsługujący logi. Tak może być, ale nie musi. Np. na Google Cloudzie tak jest, że to co wyprinuje pythonowy interpreter to pojawi sie tam w logach, ale problem jest taki, że będzie to bardzo źle sformatowane i nie do przeczytania. Natomiast to co teraz zaznaczam, będzie JEDNYM wpisem w waszym systemie do analizy logów i będzie on poprawnie sformatowany. 
Więc najlepiej jest przyjąć takie założenie: na produkcji będziecie widzieć tylko to co sami sobie zlogowaliście - nic więcej. 

Teraz ktoś z Was może sobie zadać pytanie: A co jeżeli wystąpi tutaj inny błąd niż `FileNotFoundError`, jak powinniśmy ten błąd obsłużyć? To jest bardzo dobre pytanie. Generalnie obsługujemy te błędy, których się spodziewamy z samego działania kodu - zobaczcie, ja tutaj mam `pickle.load(...)` ja wiem co ta funkcja ma zrobić - wczytać plik, więc spodziewam się, że jak tego pliku nie będzie to po prostu rzuci wyjątkiem `FileNotFoundError` dlatego go wyłapałem i zlogowałem. A co jeżeli sam `pickle.load` rzuci w sobie jakiś błąd - dajmy na to ktoś spartolił implementacje tej metody i np. dostaliśmy błąd `AttributeError` - czy powinniśmy to zlogować? Oczywiście, że tak. Ale jak? Sposób jaki może przychodzić do głowy to to aby zastąpić `FileNotFoundError` najbardziej szerokim wyjątkiem czyli `Exception`. To jest jakieś rozwiązanie, ale jest to generalnie uznawane za bad practise. Dlaczego? Dlatego, że w takim przypadku Wasze logi będą nieprecyzyjne - każdy błąd który wystąpi w kodzie odpowiedzialnym za wczytanie modelu będzie traktowany tak samo, z tą samą treścią. I za każdym razem będziecie otrzymywać to samą wiadomość - niezależnie od tego czy faktycznie model jest w tej lokalizacji czy np. właśnie w `pickle.load(...)` jest jakiś bug. 
Ok, to ktoś może teraz pomyśleć - to może napiszmy ten log tak bardziej ogólnie, nie logujmy `Credit Scoring Model not found in {path} location.`, tylko np. napiszmy "Theres a problem with loading scoring models: {path=}.". To powiem Wam od razu, że takie generalne logi nie powiedzą Wam nic. Logi muszą być precyzyjne, zawierać w sobie wszelkie niezbędne informacje żebyście nie mieli żadnych wątpliwości co się zadziało, one mają Wam pomóc w Waszej pracy - natomiast takie generalne logi i łapanie szerokich wyjątków są niezbyt precyzyjne i w efekcie nie dadzą Wam żadnych korzyści.  Zarówno treść Loga powinna być maksymalnie precyzyjna oraz sama nazwa klasy błędu też jest dodatkową informacją, bo to też zostanie zlogowane.

Wróćmy zatem do `FileNotFoundError` oraz do treści jaka była. Ok to co w sytuacji kiedy kod będzie rzucał więcej wyjątków niż jeden? To wtedy tych `exceptów` oraz `logging.exception` tyle ile spodziewamy się, że tych błędów będzie. W naszym kodzie będzie znacznie więcej, tyle aby móc spokojnie te błędy obsłużyć i je odpowiednio zlogować. 

Ok ale co z błędami których w `exceptach` nie będzie, jak je wyłapać? To Wam pokaże później, FastAPI dostarcza nam bardzo fajne mechanizmy aby móc się zabezpieczyć przed takimi caseami.

Wróćmy do `main.py` i obsłużmy sobie jeszcze połączenia z bazami danych. Połączenia z bazami danych też są istotne, bo Redis przyśpiesza nam działanie naszego API a Postgres pozwala nam na zapisanie inputów i outputów z API, które potem stanowić będą baze do monitoringu.

W kodzie na redis w metodzie `_create_connection` brakuje sprawdzenia, czy udało nam się z tym Redisem połączyć. Akurat biblioteka do Redisa nie sprawdza połączenia z baza w momencie tworzenia tego połączenia, trzeba ją pingnąć:

Importujemy logging
```python
import logging
```
I dodajmy logowanie:

```python
logging.info(f"Creating connection to Redis database on {host=}, {port=}.")  
try:  
    connection = redis.Redis(host=host, port=port)  
    connection.ping()  
except redis.exceptions.ConnectionError as e:  
    logging.exception(f"Unable to connect to Redis database.")  
    raise e  
logging.info(f"Successfully created connection to Redis database.")  
return connection
```

Został nam jeszcze postgres. 

Zaimportujmy logging a następnie w metodzie `_create_connection` dodajmy logowanie:

```python
logging.info(f"Creating connection to Postgres database on  {database=}, {user=}, {host=}, {port=}.")  
try:  
    connection = psycopg2.connect(  
        database=database,  
        user=user,  
        password=password,  
        host=host,  
        port=port,  
    )except psycopg2.OperationalError as e:  
    logging.exception(f"Unable to connect to Redis database.")  
    raise e  
logging.info("Successfully created connection to Postgres database.")  
return connection
```

W postgresie tworzony jest jeszcze cursor i tam też warto byłoby dodać logi... ale słuchajcie... umówmy się, że na potrzeby mojego live-codingu nie będziemy dodawać logowania wszędzie, chce skupić się na idei? Zaraz oczywiście powiemy sobie CO warto logować. Natomiast nie chce dodawać logów wszędzie, bo spędzimy na tym za dużo czasu i spotkanie dobiegnie końca a jest wiele rzeczy jeszcze do omówienia. Aczkolwiek troche logów musimy dodać żebyśmy mieli w ogóle co analizować. Więc w przypadku Postgresa zostane na razie przy samym połączeniu, bez cursora.

I teraz ubijmy sobie `redis`a i `postgres`a -> znajdźmy je `docker ps` i zabijmy `docker kill <<PIERWSZE_ZNAKI_CONTAINER_ID>>` i sprawdźmy czy działa.

Pierwszy błąd powinien być związany z połączeniem z Redisem. Dobra to teraz stwórzmy go `make redis`. Spróbujmy jeszcze raz. Teraz wywaliło się na `Postgresie`. A teraz powinno zadziałać. Dobra, to było szybkie sprawdzenie czy faktycznie nasze logowanie zadziałało. 

**Pytanie**: Dlaczego zwykłe printy nie zadziałają?
Powodów jest wiele:
Odp: 
1. Formatowanie będzie kiepskie - np. logging.exception ma w sobie to aby sformatować cały traceback razem z nowymi liniami, znakami tabulacji itd.
2. Biblioteki do logowania pozwolą Ci na stworzenie struktury - np. JSON, który później łatwiej jest 
3. Jeżeli masz strukture JSONa to można łatwo dodać wszelkie metadane pozwalające na jeszcze łatwiejsze zdebugowanie kodu
5. Printy piszą do konsoli, która na produkcji nie zawsze może być dostępna
6. Logging pozwala Ci na definiowanie poziomu logów - DEBUG, INFO, WARNING, ERROR itd.
7. I najwazniejsz argument - na produkcji logi będą wysyłane do jakiegoś systemu: np. na Google Cloudzie jest to Stackdriver, na AWS jest to CloudWatch itd. I biblioteki, które wysyłają logi do tych usług są zintegrowane z podstawowym modułem `logging`, ale nie ze zwykłymi `print`
8. Prawdę powiedziawszy, gdybyś się uparł to mógłbyś napisać swój własny kod do logowania oparty o printy, pewnie byłoby to trudne ale możliwe - ale po co implementować koło na nowo? 


Ok to podsumowując wariant KIEDY:

1. Początek wywołania funkcji - informacja, że działanie się rozpoczęło
2. Koniec wywołania funkcji - informacja, że się zakończyło ORAZ że działanie zakończyło się sukcesem
3. W istotnych elementach działania naszego kodu - na pewno logowanie wyjątków oraz opcjonalnie, jeśli uznamy to za istotne, informacja, że do danego etapu działani funkcji doszliśmy. Akurat w tym repo nie ma żadnych kodów robiących coś skomplikowanego, więc logowanie przeważnie będzie takie jak tutaj widzicie. 

### Co warto logować?

Teraz drugie ważne pytanie - CO warto logować? Tutaj odpowiedź jest już znacznie trudniejsza niż w przypadku KIEDY. Dlaczego? Dlatego, że nie ma generalnych zasad co warto logować, a co nie - to wszystko zależy od inżyniera i to jaką aplikację stworzył. 
Odpowiedź na CO logować jest moim zdaniem odpowiedzią mocno subiektywną. Dlaczego? Ponieważ logi, które dodajecie są dla WAS i mają pomóc Wam w waszej pracy i naprawianiu ewentualnych błędów jeśli wystąpią. Na pytanie CO warto logować można pomóc sobie odpowiadając na przykładowe pytania:
1. CO pozwoli mi naprawić ewentualne błędy? 
2. CO moim zdaniem jest istotne dla mnie abym wiedział? 
3. CZEGO w ogóle nie potrzebuję? 

Jeżeli uznacie, że jakiś element pozwoli Wam na łatwiejsze debugowanie, naprawianie błędów, po prostu informacja ta pozwoli Wam lepiej pracować, czy nawet spać - to ją zlogujcie. 

Jeśli chodzi o mnie - ja jestem osobą, która bardzo dużo rzeczy loguje, dlatego, że kieruje się zasadą, że logi mają być jak dobrze opowiedziana historia. Ma mieć początek, ma mieć wstęp, ma mieć rozwinięcie i, mam nadzieję, dobre zakończenie. Jedyne co mnie ogranicza w dodawaniu logów to fakt, że analiza logów np. na usługach w chmurze może Was kosztować jakieś pieniądze - więc pomimo moich chęci logowania dużo, staram się jednak ograniczać logi w takim zakresie, aby po prostu nie narażać firmy na niewiadomo jakie koszta, bo Marcinowi zachciało się poczytać historie logów. 

Czasami spotykam się z opiniami, że takie podejście, czyli logowania dużo, może wprowadzić szum w logach i może być logowanych tam za dużo informacji, które ostatecznie mogą się nie przydać. Cały czas nie zgadzam się z tą opinią - wychodzę z założenia, że jeżeli developer uważa informacje za istotną dla niego, która pozwoli mu spokojnie pracować i debugować, to to nie jest szum. Tym bardziej, że ja jeszcze mam trochę niepopularną opinie na temat tego jaki poziom logów ustawiać na produkcji - ale o tym zaraz.

Ok, ale wróćmy do naszego `main.py` - mamy na razie logi na poziomie naszego modelu, oraz połączeń z bazami danych. Czyli mamy te 3 linijki, które zaznaczyłem.
Teraz pytanie, a co z tymi naszymi klientami Redisowymi i Postgresowymi? Czy My też powinniśmy to zlogować? I to jest właśnie ten moment odpowiedzi na pytanie CO logujemy? Czy to co tam się dzieje w tych funkcjach jest dla nas istotne, aby ułatwić nam później debugowanie? Spójrzmy na inicjalizacje tych klas. Weźmy `DecisionRedisClient`. Dziedziczy po `BaseRedisClient` to przejdźmy tam dalej. Zobaczmy na inita: tak na prawdę, jedyne co tutaj się dzieje to zapisanie connectora w atrybutach danej klasy. Czy to jest potrzebne aby to zlogować? Moim zdaniem nie - to jest tylko przypisanie obiektu do danego atrybutu. Ta informacja akurat mi w niczym nie pomoże w przyszłości. Tymbardziej, że w naszym `RedisConnector`-ze mamy już zdefiniowane logowanie, zatem jeżeli `RedisConnector` nie zadziała, to nie zadziała również wszystkie `RedisClient`. Czyli stwierdzamy na tej podstawie, że logowanie tutaj jest niepotrzebne.

Wracamy do `main.py`... i od razu Wam powiem, że w przypadku klientów Postgresowych jest identycznie jak teraz z Redisem. Tam logowanie w inicie jest niepotrzebne. Ok czyli mamy załatwione inicjalizację naszych głównych obiektów, które służą nam do działania naszego API. 

Zatem teraz musimy przejść do naszego endpointa i zacznijmy dodawanie logów aby zobaczyć co się w nim dzieje. 

Kiedy logujemy? Na początku i na końcu:

```python
@app.post("/decisions")  
async def decisions(  
    request: DecisionRequest,  
    background_tasks: BackgroundTasks,  
) -> DecisionResponse:  
    logging.info(f"Received {request=}")  
	...
	...
	... 
	logging.info(f"Returning {response=}")
    return response
```

Teraz w endpoincie dużo się dzieje - chcielibyśmy mieć informacje o tym.

Dodajmy logi do Redisa w metodzie `read`:

```python
logging.info(f"Getting response from Redis for {request=}")  
key = self._create_key(request)  
value = self.connector.connection.get(key)  
if value:  
    response = self._create_response(value)  
    logging.info(f"Returning response from Redis {response=}")  
    return response  
else:  
    logging.info("Response not available in Redis")  
    return None
```

oraz w metodzie `write`:

```python
logging.info(f"Saving {response=} for {request=} to Redis")  
key = self._create_key(request)  
value = self._create_value(response)  
self.connector.connection.set(key, value)  
logging.info(f"Successfully saved response in Redis")
```

Dodamy sobie logi jeszcze w pozostałych etapach. Zależy mi na tym żebyśmy widzieli troche tych logów, bo potem jak przejdziemy do etapu pozwiązywania logów, to chciałbym żebyśmy mieli co analizować.

Zróbmy to też w Postgresowym kliencie - przejdźmy do `DecisionPostgresClient`, a potem do `BasePostgresClient` po którym dziedziczy i dodajmy logi tylko w metodzie `write`, bo ona obecnie w API jest tylko używana.

```python
logging.info(f"Writing {request=} and {response=} to Postgres database")  
query = self._prepare_insert_query(request, response)  
data = self._prepare_insert_data(request, response)  
self.connector.cursor.execute(query, data)  
self.connector.connection.commit()  
logging.info(f"Successfully written request and response to Postgres database")
```

Przejdźmy teraz do metody `predict_decision` i dodajmy tam logi:

```python
logging.info(f"Predicting decision for {features.to_dict()=}")  
probabilities = self.predict_proba(features)  
decision = [  
    Decision.ACCEPT if probability <= self.decision_threshold else Decision.DECLINE  
    for probability in probabilities  
]  
logging.info(f"Returning {decision=}")  
return decision
```

Zostały nam jeszcze background taski `write_to_redis` oraz `write_to_postgres` - to jest bardzo ważne żeby zlogować. Zobaczycie potem dlaczego.

`write_to_redis`:

```python
def write_to_redis(redis_client, request, response):  
    logging.info(f"Started background task to write to Redis for {request=} and {response=}")  
    redis_client.write(request, response)  
    logging.info(f"Successfuly ended background task to write to Redis.")
```

`write_to_postgres`:

```python
def write_to_postgres(postgres_client, request, response):  
    logging.info(f"Started background task to write to Postgres for {request=} and {response=}")  
    postgres_client.write(request, response)  
    logging.info(f"Successfuly ended background task to write to Postgres.")
```

Ok, załóżmy, że to są te logi które chciałem. Zobaczmy teraz jak to działa.

Uruchomimy API i zobaczmy co nam zwróci. 

(Omów to co widzimy w logach)

Czyli mamy całą historię działania naszego API w logach wraz z istotnymi danymi, które przydadzą się później na wypadek błędów i potrzeby debugowania. Te logi, jak widzicie, są dosyć spore - bo jest to zwykły tekst. Na samym końcu omawiania logowania powiem Wam jak można te logi usprawnić i czy w ogóle nie zmienić ich formy na coś bardziej przystępnego.

Ok dodaliśmy sobie logowanie do elementów, które są moim zdaniem na pewno są istotne w działaniu API. Jak spojrzymy sobie w logi to mamy informacje właśnie o tym jaki request przyszedł, jakie odpowiedzi zwracamy + dodatkowe logi z konkretnych funkcji, czy metod, które raportują to co robią i czy udaje im się to zrobić z sukcesem. Ale jeszcze tym logom trochę brakuje. Brakuje im istotnych metadanych abyśmy wiedzieli więcej o naszym API oraz mogli się połapać w tych logach.

Jest dużo dostępnych metadanych jakie możemy dodać do naszych logów, zaraz Wam pokaże co jest dostępne, natomiast w logach muszą znaleźć się na pewno dwa podstawowe metadane:

1. Rodzaj logów: czy mamy styczność ze zwykła informacją, czy może z ostrzeżeniem, czy może z błędem w naszej aplikacji
2. Oraz czas kiedy dane zdarzenie nastąpiło.

Bez tych dwóch rzeczy naprawdę analiza logów jest niemożliwa:

Wróćmy do początku `main.py` i zmieńmy import `setup_logging` na coś innego:

```python
from src.utils.logging import setup_logging_with_formatters

setup_logging_with_formatters()
```

Zresetujmy nasze API i zobaczmy co otrzymamy.

Widzimy, że mamy teraz dodatkowe informacje o czasie logów oraz o ich poziomie - w tym przypadku jest to INFO, bo skorzystaliśmy z `logging.info`. Wykonajmy request i zobaczmy teraz logi z działania endpointa. 

No teraz to już zdecydowanie lepiej wygląda i możemy analizować historię tego co się zadziało w naszym endpoincie.

Jest sporo metadanych jakie możemy dodać: (omów kruciutko)

https://docs.python.org/3/library/logging.html#logrecord-attributes

W zależności od tego co uznacie za istotne w waszym API, można te metadane dorzucić do logowania i one zawsze będą wypisywane z każdym logiem. Teraz jak te metadane są dodawane do logów? Tak jak mówiłem, nie chce omawiać dokładnie jak działa moduł `logging`, bo chce sie skupić maksymalnie na samej idei logowania, a nie na konkretnym narzędziu - ale krótko mówiąc, biblioteki do logowania dostarczają tzw. Formaterów, które odpowiednio zdefiniowane po prostu dodają metadane do każdego naszego logu, który wypisujemy. Niezależnie od tego jakie metadane wybierzecie, czas oraz rodzaj logu to dwie podstawowe, bez których analiza logów jest wręcz niemożliwa.

Teraz krótko o rodzajach logów. Tutaj nie będę się rozwodził na ten temat, bo każdy z Was na pewno je widział, czyli mamy 
1. `DEBUG` -  można to określić jako "niskopoziomowe" detale, które przydają się głównie podczas debugowania aplikacji - `logging.debug`
2. `INFO` - podstawowy poziom informujący o zdarzeniu/stanie naszej aplikacji - tak jak tutaj używaliśmy aby przekazać informacje, że rozpoczęło się przetwarzanie funkcji i zakończyło się sukcesem wraz z danymi wejściowymi i wyjściowymi - `logging.info`
3. `WARNING` -  poziom wyżej niż INFO, który informuje, że coś się zadziało w aplikacji co może nie do końca było spodziewane, albo spodziewamy się, że coś się może wydarzyć - w naszym mozna by było zrobić tak, że akceptujemy fakt, że bazy Redis nie ma i w momencie próby połączenia z Redisem i rzucienia wyjątkiem, my tak na prawdę nie zatrzymujemy API, tylko pozwalamy działać dalej i np. rzucamy sobie warningiem, że połączenie z Redisem było niemożliwe do nawiązania. Trzeba by też zrefactorować kod na read i write aby takie coś obsłużyć - nie mniej jednak brak Redisa mógłby być takim przypadkiem na warning, dlaczego? Dlatego, że bez niego nasze API działało by poprawnie, po prostu wszystkie requesty byłyby przetwarzane przez model. Oczywiście działałoby wolniej, ale wciąż mogłoby przyjmować requesty - `logging.warning`
4. `ERROR` - sprawa banalna - wszelkie wystąpienia błędów i wyjątków `logging.exception`
5. `CRITICAL` - rzadko używane, ale używane w kontekście naprawdę istotnych rzeczy w API jak np. autoryzacja do API nam padła i tak na prawdę nikt nie może z niego skorzystać. Albo nawet brak dostępnego modelu w API (czyli tam gdzie wczytujemy model) też może służyć nam jako coś krytycznego - brak w API jakiegoś istotnego elementu, jak w naszym przypadku modelu.

Najczęściej używane są oczywiście `INFO` oraz `ERROR` - natomiast nie zapomnijcie o pozostałych poziomach, jeżeli uznacie że informacja jest mniej istotna - wrzućcie ją do `DEBUG`, jeżeli są jakieś zachowania API o których powinniśmy być ostrzeżeni, ale nie przeszkadzają w działaniu API - użyjcie `WARNING`

I teraz porozmawiajmy sobie trochę o tym poziomie `DEBUG`. Jak poczytacie sobie w swojej wolnej chwili o poziomie `DEBUG` w logowaniu i to co inni developerzy sądzą o tym poziomie logowania, to często możecie spotkać się z dwoma informacjami na ten temat:

1. Że jest to najniższy poziom, w którym umieszczane są bardzo szczegółowe informację, które, jak sama nazwa może wskazywać, byłyby potrzebne w procesie debugowania.
2. I drugi punkt - że na produkcji nie powinny pojawiać się logi z poziomem `DEBUG` - w tym przypadku nie wiem czy wspomniałem wcześniej, ale w momencie ustawiania logowania można wskazać od jakiego poziomu logi będą pokazywane, więc tutaj nie chodzi o to, żeby w ogóle w kodzie nie pojawiały się żadne `logging.debug`.

Niestety ale nie do końca zgadzam się z drugim punktem. To co powiem jest moją prywatną opinią, ale chciałbym Wam przedstawić swój punkt widzenia, abyście mieli też inne spojrzenie i sami w swojej pracy zdecydowali się na to czy na produkcji umieszczać logi z poziomem `DEBUG`. Skąd wynika mój sceptycyzm co do drugiego punktu? Z powodu pewnego błędu, z którym napotkałem się w swojej codziennej pracy

![[GCP Unkown Error.png]]

To co widać na zdjęciu to treść błędu z jednego z naszych serwisów działających na produkcji na chmurze Google'a, która jak widzicie brzmi: "There was a problem opening a stream. Try turning on DEBUG level logs to see the error". I jeszcze bardzo ważne jest to, jaka biblioteka to rzuciła: `google.api_core`, która stanowi trzon wszystkich bibliotek Pythonowych, które pozwalają wam na interakcje z usługami w Google'u. Ten log który Wam pokazuje wystąpił wystąpił podczas zapisywania danych do BigQuery. Ale spotkałem się z nim jeszcze potem w kilku innych miejscach. Co możemy zrobić w takiej sytuacji? Błąd proponuje włączenie poziomu DEBUG, ale ja go na produkcji nie mam włączonego. Zatem jedyne co nam zostaje w takiej sytuacji to przeniesienie tego na środowisko developerskie i ustawienie tam sobie poziomu logowania na DEBUG. Zdeployowałem sobie tą implementację na środowisku DEVowym i zacząłem wysyłać do niego dane, ale nie udało mi się go w ogóle odtworzyć tego błędu. Wszystko działało świetnie, ale błąd na prodzie pojawiał się - i najgorsze, że on się pojawiał raz na jakiś czas, to nie był błąd który pojawiał się ciągle. Nie byłem niestety w stanie odtworzyć tego błędu po długim czasie, więc zrobiłem to tak jak proponuje sama treść błędu: po prostu ustawiłem logowanie na poziomie DEBUGa na produkcyjnym serwisie i go zrestartowałem - notabene będziemy się tego uczyć na kolejnych zjazdach. I co się okazało? Był taki moment, kiedy dosłownie w bardzo krótkim czasie rzędu wręcz mniej niż 1 sekundy kilka instancji tego serwisu otwierało połączenie do BigQuery aby zapisać dane i logach typu DEBUG dostawałem informacje, że po prostu jest próba otwarcia zbyt dużej ilości połączeń na raz... więc musiałem dodać do jobów retry'e, które na wypadek tego błędu po prostu spróbują otworzyć połączenie za od 1 do 5 sekund, czas wybierany losowo - rozwiązało to sprawę. Ten case byłby możliwe, że byłby do odtworzenia na devie, gdybym przekierował cały ruch z serwisów produkcyjnych na developerskie, ale to pewnie traktowałbym jako ostateczność. Po prostu pomyślałem, że dodam włącze te logi z poziomiem DEBUGa na produkcję - restart serwisów nie spowoduje zaburzenia działania naszych systemów. 

I ten case mnie zaczął zastanawiać i pozwoliłem sobie na ustawienie na wszystkich serwisach na produkcji aby logi z poziomu DEBUG były odkładane. Powiem Wam szczerze, że dzięki temu zabiegowi, później w trakcie kolejnych problemów, ja nie musiałem poświęcać swojego czasu aby deployować na deva i spróbować odtwarzać błąd, tylko po prostu patrzyłem we WSZYSTKIE logi - bo DEBUG był już włączony - i pozwalało mi to na zidentyfikowanie problemu od razu, bez DODATKOWYCH czynności po mojej stronie - logi po prostu wtedy dostarczyły mi wszystkich niezbędnych informacji. 

Jednakże te podejście ma swoją istotną wadę i chce żebyście o niej wiedzieli. Biblioteki których użyjecie mają również zaimplementowane u siebie logi, na różnych poziomach. Włączenie poziomu DEBUG spowoduje, że oprócz informacji, które faktycznie Wam się przydadzą do określenia przyczyny błędu, pojawi się również sporo śmieci. W efekcie czego, w zależności jak macie zaimplementowane logowanie np. czy dodatkowo te logi zapisywane są do plików czy właśnie wysyłane są one do jakiejś usługi która pozwala Wam te logi analizować możecie zobaczyć:
1. Degradacja w szybkości przetwarzania requestów - czyli troche wolniej mogą być requesty przetwarzane ze względu na generowanie logów. Tutaj nie mówimy o jakiejś degradacji typu, że zrzucenie jednego loga to 1 sekunda. Nie nie. To jest liczone bardziej w mili, czy może mikrosekundach, ale jeżeli pracujecie w warunkach, w których każda milisekunda jest dla Was istotna to może to odgrywać istotną rolę - zważywszy na to, że ilość odkładanych logów będzie naprawdę duża. 
2. Znacznie zwiększony wolumen logów - bo jest ich znacznie więcej - to się może przełożyć też na zwiększone koszty

Dlatego decyzję o ustawieniu poziomu logowania na swoich produkcyjnych systemach zostawiam Wam: 
1. możecie pójść standardowym rozwiązaniem i zostać przy wszystkim powyżej INFO
2. możecie pójść w rozwiązanie które proponuje, czyli zostać przy wszystkim powyżej DEBUG - ale biorąc pod uwagę wady które wcześniej opisałem
3. lub nawet pójść w bardziej ekstremalne rozwiązanie i logować wszystko dopiero od poziomu WARNING wzwyż - z czym też możecie się spotkać: argument za tym jest następujący: jeżeli wszystko działa poprawnie, czyli innymi słowy: nie rzucane są warningi, errory i criticale - to po co w ogóle przechowywać i patrzyć w logi? 

Także decyzję pozostawiam Wam... to co Wam najbardziej będzie odpowiadało, wyjdzie w tzw. "praniu" kiedy już nabierzecie doświadczenia i ogłady z logami na produkcji i z naprawianiem bugów i błędów... ale chciałbym żebyście byli świadomi opcji jakie macie.

Ok, podsumowując część CO logować: 
1. Najważniejsza rzecz - logi mają Wam pomóc w naprawie błędów - jeżeli dane działanie funkcji/metody/kodu jest dla Was istotne i uważacie, że dzięki wiedzy o działaniu tego kawałka kodu będzie w stanie lepiej śledzić działanie Waszego API i naprawić ewentualne błędy, to jak najbardziej dodajcie logowanie tego miejsca. 
2. Ważne jest dodanie dwóch najważniejszych metadanych do waszych logów:
	1. czas kiedy dany log powstał, abyście mogli ogarnąć co działo się najpierw a co potem. A drugim plusem dla Was jest też informacja o tym jak długo dana funkcja się wykonywała, więc dzięki temu też możecie zwrócić uwagę czy może coś działa za wolno
	2. oraz używanie odpowiednich poziomów, DEBUG, INFO, WARNING, ERROR, CRITICAL - to Wam pozwoli na przede pogrupowanie logów i ich łatwiejszą analizę no i to co przedchwilą powiedziałem - te poziomu logów również są używane do określenia, które logi ostatecznie będą pokazywane na produkcji, a które nie.


No dobrze... czy macie jakieś pytania do tej części, zanim przejdziemy dalej?

Troche już czasu mówię o logach, ale ten temat jest bardzo istotny. I jesteśmy dopiero w połowie. Jeżeli spojrzymy sobie na te logi, to widać, że wygląda one OK. Mamy czas przetwarzania, mamy informacje o tym jaki to jest typ loga i mamy treść wiadomości. Wygląda to na pierwszy rzut oka dobrze i wystarczająco. Ale tak łatwo i ładnie nie będzie. To co my teraz robimy to budujemy sobie API na razie lokalnie i wysyłamy sobie pojedynczy request raz na jakiś czas żeby zobaczyć czy nasze API działa tak jak chcemy. Ale w rzeczywistości tak nie bęðzie - w rzeczywistości naszych instancji API będzie kilka, kilkanaście lub kilkaset, a requestów podobnie - będzie ich kilka, kilkanaście lub kilkaset przychodzących NA SEKUNDĘ. Wasze logi będą wyglądać w taki sposób:

(zakomentuj wszystko co jest w `send_example_request.py`) i wrzuć ten kod:

```python
import asyncio  
import random  
import math  
  
import aiohttp  
  
  
async def fetch(s):  
    headers = {  
        "Content-Type": "application/json",  
    }    data = {  
        "installment_rate_in_percentage_of_disposable_income": 0.25,  
        "age_in_years": 40,  
        "foreign_worker": "yes",  
        "present_employment_since": "unemployed",  
        "personal_status_and_sex": "male: single",  
    }    await asyncio.sleep(math.ceil(random.random() * 5))  
    async with s.post(f"http://localhost:8080/decisions", headers=headers, json=data) as r:  
        if r.status != 200:  
            r.raise_for_status()  
        return await r.json()  
  
  
async def fetch_all(s):  
    tasks = []  
    for _ in range(10):  
        task = asyncio.create_task(fetch(s))  
        tasks.append(task)  
    res = await asyncio.gather(*tasks)  
    return res  
  
  
async def main():  
    while True:  
        async with aiohttp.ClientSession() as session:  
            htmls = await fetch_all(session)  
            print(htmls)  
  
  
if __name__ == "__main__":  
    asyncio.run(main())
```


A API uruchom jako:

```bash
gunicorn src.service.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8080
```

Uruchomie teraz API na 4 procesach i zaczne wysyłać do niego blisko po 10 requestów na raz, z różnymi odstępami czasowymi. Spójrzmy sobie na logi naszego API.

Jak widzicie logi pojawią się non stop, każdy request generuje mase logów. Nie wiem czy tutaj to widać, ale z racji tego, że mamy API uruchomione na 4 procesach, to mogą zdażyć się takie momenty, w których logi z jednego requesta będą zazębiać się z logami innego requesta. Pytanie powstaje, jak to wszystko analizować? Jak się w tym wszystkim połapać? Jak zorientować się, że ten log, który zaznaczam dotyczy jednego requesta, a ten log nad nim albo pod nim dotyczy tego samego? Może to już jest log z innego requesta? Przejdźmy zatem do tego jak można powiązać konkretne logi z danym zapytaniem do API, tak aby móc się w tym wszystkim połapać.

### Jak powiązać logi?

[[25.5. Middleware|Teraz trzeba omówić czy jest Middleware, aby móc przejść dalej]]

Stwórzmy sobie nowy folder `middlewares` w `service` i stwórzmy sobie plik `correlation.py`. Dlaczego nazwaliśmy plik `correlation.py` - to co nasz Middleware będzie robił to każdy request, zanim trafi do naszego widoku, czyli do naszych funkcji, które generują predykcję, będzie odpowiednio oznaczany pewnym identyfikatorem, który wykorzystamy do powiązania wszelkich zdarzeń zachodzących w API właśnie z tym identyfikatorem, tudzież z tym requestem. I technicznie ten identyfikator nazywa się właśnie Correlation ID.

Teraz od razu powiem na wstępie, że implementacja tego Middleware może Wam się wydać dosyć skomplikowana na pierwszy rzut oka. Ja postaram się zaimplementować to jak najprościej dla Was, natomiast będą elementy, które mogą być niejasne i część z tych rzeczy wyjaśnimy sobie teraz, a część dopiero przy temacie związanym z asynchronicznościa w FastAPI.  

Na początku `correlation.py` musimy zaimportować ContextVar i zdefiniować zmienną globalną `CORRELATION_ID`:

```python
from contextvars import ContextVar

CORRELATION_ID: ContextVar[str] = ContextVar("correlation_id", default="---")
```

Zaraz powiem co to jest `ContextVar` i do czego służy ta zmienna globalna, będzie mi łatwiej ją wyjaśnić jak już troche więcej kodu napiszemy

Następnie zaimportujmy sobie obiekty, które pomogą nam w implementacji.

```python
from starlette.types import ASGIApp, Receive, Scope, Send
```

Jak widzicie, zaimportowałem to z pakietu `starlette` - tak jak wspominałem, FastAPI opiera się w pełni na `starlette`. Niestety FastAPI nie ma tych 5-ciu obiektów w sobie. Powiem Wam więcej, że dokumentacja FastAPI na temat Middleware jest strasznie uboga - żeby móc zrozumieć jak się implementuje, trzeba sięgnąc do dokumentacji właśnie Starlette.

Następnie zaczynamy od implementacji naszego Middleware. Nazwijmy to i zdefiniujmy sobie inita.

```python
class CorrelationIdMiddleware:  
    def __init__(self, app: ASGIApp):  
        self.app = app
```

Czym jest te `ASGIApp`? o ASGI będziemy rozmawiać przy temacie asynchroniczności, ale to tak na prawdę jest nasz obiekt `FastAPI` - czyli inicjalizacja Middelware zakłada, że jednym z argumentów będzie po prostu zainicjowany obiekt `FastAPI`, czyli ten co mamy w `main.py` - czyli `app = FastAPI()`.

Dodajmy jeszcze do inita jedną rzecz:
```python
self.header_name = "X-Correlation-ID"
```
Tak jak mówiłem, nasz Middleware będzie oznaczał nasze requesty odpowiednim IDkiem. Aby móc dodawać wszelkie metadane odnośnie requesta, to trzeba dodać je w nagłówkach, dlatego stwórzyłem obiekt `header_name`. Przypominajka: wszelkie customowe nagłówki muszą zaczynać się od `X-` i mamy dalej `X-Correlation-Id` czyli każdy request będzie przychodził do naszych widoków z informacja o unikalnym IDku, który będzie przechowywany w jego nagłówkach. Do tej pory na razie jest wszystko jasne tak?

Teraz aby nasz Middleware działał to musimy zaimplementować jego logikę w metodzie `__call__`

```python
async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
```

Mam nadzieję, że pamiętacie co robi `__call__` w Pythonie - powoduje ona to, że z instancje danej klasy możecie wywoływać tak jak każdą inną funkcję, podając jej te trzy argumenty. O tym czym jest `async` bedziemy mówić później, przy temacie asynchroniczności.

Czym jest `scope`, `receive`, `send` to zaraz się wyjaśni.

Dalej musimy dodać taki kawałek kodu:

```python
if scope["type"] != "http":  
    await self.app(scope, receive, send)  
    return
```

Ok to teraz zatrzymajmy się tutaj i wyjaśnimy sobie co się tutaj dzieje.

Dodajmy sobie `breakpoint()` po return, czyli:

```python
async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:  
    if scope["type"] != "http":  
        await self.app(scope, receive, send)  
        return  
    breakpoint()
```

Następnie przejdźmy sobie do `main.py`

Zaimportujmy ten middleware:

```python
from src.service.middlewares.correlation import CorrelationIdMiddleware
```

I dodajmy go do naszej aplikacji

```python
app.add_middleware(CorrelationIdMiddleware)
```

Uruchomimy sobie API w trybie debugera, czyli przechodzimy do 

```python
if __name__ == "__main__":
```

I po lewej stronie uruchamiamy `Debug 'main'`, ale zanim to zrobimy to upewnijmy się w `Modify run configuration`, że ścieżki są prawidłowo ustawione na główny folder np. `/home/marcin/PycharmProjects/inzynier-ai-api-live-coding/`

Wyślijmy potem requesta `make request` i powinniśmy zatrzymać się w Middleware.

Teraz żeby łatwiej zrozumieć z czym mamy doczynienia, to można sobie w konsoli podejrzeć czym są `scope`, `receive` i `send`.

1. Obiekt `scope` to nic innego jak kontekst naszego requesta. Tak jak widzicie jest tutaj sporo metadanych. 
2. Natomiast `receive` oraz `send` - to to są funkcje. Teraz jeśli sobie je wpiszemy do konsoli to nic nam to za bardzo nie powie. Ale w tym przypadku `receive` to funkcja, która przetwarza `requesta`, czyli zapytanie które przyszło do API, a `send` to funkcja, która przetwarza nam `response` czyli naszą odpowiedź z naszego API. My możemy zdefiniować swoje własne funkcje `receive` oraz `send` właśnie po to aby Middleware mogło nam coś w nich modyfikować - i to zaraz będziemy robić. 

Ten kawałek kodu, który dodaliśmy, czyli:

```python
if scope["type"] != "http":  
    await self.app(scope, receive, send)  
    return
```

Oznacza, że jeżeli przyjdzie do naszego requesta inne zapytanie niż zapytanie HTTP to wtedy my po prostu te zapytanie wpuszczamy do naszego widoku praktycznie nic nie robiąc z requestem i odpowiedzą, bo domyślnie funkcje `receive` oraz `send` po prostu nic nie robią. Teraz ten kod może być niejasny... jak to może być inne zapytanie niż HTTP? Oprócz HTTP możecie spotkać się z tak zwanymi Websocketami, ale niestety nie omawiamy ich dlatego, że możecie się w życiu z nimi spotkać, ale wasze REST-owe API MLowe nie będzie używało web socketów. Ba... obsługę websocketów trzeba w ogóle zaimplementować u siebie w aplikacji - jest o tym obszerny rozdział w dokumentacji FastAPI. Jest jeszcze inny typ nazywa się `lifespan`, o `lifespan` będziemy mówić później. Niemniej jednak MUSIMY taki kawałek kodu dodać na początku każdego Middleware. Generalnie przy czytaniu kodu innych Middleware do FastAPI spotkanie się właśnie z takich IFem - który właśnie mówi, że wszelkie requesty które nie komunikują się poprzez HTTP to wtedy wpuść je do API, nic z nimi nie robiąc. 

Ok wyrzucamy ten breakpoint i zatrzymujemy debugera. Wracamy do kodzenia dalej.

Teraz ideą tego middleware jest to aby naszym requestom przyporządkować jakiś ID, po którym będą reprezentowane. Ja w tym celu skorzystam z pythonowej bilbioteki `uuid` i pobiore z niej funkcje `uuid4`

```python
from uuid import uuid4
```

UUID - oznacza Universal Unique Identifier. Zobaczmy sobie w konsoli co dostajemy:

```python
from uuid import uuid4
```

Następnie

```python
uuid4()
```

Jak widzicie, otrzymuje po prostu ID. Te ID posłuży nam do tego abyśmy mogli identyfikowac requesty. Ok. W takim razie ustawmy sobie nasze `CORRELATION_ID`.

```python
CORRELATION_ID.set(uuid4().hex)
```

Jeszcze raz sie powtórze -> czym jest CORRELATION_ID i czemu jest to zmienna globalna powiem jak już zaimplementujemy Middleware do końca. Chce zebyście zobaczyli całość, bo potem będzie mi się znacznie łatwiej wytłumaczyć o co tutaj chodzi.

Teraz to co my musimy zrobić, to tą wartość CORRELATION_ID po prostu zapisać w nagłówkach. Sprawa jest bardzo prosta. 

Pobieramy sobie obiekt z biblioteki Starlette:

```python
from starlette.datastructures import MutableHeaders
```

`MutableHeaders` pozwoli nam na dobranie się do nagłówków requesta. I wtedy w ciele Middleware piszemy tak:

```python
headers = MutableHeaders(scope=scope)  
headers.append(self.header_name, CORRELATION_ID.get())
```

I sprawa jest załatwione. Teraz po prostu pozwalamy naszej aplikacji na dalsze działanie, czyli dodajemy 

```python
await self.app(scope, receive, send)  
return
```

Ok to teraz chciałbym Wam pokazać, że to działa.

Wróćmy do naszego `main.py` i dodajmy `breakpoint` do naszego decisions. Następnie zróbmy tak jak robiliśmy na początku naszego zjazdu, tzn. dodajmy surowy request do endpointa, tylko po to żebyśmy mogli podejrzeć sobie co się dzieje.

```python
@app.post("/decisions")  
async def decisions(  
    request: DecisionRequest,  
    background_tasks: BackgroundTasks,  
    raw_request: Request,  
) -> DecisionResponse:
```

Uruchomimy API znowu w trybie debugera, wyślijmy requesta i zobaczmy co dostajemy. Jesteśmy w Debugerze i podejrzyjmy sobie co mamy w nagłówkach `raw_request.headers`. Jak widzicie, otrzymaliśmy te same metadane które wcześniej widzieliśmy w obiekcie `scope`. Ale oprócz tego jest również to co nas interesuje, czyli mamy ID naszego requesta w nagłówku `x-correlation-id`. Super. Middleware działa. Teraz do każdego requesta który zostałe wysłany do Waszego API będzie dodawany taki IDkich dzięki czemu odróżnimy logi jednego requesta od drugiego. 

I teraz czas na trudną część - jak wykorzystać wartość nagłówka requesta `x-correlation-id` w taki sposób aby pojawił się w naszych logach API?

Żeby to zrozumieć to musimy zacząc od końca. Chciałbym żebyśmy spojrzeli sobie na `src.utils.logging.` Tam jest taka funkcja jak `setup_logging_with_correlation_id`. Biblioteki do logowania pozwalają Wam na definiowanie tego jak Wasze logi powinny wyglądać. Wiem, że mówiłem, że nie będę skupiał się na tym jak działa konkretnie pythonowy `logging` pod spodem, bo każdy z Was może użyć docelowo innej bilbioteki. Ale generalnie idee, którą Wam przedstawię jest spójna w pozostałych bibliotekach do logowania, no bo one i tak wszystkie pod spodem opierają się na pythonowym `loggingu`, bo są po prostu nakładką na niego. A chciałbym żebyście wiedzieli dokładnie jak taka implementacja działa. Spójrzmy na to jak jest zdefiniowany formatter:

```python
sys_stdout_formatter = logging.Formatter("%(asctime)s - %(levelname)s - [%(correlation_id)s] - %(message)s")
```

Jeżeli spojrzymy sobie na to co jest w jego stringu i porównamy sobie z tym co dostaliśmy w konsoli, to można wydedukować co te wartości oznaczają. 
1. `asctime` w tym przypadku to metadana, która po prostu wskazuje obecny czas wypisania logu,
2. `levelname` to jest ten poziom logów - czyli DEBUG, INFO, WARNING, ERROR i CRITICAL
3. `message` z kolei to po prostu treść wiadomości loga - czyli to co my sami sobie zdefiniujemy w tych funkcjach `logging.info(...)`, `logging.exception(...)` itd.
4. Natomiast jak widzicie, pojawiło się coś takiego jak Correlation ID. Co to jest? Zescrolujmy sobie do góry i spójrzmy na implementację `CorrelationIdFilter`. Biblioteki do filtrowania pozwalają na implementacje tak zwanych filtrów, które mają w jakiś sposób po prostu segregować logi. Ich zastosowanie może być. np. wszystkie logi, które są ERRORAMI i CRITICALAMI możemy filtrować i zapisywać do plików. Natomiast w tym przypadku to co my robimy, to w zasadzie nie filtriujemy żadnych logów, tylko chcemy do nich dodać pewien atrybut. I w tym wypadku jest to właśnie `correlation_id` i ta wartość atrybutu to właśnie zmienna globalna `CORRELATION_ID`, która jest ustawiana poprzez Middleware.

Dzięki tej implementacji, my z tego `correlation_id` możemy skorzystać w naszych Formatterach, jeżeli dodamy do niego taki filtr.

Spójrzcie na:

```python
sys_stdout_formatter = logging.Formatter("%(asctime)s - %(levelname)s - [%(correlation_id)s] - %(message)s")
```
A następnie na:

```python
correlation_id_filter = CorrelationIdFilter()
sys_stdout_handler.addFilter(correlation_id_filter)
```

Dzięki temu, ten `correlation_id`, który ustawiany jest przez Middleware, będzie dostępny w logach poprzez tą zmienną globalną `CORRELATION_ID`.

Zobaczmy sobie w takim działanie teraz tego nowego ustawienia.

Wróćmy do `main.py`. Usuńmy sobie breakpointa oraz tego `raw_request` z endpointa, już nie będzie nam potrzebny.

Zamieńmy `setup_logging_with_formatters` na `setup_logging_with_correlation_id`

```python
from src.utils.logging import setup_logging_with_formatters  
  
setup_logging_with_correlation_id()
```

Włączmy API, wyślijmy requesta i zobaczmy efekt. Mamy to :) Zobaczcie, każdy log który widzicie, został odpowiednio oznaczony tym unikalnym ID, który został stworzony w Middlewarze i teraz bez problemu możemy je ze sobą powiązać.  Wyślijmy kolenego requesta żeby zobaczyć, że faktycznie ta wartość się zmienia.

Wróćmy sobie do `correlation.py` i wróćmy sobie do tego `CORRELATION_ID`. Ta zmienna globalna została zdefiniowana za pomocą takiego obiektu jak `ContextVar`. Teraz dlaczego tak jest. To jest bardzo ważne - bez tego, nie uda Wam się to poprawnie zaimplementować. Dlaczego? FastAPI działa wielowątkowo, asynchronicznie - o wielowątkowości i asynchroniczności dokładniej będziemy mówić później.  To co na ten moment jest istotne to to, że jeżeli jakieś procesy działają wielowątkowo, to oznacza to, że współdzielą ze sobą pamięć. Co to oznacza?  Gdybyśmy ten CORRELATION_ID zdefiniowali jako taka zwykła zmienna globalna np. tak

```python
CORRELATION_ID = JAKAS WARTOŚĆ (bez typowania, że jest to ContextVar)
```
Oczywiście, to jeszcze dalszy kod trzeba by zrefactorować żeby skorzystać z tej zmiennej. Problem z takim rozwiązaniem jest taki, że jeżeli przyjdą dwa requesty do Waszego API, które będą przetwarzane jednocześnie to istnieje bardzo duże prawdopodobieństwo, że wartość w `CORRELATION_ID` zostanie nadpisana przez ten drugi request. W efekcie czego ID pierwszego requesta zamieni się na ID drugiega request w trakcie jego przetwarzania. To będzie naprawde duży problem dla Was, bo logi się po prostu zepsują. 

Jak tego uniknąć? Właśnie Python dostarcza nam tak zwanych ContextVars, aby temu zapobiec. Jest cały [PEP 567](https://peps.python.org/pep-0567/#introduction) poświęcony temu zagadnieniu - ale straszczając: są to zmienne, które są zdefiniowane lokalnie, na danym wątku. I nie są współdzielone przez inne wątki. Czyli w przetwarzaniu wielowątkowym, każdy request, który działać będzie na swoim wątku, będzie miał swój ID unikalny, który niedostępny jest dla innych wątków i te inne wątki również nie są w stanie sobie tego IDka nadpisać. Dzięki temu nie będziecie mieli sytuacji, w której inny request nadpisze wartość `correlation_id` innemu requestowi, bo każdy z nich będzie miał swoją własną zmienną globalną `CORRELATION_ID`. 

Czy to co powiedziałem jest dla Was jasne?

Ok to teraz zobaczmy sobie to co zrobiliśmy w akcji. Ponownie zrobię tak jak poprzednio, czyli uruchomie API na 4 procesach i będę wysyłał kilka requestów na raz.

```bash
gunicorn src.service.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8080
```

```python
import asyncio  
import random  
import math  
  
import aiohttp  
  
  
async def fetch(s):  
    headers = {  
        "Content-Type": "application/json",  
    }    data = {  
        "installment_rate_in_percentage_of_disposable_income": 0.25,  
        "age_in_years": 40,  
        "foreign_worker": "yes",  
        "present_employment_since": "unemployed",  
        "personal_status_and_sex": "male: single",  
    }    await asyncio.sleep(math.ceil(random.random() * 5))  
    async with s.post(f"http://localhost:8080/decisions", headers=headers, json=data) as r:  
        if r.status != 200:  
            r.raise_for_status()  
        return await r.json()  
  
  
async def fetch_all(s):  
    tasks = []  
    for _ in range(10):  
        task = asyncio.create_task(fetch(s))  
        tasks.append(task)  
    res = await asyncio.gather(*tasks)  
    return res  
  
  
async def main():  
    while True:  
        async with aiohttp.ClientSession() as session:  
            htmls = await fetch_all(session)  
            print(htmls)  
  
  
if __name__ == "__main__":  
    asyncio.run(main())
```

Zobaczcie... mamy mnóstwo logów. Ale teraz połapanie się w tym wszystkim już jest znacznie prostsze. Bo każdy log jest oznaczony unikalnym ID reprezentującym dany request. Oczywiście Wy na produkcji nie bedzie patrzeć w taką konsolę, tylko używać będzie do tego usług do analizy logów a one pozwalają na filtorwanie logów po dowolnych wartościach i polach - zatem znalezienie w tym stosie logów dla danego requesta jest bardzo prosta - wystarczy odsiać je po konkretnym IDku... i w ten sposób uzyskacie całą historię przetwarzania danego requesta przez Wasze API.

No i jak sami widzicie, logi requestów się przeplatają, więc bez Correlation ID analiza logów jest praktycznie niemożliwa - Correlation ID musi być zaimplementowane w waszym API, koniec kropa.

Niestety ale to nie koniec pracy z logami... czy macie jakieś pytania do tego wszystkie co do tej pory Wam powiedziałem?

Zanim przejdziemy sobie do tematu obsługi błędów i ich logowania, ale już podejdziemy do tego całościowo, to porozmawiajmy sobie chwilę jak możemy nasze logi poprawić

### Jak usprawnić logi?

Pierwsza sprawa - jak widzicie, obecne logi to zwykły tekst. W zależności od tego jak dużo chcecie logować, to jednak pewne wpisy mogą stać się bardzo długie przez co nieczytelne. Pytanie jakie można zadać to oczywiście czy nie można tego jakoś uładnić oraz drugie ważne pytanie jak systemy obsługujące logi sobie radzą z takim tekstem?. Jeżeli zaczniecie korzystać z innych bibliotek do logowania, które pozwalają Wam na wrzucanie logów do jakiegoś systemu zewnętrznego, to oczywiście w tamtym systemie logi się będą ładnie wyświetlać, ale jak spojrzycie sobie w jakiej strukturze są logi, to zobaczycie że są one w JSONach. Dlaczego? Po prostu JSONa jest bardzo łatwo sparsować i wyciągnąć z niego dane. Zatem jeżeli myślicie o tym aby usprawnić swoje logi, to pierwszą rzeczą jaką możecie zrobić to zrezygnować z takich plain textów jak tutaj i przesiąść się na JSONy i w sumie jedną z najlepszych bibliotek w Pythonie jest [structlog](https://www.structlog.org/en/stable/). Jeżeli spojrzymy sobie do dokumentacji, to jest takie fajne zdjęcie to jest fajne zdjęcie które podsumowuje to co structlog Wam dostarczy. Spójrzmy sobie na nie.

1. Mamy przedwszystkim czas kiedy log powstał, 
2. jego poziom INFO, DEBUG, WARNING, ERROR itd. 
3. Treść wiadomości oraz z prawej strony wszelkie dodatkowe wartości zmiennych, które chcemy dodać do loga.
4. Kolorami się nie przejmujcie, bo one są widoczne tylko i wyłącznie w konsoli pythonowej, natomiast w tych usługach do analizy logów no takich kolorków mieć nie będziecie, więc to tylko taki bajer.
5. Natomiast co jest fajne w tej bibliotece, to to, że w momencie rzucenia błędów on również raportuje co znajduje się w zmiennej `locals()`, czyli dostajecie informacje o wartościach wszystkich obiektów, które są dostępne wewnątrz funkcji, w której napotkaliśmy błąd, co jest bardzo wygodne.

Druga sprawa - musicie pamiętać, że Wasze logi nie będą trzymane wiecznie. Oczywiście technicznie jest to możliwe - możecie tak ustawić - ale w rzeczywistości tak robić nie będziecie, bo koszty waszych logów będą cały czas rosły i rosły. To jak długo logi będą zachowane w systemie zależy przedewszystkim od ich rozmiaru i wolumenu - ile ich będzie przychodzić. To co jest często spotykane w tym kontekście to aby logi, które są istotne, a najczęściej bardziej istotne są te dotyczące błędów, były przechowywane gdzieś przez dłuższy okres. Dlatego dodatkową rzeczą którą warto mieć na uwadze jest zapisywanie logów do dedykowanego storage, które będą trzymane więcej czasu na potrzeby analizy błędów. Czyli można sobie wyobrazić dwa storage'y - jeden taki, który jest domyślny i wpadają tam wszystkie nasze logi i można z tego korzystać jako przeglądanie bieżących logów i przeważnie czas retencji jest krótki oraz drugi storage w którym trzymane są logi w momencie rzucenia błędami - ich storage może być znacznie dłuższy. Dłuższy dlatego, że chcemy mieć więcej czasu na analize tych przypadków. 

Ciekawą implementacją w celu przechowywania błędów może być zastosowanie `MemoryHandlera` z `FileHandlerem`, które dostępne są w pythonowym podstawowym module `logging`. Działa to tak, że `MemoryHandler` przetrzymuje w sobie np. ostatnie 1000 logów i w sytuacji napotkania błędu zapisuje, wywołuje `FileHandler` po to aby stworzyć plik do którego zostanie zlogowana treść błędu ORAZ 1000 logów, które nastąpiły tuż przed nim. Czyli w efekcie możemy dodatkowo przechować sobie całą historię tego co zadziało się tuż przed wystąpieniem błędów. Jest to ciekawe rozwiązanie dla osób, które np. uważają, że ustawienie poziomu `DEBUG` na produkcji jest kiepskim pomysłem. Albo w ogóle idą w skrajność - przy tym rozwiązaniu można mieć 2 pieczenie na jednym ogniu. Do tego 1-go storage idzie wszystko co jest od poziomu `INFO` i wyżej, a do drugiego pójdzie wszystko od poziomu `DEBUG` i wyżej ALE pod warunkiem wystąpienia błędu i na dodatek tylko ostatnie np. 1000 logów. Polecam w wolnej chwili przyjrzeć się tym implementacjom i spróbować to stworzyć - my tego tutaj na kursie nie bedziemy robić, bo zgodnie z moją zasadą - chce Wam przekazać wiedzę tyle żebyście mogli ją przyswoić - nie chce Was obrzucać wszystkimi mozliwymi implementacjami jakie istnieją bo po prostu cały weekend spędzimy zaraz tylko na logowaniu.

[[26. Wyłapywanie błędów|Teraz przechodzimy do kwestii związanych z wyłapywaniem błędów]]