# Definicja reprezentacji w API

1. Wróćmy teraz do naszego kodu i przyjrzymy się naszemu endpointowi. Tak jak widać, brzmi on `predict_decision` co bardziej odpowiada architekturze RPC niż REST, więc jest to rzecz do zmiany. 
2. Chciałbym Wam pokazać dwa sposoby podejścia do reprezentacji w serwisach MLowych, z którymi się spotkacie. Mają swoje zalety i wady i powiem Wam, którą ja rekomenduje.
3. Jak iwdzicie na ten moment mamy zdefiniowany jeden endpoint dla jednego rodzaju outputu z modelu. Jak przejdziemy sobie do klasy `CreditScoringModel` możemy zauważyć, że mamy 3 rodzaje outputów - decyzje, prawdopodobieństwa i kategoria ryzyka. Teraz.... jak można do tego podejść? Są dwa sposoby:
	1. Pierwszy z nich zakłada aby stworzyć oddzielne reprezentacje i w konsekwencji oddzielne endpointy dla każdego rodzaju outputu jaki model zwraca. Czyli mielibyśmy 3 reprezetnacje: `probabilities`, `decisions` oraz `risk_categories`
	2. Drugi sposób zakłada, aby stworzyć jedną reprezentację, która można by nazwać `predictions` natomiast to jaki rodzaj/kształt przyjmą te predykcje zależy od tego jakie parametry przekażemy do naszego żądania.
4. Zaczniemy od implementacji tego drugiego sposobu, czyli mamy jedną reprezentację `predictions` i odpowiednio będziemy sterować co chcemy otrzymać na wyjściu.
5. Na początek przejdźmy sobie do pliku `responses.py` i zdefiniujmy dodatkowe odpowiedzi, które będą nam teraz potrzebne. Zkopiujmy nasz `PredictDecisionResponse` i zmodyfikujmy odpowiednio:

```python
class PredictProbabilityResponse(BaseModelExtraFieldsForbidden):  
    probability: float = Field(  
        default=...,  
        title="Probability",  
        description="Probability of default for credit application.",  
    )  
  
class PredictRiskCategoryResponse(BaseModelExtraFieldsForbidden):  
    risk_category: RiskCategory = Field(  
        default=...,  
        title="Risk Category",  
        description="Risk category of credit application.",  
    )
```

W dodatku u góry zdefiniujemy sobie obiekt, który będzie przechowywał nam jakie mamy rodzaje odpowiedzi, to nam znacznie pomoże przy implementacji tego sposobu, który teraz robimy:

```python
from enum import Enum

class ResponseType(str, Enum):  
    decision = "decision"  
    probability = "probability"  
    risk_category = "risk_category"
```

6. Ok mamy to teraz przejdźmy do naszego `main.py` i zmodyfikujmy odpowiednio nasz endpoint aby obsłużyć te rozwiązanie. Zaimportujmy sobie nasze nowe odpowiedzi:

```python
from src.service.schemas.responses import (  
    PredictDecisionResponse,  
    PredictRiskCategoryResponse,  
    PredictProbabilityResponse,  
    ResponseType,
)
```

7. Zacznijmy od tego aby nazwać nasz endpoint tak jak powinniśmy w przypadku tego rozwiązania i będzie to po prostu `predictions`.

```python
@app.post("/predictions")  
async def predictions(request: PredictRequest) -> PredictDecisionResponse:
```

Nasze ciało funkcji trzeba teraz odpowiednio zmodyfikować, aby móc obsłużyć te trzy rodzaje outputów. Aby móc to osiągnąć musimy zaimportować sobie jeszcze dwa elementy - jeden z `fastapi`, drugi z `typing` czyli:

```python
from fastapi import Query
from typing import Annotated
```

i dodajmy do naszego endpointa:

```python
@app.post("/predictions")
async def predictions(
    request: PredictRequest,
    response_type: Annotated[ResponseType, Query()],
) -> PredictDecisionResponse:
```

Teraz co to jest za dziwny twór? Jak Wam mówiłem na początku, FastAPI bardzo mocno opiera się o type hintowanie - to pozwala mu na generowanie automatycznie dokumentacji naszego API oraz na przekształcanie naszych obiektów w odpowiednie inne obiekty żeby nasze API działało tak jak chcemy. 

Teraz czym jest ten `Annotated`? Pokaże Wam na prostszym przykładzie, załóżmy że jest tutaj jakiś prosty parametr `param`, któremu nadam `Annotated[str]`, czyli mówimy, że jest to typu param typu string, natomiast wszelkie pozostałe argumenty, to są metadane, które mogą nam coś mówić o tym parametrze.

Czyli w naszym przypadku mamy `response_type`, które będzie typem `ResponseType`, a drugi parametr mówi, że jest to instancja klasy `Query()` z FastAPI. Ten obiekt `Annotated` jest po to aby dodawąc metadane do naszych typów, które później mogą zostać wykorzystane przez twórców różnych bibliotek pythonowych, które chciałyby się po prostu oprzeć o te metadane i je wykorzystać w działaniu swojej biblioteki. I w przypadku FastAPI tak jest, on wykorzystuje Annotated w wielu różnych miejscach. Tutaj mamy przykład wykorzystania `Query()` o którym zaraz powiem więcej co to jest.

Dodajmy sobie na dole `print(f'{response_type=}')` żeby zobaczyć co otrzymamy teraz na wejściu. Przejdźmy sobie do `send_example_request.py` i tam musimy dodać jeden nowy argument czyli `params` oraz zmieńmy sobie wywołanie endpointa, bo teraz nazywa sie `predictions`

```python
params = {"response_type": "decision"}

url = "http://localhost:8080/predictions"
response = requests.post(url=url, headers=headers, json=data, params=params)
```

Uruchomimy sobie API, wyślijmy requesta i zobaczmy co otrzymaliśmy. Otrzymaliśmy tą samą odpowiedź co wcześniej. Przejdźmy teraz do konsoli z API i zobaczmy co mam tam w logach.

Zobaczcie:  czyli otrzymałem naszego Enuma `ResponseTyp` z wartością `decision` - OK.
Natomiast zobaczcie tutaj niżej na `"POST /predictions?response_type=decision HTTP/1.1" 200 OK`

Został dodany do naszego endpointa taki string jak `?response_type=decision`. To są tak zwane parametry "query", które służą do określenia pewnych czynności jakie chcemy aby zostały wykonane na odpowiedziach, które otrzymamy z danego endpointu.
Przykładamy takich query mogą być np.:
	1. `/items?filter=shoes` - czyli rzeczy, które mogą mięc w swojej nazwie `shoes`
	2. `/items?sort=ascending&field=create_date` - posortuj rosnąco po dacie utworzenia
	3. `/items?start=10&end=20` - czyli paginacja, wyświetl mi od 10 do 20 obiektu. 
	4. Zatem w naszym przypadku `/predictions?response_type=decision` będą określać to w jakim typie chcemy zobaczyć nasze odpowiedzi.

Teraz ktoś z Was może się zastanawiać  Dlaczego umieszczamy taką informację w parametrach query a nie np. w nagłówkach? To jest bardzo dobre pytanie. W Headers umieszczamy metadane, czyli informacje o Nas (w żądaniu) jak i o serverze (w odpowiedziać) np. mogą to być tokeny/klucze które uwierzytelniają naszą osobę, dodatkowe informacje o tym jakiego typu dane wysyłamy do servera, czy jest to JSON, XML, czy zwykły string, czy chcemy bądź nie chcemy żeby nasze żądania były zapisywane w pamięci podręcznej itd. Natomiast jeżeli chcemy wykonać wszelkie manipulacje bezpośrednio na reprezentacjach zwracanych z API - filtorwanie, sortowanie, zmiana formatu - to umieszczamy to w Query. Granica między tymi może być momentami cienka i raczej to już w praktyce będziecie "czuli" co bardziej pasuje do Query a co bardziej do nagłówków.

To teraz wrócmy do naszego `main.py` i zmodyfikujmy sobie kod żeby zwracać odpodzie w zależności od parametru `response_type`. Teraz bardzo ważne. to co napisze to będzie brzydka ifologia, ale chce żebyście zobaczyli, że to działa oraz co najwazniejsze jak dokumentacja jest potem wyrenderowana. 
```python
    if response_type == ResponseType.decision:
        return PredictDecisionResponse(decision=model.predict_decision(request.to_dataframe())[0])
    elif response_type == ResponseType.risk_category:
        return PredictRiskCategoryResponse(risk_category=model.predict_risk_category(request.to_dataframe())[0])
    elif response_type == ResponseType.probability:
        return PredictProbabilityResponse(probability=model.predict_proba(request.to_dataframe())[0])
```

Tą ilofogię którą napisałem możnaby zaimplementować w oddzielnej klasie, która ma logikę wyboru funkcji z modeli w zależności od `response_type` ale nie chciałem się rozpisywać teraz i poświęcać na to czas, bo zaspoileruje i powiem, że tej metody nie rekomenduje i ostatecznie w naszym API tutaj nie będziemy jej implementować i używać, zrobimy coś innego. 

Uruchommy nasze API, i spróbujmy odpytać je i zobaczyć czy to działa. Pozmieniajmy w `params` w `send_example_requests` wartości i zobaczmy czy jest wszystko zwracane poprawnie. Wpiszmy też złą nazwę parametru i zobaczmy co dostaniemy. Dostaliśmy błąd wraz z informacją co jest mozliwe a co nie, dzięki zastosowaniu Enumów. I teraz najważniejsza rzecz - zobaczmy sobie jak wygląda dokumentacja naszego API w takim przypadku - wejdźmy sobie na `/redoc`: 
	1. Widzimy, że została dodana informacja o `query`, że jest wymagane i jakie wartości są akceptowalne.
	2. Wejdźmy w odpowiedzi i zobaczmy, że mamy teraz 3 rodzaje odpowiedzi i możemy sobie przeklikać i zobaczyć co dostaniemy. Rozwiązanie działa, ma się dobrze.

Te podejście jest atrakcyjne z naszego punktu widzenia, developerskiego, bo możemy mieć jeden endpoint, w którym zdefiniujemy sobie logikę wybierania funkcji z modeli w zależności od wartości w parametrze query. Ale nie tak jak ja zrobiłem na szybko IFologie, tylko warto byłoby zaimplementować oddzielną klasę, która tą logikę ma w sobie zaimplementowaną i wywołanie metod z niej tutaj w kodzie - ja to zrobiłem tylko na szybko, żeby Wam pokazać, ze działa. 

Natomiast ja go nie rekomenduję, dlatego, że z własnego doświadczenia korzystania z takich API oraz z doświadczenia innych osób korzystających z takich API wynika... że korzystanie z takich API jest po prostu nieprzyjemne, pod tym kątem że mamy endpoint wraz ze zmieniającymi się outputami w zależności od jakiegoś parametru. Nawet jeżeli udokumentowalibyście ten parametr bardzo dokładnie, wręcz łopatologicznie, że przekazanie takiej wartości oznacza, że otrzymasz tają odpowiedź i np. szczegóły tej odpowiedzi znajdziesz w innym miejscu w dokumentacji. A z kolei w odpowiedziach możnaby zawrzeć, że tą konkretną odpowiedź otrzymasz wtedy kiedy w parametrach przekażesz taką wartość. Ale pomimo tego dużego i dokładnego opisu, wciąż w osobach korzystających z Waszego API będzie nutka zastanowienia i zwiątpienia. I zawsze trafi się ktoś kto poprosi Was, "czy możesz przesłać mu przykładowe zapytanie aby otrzymać prawdopodobieństwo bo on nie rozumie jak ma z tego skorzystać". Więc Wasza robota z piękna dokumentacją pójdzie na marne. W dodatku w zależności od modeli jakie bęðziecie implementować tych rodzaji odpowiedzi może być więcej i naprawdę robi się tego po prostu za dużo. Żeby łatwiej Wam to zwizualizować wróćmy do naszego `CreditScoringModel` bo ten problem można przedstawić w innym miejscu. Założmy że chcielibyśmy zdefiniować jedną funkcje `predict`, która zwraca trzy różne odpowiedzi. Nie wiem jakie macie doświadczenia, ale dla mnie korzystanie z takich funkcji jest zdecydowanie trudniejsze i mniej jasne niż gdybym miał funkcje rozbite na 3 mniejsze, tak jak jest wyżej. W programowaniu istnieje taki anti-pattern jak God Object albo God Class. To ja jak widzę takie funkcje to od razu zapala mi się w głowie lampka, że tutaj jest chyba za dużo logiki zaimplementowanej w jednej funkcji i trzeba to zrefactorować. Najgorzej jeszcze jak inny Data Scientist wymyśli sobie, że `features` może być kilkoma różnymi typami na raz 
`features: pd.DataFrame | pd.Series | np.array | list` i jeszcze obok jakiś parametr który steruje co chcemy dostać za odpowiedź. Może teraz przesadziłem z tym przykładem, ale u mniej doświadczonych programistów spotykam się z takimi rozwiązaniami, bo wygląda to fancy - napiszmy jedną super funkcję, bo będzie to super. Ale w rzeczywistości korzystanie z takich rzeczy jest masakryczne. A w dodatku jeszcze NAPISANIE TESTÓW JEDNOSTKOWYCH do czegoś takiego jest katorgą. Ale zakładam, że osoby piszące w ten sposób z pistaniem testów mają nie wiele wspólnego, bo gdyby próbowali to otestować, to zobaczyli jaki jest problem i tą funkcje po prostu uprościli. Także bazując na tym przykładzie, chce Wam przekazać, że korzystanie z takich endpointów (i analogicznie funkcji) jest po prostu niewygodne i obarczone błędami. To co ja proponuje i to co się dobrze sprawdza, to po prostu rozbicie ogólnego endpointa z reprezetnacją `predictions` na oddzielne endpointy i określenie reprezentacji bardziej precyzyjnie.

Ten endpoint `predictions` zostawimy sobie, żebyście mogli mieć porównanie. Sprawa w tym przypadku jest bardzo prosta. Skopiujmy sobie ten endpoint i go pozmieniajmy

1. `/decisions`:
```python
@app.post("/decisions")  
async def decisions(request: PredictRequest) -> PredictDecisionResponse:  
    return PredictDecisionResponse(decision=model.predict_decision(request.to_dataframe())[0])
```
2. `/risk_categories`:
```python
@app.post("/risk_categories")  
async def risk_categories(request: PredictRequest) -> PredictRiskCategoryResponse:  
    return PredictRiskCategoryResponse(risk_category=model.predict_risk_category(request.to_dataframe())[0])
```
3. `/probabilities`:
```python
@app.post("/probabilities")  
async def probabilities(request: PredictRequest) -> PredictProbabilityResponse:  
    return PredictProbabilityResponse(probability=model.predict_proba(request.to_dataframe())[0])
```

Włączmy API i sprawdźmy sobie `/redoc`, zobaczmy jak wygląda dokumentacja. Więc mamy 3 różne endpointy. które określają już precyzyjniej reprezentację na której nasze metody HTTP będą wykonywały akcje. Nie mamy ogólnej reprezentacji `predictions` i sterowania outputem. Tylko po prostu dany endpoint reprezentujący `Decisions`. Wymagane inputy i odpowiedź, która jest... Decyzją. Analogicznie Risk Categories i Probabilities.

Teraz zobaczmy czy odpytywanie jeszcze działa. Zmieńmy sobie `send_example_requests.py`

```python
# params = {"response_type": "probabilities"}
url = "http://localhost:8080/decisions"
response = requests.post(url=url, headers=headers, json=data)
```

Jakie są zalety tego podejścia:
1. Uproszczone odpytywanie: odpytuje już znacznie precyzyjniejszą reprezentację `Decisions`, `Probabilities`, `Risk Categories`, a nie ogólną `Predictions`, więc też jest łatwiej zrozumieć co otrzymam z endpointa.
2. Nie mamy już parametru `query`, tylko po prostu odpytujemy konkretny endpoint `decisions`, `probabilities`, `risk_categories` i otrzymujemy taki typ odpowiedzi na jaki wskazuje dokumentacja jak i sama nazwa endpointu.
3. Po trzecie, takie rozwiązanie jest zgodne z naszymi regułami programowania, a dokładnie z SRP czyli Single Responsible Principle - dana funkcja implementuję jedną logikę/jedną rzecz. 
4. Wadą takiego rozwiązania może być dla Was to, że kod się powiela. Bo potem w dalszej części kursu będziemy implementować kolejne rzeczy i trochę tutaj nowych linii kodu się pojawi, który musi być w każdym endpoincie. Tak, ale potem pokaże Wam jak to zrefactorować, żeby trzymać się zasady DRY - Dont Repeat Yourself. Ale to dopiero na końcu kursu. 

I teraz na koniec - to jest moja rekomendacja, wynikająca z doświadczenia. Natomiast to jaką Wy wybierzecie - należy do Was. Dla własnego rozwoju możecie nawet raz to, raz to. Po to abyście poczuli na własnej skórze, które rozwiązanie bardziej Wam odpowiada od strony programistycznej ale przede wszystkim od strony UŻYTKOWNIKA WASZEGO API. Czy łatwiej mu jest skorzystać z 3 różnych prostszych endpointów, czy 1-dnego "powszechnego". W projekcie swoim możecie wybrać to albo to - pozostawiam Wam. Ale ze swojej strony, nie rekomenduję tego pojdeścia z jednym "generalnym" endpointem.

My w swoim kursie zostaniemy przy rozwiązaniu tym z 3 endpointami i jego bęðziemy dalej rozwijać. W takim razie pozbądźmy się rzeczy, których już nie potrzebujemy. 

(Do usunięcia endpoint `predictions` w `main.py`)
(Do usunięcia `ResponseType` w `responses.py`)

I na koniec pozmieniajmy nazwy tych klas, żeby lepiej odpowiadały naszym endpointom.
 W tym celu proponuje skorzystać z PyCharmowego prawy myszy -> refactor -> rename a w VS CODE (DO SPRAWDZENIA JAK JEST W VSCODE), wtedy te nazwy zaktualizują się wszędzie gdzie są używane.

1. `PredictDecisionResponse` -> `DecisionResponse`
2. `PredictProbabilityResponse` -> `ProbabilityResponse`
3. `PredictRiskCategoryResponse` -> `RiskCategoryResponse`

Dodajmy też klasę abstrakcyjną, która grupować będzie nasze odpowiedzi:

```python
from abc import ABC  
  
  
class BaseResponse(ABC, BaseModelExtraFieldsForbidden):  
    pass
```

Pytanie: dlaczego definiujemy taką pustą abstrakcyjną klasę?

I dziedziczmy po niej w naszych odpowiedziach:

```python
class DecisionResponse(BaseResponse):  
    decision: Decision = Field(  
        default=...,  
        title="Decision",  
        description="Decision whether the credit application has been accepted or not.",  
    )  
  
class ProbabilityResponse(BaseResponse):  
    probability: float = Field(  
        default=...,  
        title="Probability",  
        description="Probability of default for credit application.",  
    )  
  
class RiskCategoryResponse(BaseResponse):  
    risk_category: RiskCategory = Field(  
        default=...,  
        title="Risk Category",  
        description="Risk category of credit application.",  
    )
```

Zróbmy to samo w w `requests.py`

1. `PredictRequest` zamienie na `BaseRequest`.  Oraz dodatkowo dziediczmy po `ABC` W tym celu proponuje skorzystać z PyCharmowego prawy myszy -> refactor -> rename a w VS CODE (DO SPRAWDZENIA JAK JEST W VSCODE), wtedy te nazwy zaktualizują się wszędzie gdzie są używane.

```python
from abc import ABC


class BaseRequest(ABC, BaseModelExtraFieldsForbidden):
	(...)
```

Oraz dodajmy klasy:

```python
class DecisionRequest(BaseRequest):
    pass


class RiskCategoryRequest(BaseRequest):
    pass


class ProbabilityRequest(BaseRequest):
    pass
```

Dlaczego je dodaje? Ja już troche wiem co będziemy dalej implementować, więc przygotowuje sobie już klasy na przyszłą implementację. Natomiast gdybyśmy mieli zakończyć prace nad naszym API dokłądnie w tym momencie, to nie trzeba by było dodawać tych klas i ich używać - można by zostać przy jednej klasie, tak jak mieliśmy u góry.

Których użyjemy w `main.py`

```python
from src.service.schemas.requests import (
    DecisionRequest,
    RiskCategoryRequest,
    ProbabilityRequest,
)
```

I dalej w endpointach:

```python
@app.post("/decisions")
async def decisions(request: DecisionRequest) -> DecisionResponse:
    return DecisionResponse(decision=model.predict_decision(request.to_dataframe())[0])


@app.post("/risk_categories")
async def risk_categories(request: RiskCategoryRequest) -> RiskCategoryResponse:
    return RiskCategoryResponse(risk_category=model.predict_risk_category(request.to_dataframe())[0])


@app.post("/probabilities")
async def probabilities(request: ProbabilityRequest) -> ProbabilityResponse:
    return ProbabilityResponse(probability=model.predict_proba(request.to_dataframe())[0])
```



https://www.torocloud.com/blog/using-query-parameters-and-headers-in-rest-api-design

