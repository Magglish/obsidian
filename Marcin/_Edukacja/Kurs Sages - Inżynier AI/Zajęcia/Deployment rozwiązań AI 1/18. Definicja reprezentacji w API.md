# Definicja reprezentacji w API

1. Wróćmy teraz do naszego kodu i przyjrzymy się naszemu endpointowi. Tak jak widać, brzmi on `predict_decision` co bardziej odpowiada architekturze RPC niż REST, więc jest to rzecz do zmiany. 
2. Chciałbym Wam pokazać dwa sposoby podejścia do reprezentacji w serwisach MLowych, z którymi się spotkacie. Mają swoje zalety i wady i powiem Wam, którą ja rekomenduje.
3. Jak iwdzicie na ten moment mamy zdefiniowany jeden endpoint dla jednego rodzaju outputu z modelu. Jak przejdziemy sobie do klasy `CreditScoringModel` możemy zauważyć, że mamy 3 rodzaje outputów - decyzje, prawdopodobieństwa i kategoria ryzyka. Teraz.... jak można do tego podejść? Są dwa sposoby:
	1. Pierwszy z nich zakłada aby stworzyć oddzielne reprezentacje i w konsekwencji oddzielne endpointy dla każdego rodzaju outputu jaki model zwraca. Czyli mielibyśmy 3 reprezetnacje: `probabilities`, `decisions` oraz `risk_categories`
	2. Drugi sposób zakłada, aby stworzyć jedną reprezentację, która można by nazwać `predictions` natomiast to jaki rodzaj/kształt przyjmą te predykcje zależy od tego jakie parametry przekażemy do naszego żądania.
4. Zaczniemy od implementacji tego drugiego sposobu, czyli mamy jedną reprezentację `predictions` i odpowiednio będziemy sterować co chcemy otrzymać na wyjściu.
5. Na początek przejdźmy sobie do pliku `responses.py` i zdefiniujmy dodatkowe odpowiedzi, które będą nam teraz potrzebne. Zkopiujmy nasz `PredictDecisionResponse` i zmodyfikujmy odpowiednio:

```python
class PredictProbabilityResponse(BaseModelExtraFieldsForbidden):  
    probability: float = Field(  
        default=...,  
        title="Probability",  
        description="Probability of default for credit application.",  
    )  
  
class PredictRiskCategoryResponse(BaseModelExtraFieldsForbidden):  
    risk_category: RiskCategory = Field(  
        default=...,  
        title="Risk Category",  
        description="Risk category of credit application.",  
    )
```

W dodatku u góry zdefiniujemy sobie obiekt, który będzie przechowywał nam jakie mamy rodzaje odpowiedzi, to nam znacznie pomoże przy implementacji tego sposobu, który teraz robimy:

```python
from enum import Enum

class ResponseType(str, Enum):  
    decision = "decision"  
    probability = "probability"  
    risk_category = "risk_category"
```

6. Ok mamy to teraz przejdźmy do naszego `main.py` i zmodyfikujmy odpowiednio nasz endpoint aby obsłużyć te rozwiązanie. Zaimportujmy sobie nasze nowe odpowiedzi:

```python
from src.service.schemas.responses import (  
    PredictDecisionResponse,  
    PredictRiskCategoryResponse,  
    PredictProbabilityResponse,  
    ResponseType,
)
```

7. Zacznijmy od tego aby nazwać nasz endpoint tak jak powinniśmy w przypadku tego rozwiązania i będzie to po prostu `predictions`.

```python
@app.post("/predictions")  
async def predictions(request: PredictRequest) -> PredictDecisionResponse:
```

Nasze ciało funkcji trzeba teraz odpowiednio zmodyfikować, aby móc obsłużyć te trzy rodzaje outputów. Aby móc to osiągnąć musimy zaimportować sobie jeszcze dwa elementy - jeden z `fastapi`, drugi z `typing` czyli:

```python
from fastapi import Query
from typing import Annotated
```

i dodajmy do naszego endpointa:

```python
@app.post("/predictions")
async def predictions(
    request: PredictRequest,
    response_type: Annotated[ResponseType, Query()],
) -> PredictDecisionResponse:
```

Teraz co to jest za dziwny twór? Jak Wam mówiłem na początku, FastAPI bardzo mocno opiera się o type hintowanie - to pozwala mu na generowanie automatycznie dokumentacji naszego API oraz na przekształcanie naszych obiektów w odpowiednie inne obiekty żeby nasze API działało tak jak chcemy. 

Teraz czym jest ten `Annotated`? Pokaże Wam na prostszym przykładzie, załóżmy że jest tutaj jakiś prosty parametr `param`, któremu nadam `Annotated[str]`, czyli mówimy, że jest to typu param typu string, natomiast wszelkie pozostałe argumenty, to są metadane, które mogą nam coś mówić o tym parametrze.

Czyli w naszym przypadku mamy `response_type`, które będzie typem `ResponseType`, a drugi parametr mówi, że jest to instancja klasy `Query()` z FastAPI. Ten obiekt `Annotated` jest po to aby dodawąc metadane do naszych typów, które później mogą zostać wykorzystane przez twórców różnych bibliotek pythonowych, które chciałyby się po prostu oprzeć o te metadane i je wykorzystać w działaniu swojej biblioteki. I w przypadku FastAPI tak jest, on wykorzystuje Annotated w wielu różnych miejscach. Tutaj mamy przykład wykorzystania `Query()` o którym zaraz powiem więcej co to jest.

Dodajmy sobie na dole `print(f'{response_type=}')` żeby zobaczyć co otrzymamy teraz na wejściu. Przejdźmy sobie do `send_example_request.py` i tam musimy dodać jeden nowy argument czyli `params` oraz zmieńmy sobie wywołanie endpointa, bo teraz nazywa sie `predictions`

```python
params = {"response_type": "decision"}

url = "http://localhost:8080/predictions"
response = requests.post(url=url, headers=headers, json=data, params=params)
```

Uruchomimy sobie API, wyślijmy requesta i zobaczmy co otrzymaliśmy. Otrzymaliśmy tą samą odpowiedź co wcześniej. Przejdźmy teraz do konsoli z API i zobaczmy co mam tam w logach.

Zobaczcie:  czyli otrzymałem naszego Enuma `ResponseTyp` z wartością `decision` - OK.
Natomiast zobaczcie tutaj niżej na `"POST /predictions?response_type=decision HTTP/1.1" 200 OK`

Został dodany do naszego endpointa taki string jak `?response_type=decision`. To są tak zwane parametry "query", które służą do określenia pewnych czynności jakie chcemy aby zostały wykonane na odpowiedziach, które otrzymamy z danego endpointu.
Przykładamy takich query mogą być np.:
	1. `/items?filter=shoes` - czyli rzeczy, które mogą mięc w swojej nazwie `shoes`
	2. `/items?sort=ascending&field=create_date` - posortuj rosnąco po dacie utworzenia
	3. `/items?start=10&end=20` - czyli paginacja, wyświetl mi od 10 do 20 obiektu. 
	4. Zatem w naszym przypadku `/predictions?response_type=decision` będą określać to w jakim typie chcemy zobaczyć nasze odpowiedzi.

Teraz ktoś z Was może się zastanawiać  Dlaczego umieszczamy taką informację w parametrach query a nie np. w nagłówkach? To jest bardzo dobre pytanie. W Headers umieszczamy metadane, czyli informacje o Nas (w żądaniu) jak i o serverze (w odpowiedziać) np. mogą to być tokeny/klucze które uwierzytelniają naszą osobę, dodatkowe informacje o tym jakiego typu dane wysyłamy do servera, czy jest to JSON, XML, czy zwykły string, czy chcemy bądź nie chcemy żeby nasze żądania były zapisywane w pamięci podręcznej itd. Natomiast jeżeli chcemy wykonać wszelkie manipulacje bezpośrednio na reprezentacjach zwracanych z API - filtorwanie, sortowanie, zmiana formatu - to umieszczamy to w Query. Granica między tymi może być momentami cienka i raczej to już w praktyce będziecie "czuli" co bardziej pasuje do Query a co bardziej do nagłówków.

To teraz wrócmy do naszego `main.py` i zmodyfikujmy sobie kod żeby zwracać odpodzie w zależności od parametru `response_type`. Teraz bardzo ważne. to co napisze to będzie brzydka ifologia, ale chce żebyście zobaczyli, że to działa oraz co najwazniejsze jak dokumentacja jest potem wyrenderowana. 
```python
    if response_type == ResponseType.decision:
        return PredictDecisionResponse(decision=model.predict_decision(request.to_dataframe())[0])
    elif response_type == ResponseType.risk_category:
        return PredictRiskCategoryResponse(risk_category=model.predict_risk_category(request.to_dataframe())[0])
    elif response_type == ResponseType.probability:
        return PredictProbabilityResponse(probability=model.predict_proba(request.to_dataframe())[0])
```

Tą ilofogię którą napisałem możnaby zaimplementować w oddzielnej klasie, która ma logikę wyboru funkcji z modeli w zależności od `response_type` ale nie chciałem się rozpisywać teraz i poświęcać na to czas, bo zaspoileruje i powiem, że tej metody nie rekomenduje i ostatecznie w naszym API tutaj nie będziemy jej implementować i używać, zrobimy coś innego. 

Uruchommy nasze API, i spróbujmy odpytać je i zobaczyć czy to działa. Pozmieniajmy w `params` w `send_example_requests` wartości i zobaczmy czy jest wszystko zwracane poprawnie. Wpiszmy też złą nazwę parametru i zobaczmy co dostaniemy. Dostaliśmy błąd wraz z informacją co jest mozliwe a co nie, dzięki zastosowaniu Enumów. I teraz najważniejsza rzecz - zobaczmy sobie jak wygląda dokumentacja naszego API w takim przypadku - wejdźmy sobie na `/redoc`: 
	1. Widzimy, że została dodana informacja o `query`, że jest wymagane i jakie wartości są akceptowalne.
	2. Wejdźmy w odpowiedzi i zobaczmy, że mamy teraz 3 rodzaje odpowiedzi i możemy sobie przeklikać i zobaczyć co dostaniemy. Rozwiązanie działa, ma się dobrze.

Te podejście jest atrakcyjne z naszego punktu widzenia, developerskiego, bo możemy mieć jeden endpoint, w którym zdefiniujemy sobie logikę wybierania funkcji z modeli w zależności od wartości w parametrze query. Ale nie tak jak ja zrobiłem na szybko IFologie, tylko warto byłoby zaimplementować oddzielną klasę, która tą logikę ma w sobie zaimplementowaną i wywołanie metod z niej tutaj w kodzie - ja to zrobiłem tylko na szybko, żeby Wam pokazać, ze działa. 

Natomiast ja go nie rekomenduję, dlatego, że z własnego doświadczenia korzystania z takich API oraz z doświadczenia innych osób korzystających z takich API wynika... że korzystanie z takich API jest nieprzyjemne, pod tym kątem że mamy endpoint wraz ze zmieniającymi się outputami w zależności od jakiegoś parametru. Nawet jeżeli udokumentowalibyście ten parametr bardzo dokładnie, wręcz łopatologicznie, że przekazanie takiej wartości oznacza, że otrzymasz tają odpowiedź i np. szczegóły tej odpowiedzi znajdziesz w innym miejscu w dokumentacji. A z kolei w odpowiedziach możnaby zawrzeć, że tą konkretną odpowiedź otrzymasz wtedy kiedy w parametrach przekażesz taką wartość. Ale pomimo tego dużego i dokładnego opisu, wciąż w osobach korzystających z Waszego API będzie nutka zastanowienia i zwiątpienia. I zawsze trafi się ktoś kto poprosi Was, "czy możesz przesłać mu przykładowe zapytanie aby otrzymać prawdopodobieństwo bo on nie rozumie jak ma z tego skorzystać". Więc Wasza robota z piękna dokumentacją pójdzie na marne. W dodatku w zależności od modeli jakie bęðziecie implementować tych rodzaji odpowiedzi może być więcej i naprawdę robi się tego po prostu za dużo. Żeby łatwiej Wam to zwizualizować wróćmy do naszego `CreditScoringModel` i ten problem z tym rozwiązaniem możnaby odnieść ta, że chcielibyśmy zdefiniować jedną funkcje `predict`, która zwraca trzy różne odpowiedzi. Nie wiem jakie doświadczenia, ale dla mnie korzystanie z takich funkcji jest zdecydowanie trudniejsze i mniej jasne niż gdybym miał funkcje rozbite na 3 mniejsze, tak jak jest wyżej. W programowaniu istnieje taki anti-pattern jak God Object albo God Class


https://www.torocloud.com/blog/using-query-parameters-and-headers-in-rest-api-design

