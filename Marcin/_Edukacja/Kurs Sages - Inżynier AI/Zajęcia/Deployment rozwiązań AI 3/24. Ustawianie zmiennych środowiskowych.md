# Ustawianie zmiennych środowiskowych

  

Natomiast To co chciałbym z wami przećwiczyć to  jak napisać API aby można było jednocześnie korzystać sobie z baz danych lokalnie uruchomionych poprzez kontenery np. poprzez docker-compose ii jak potem przenieść te nasze rozwiązanie tak żeby można było korzystać z baz danych  dostępnych na chmurze, ale bez przyszłych zmian w kodzie.

  

A czy zmiany w kodzie musimy teraz poczynić żeby  dostosować nasze API do takiej sytuacji ale jak już to zrobimy to później jakby sterowanie to tym Do jakiej bazy się łączymy czy lokalnie czy czy na chmurę jest bardzo przyjemne i proste.  Wróćmy sobie na naszym kodu na API I zobaczmy sobie funkcję startup która  inicjalizując że API i między innymi tworzy połączenia z naszymi bazami danych.

  

Jak widzicie kot jest bardzo prosty tworzymy sobie connectory które są odpowiedzialne właśnie za trzymanie połączenia z naszą bazą danych - jest to `redis_connector` oraz `postgres_connector`. Od razu wam powiem do czego dążymy -  żeby móc sobie sterować naszym API to czy ono  odpytuje bazy danych uruchomionych lokalnie poprzez kontenery czy odpytuje bazę danych na chmurze po prostu wykorzystamy zmienne środowiskowe. Dlaczego akurat zmienia środowiskowy?  to sie wyjaśni jak już to zaimplementujemy. 

  

Ustawialiśmy na środowisko robisz z poziomu terminala ale jest to tylko i wyłącznie ustawienie na czas naszej sesji,  Natomiast tutaj w tym celu wykorzystamy dedykowany plik w którym będziemy takie zmienne środowiskowe tworzyć i nazywa się `.env`. Stwórzmy sobie taki plik jak `.env`. Teraz co będziemy w nim umieszczać?  wszystkie niezbędne parametry do połączenia z naszymi bazami danych. 

  

Dodajmy go sobie też do `.gitignore` oraz do `.dockerignore`.

  

 musimy sobie na to jak jest zaimplementowane nasz  konektor do redisa. On wymaga dwóch informacji `host` oraz `port`.  w takim razie utwórzmy sobie takie zmienne środowiskowe z których później skorzystamy w naszym `env`:

  

```env

REDIS_HOST=127.0.0.1

REDIS_PORT=6379

```

  

Teraz zobaczmy jak wygląda nasz connector dla Postgresa.  widzimy że wymagany jest `host`, `port`, `database`, `user` i `password` Zatem dodajmy sobie te zmienne środowiskowe do `.env`:

  

```env

POSTGRES_HOST=127.0.0.1

POSTGRES_PORT=5432

POSTGRES_DATABASE=monitoring

POSTGRES_USER=monitoring

POSTGRES_PASSWORD=12345

```

  

Okej czyli mamy zestaw wszystkie zmienne środowiskowych które nam są w tej chwili potrzebne żeby połączyć się z naszymi bazami danych.  Teraz po prostu musimy z nich skorzystać w naszym kodzie.

  

 aby załadować tego do Ewa musimy dodać sobie bibliotekę do naszego środowiska bo chyba je brakuje nam:

  

```bash

poetry add python-dotenv

```

  

Teraz przejdźmy sobie do naszego `src/service/main.py`  i Dodajmy import  jednej funkcji z tej biblioteki oraz sama biblioteke `os`, która zaraz nam sie przyda:

  

```python

from dotenv import load_dotenv

import os

```

  

I na samym dole w `if __name__ == "__main__":` Musi po prostu dodać załadowanie naszego `.env` do środowiska zanim nasze API zostanie uruchomione:

  

```python

if __name__ == "__main__":

    load_dotenv()

  

    uvicorn.run(

        app=app,

        host="0.0.0.0",

        port=8080,

        workers=1,

        reload=False,

    )

```

  

I następnie Wróćmy sobie do  kodu który Inicjuje konektory  i skorzystajmy sobie z tych zmiennych środowiskowych w momencie kiedy po prostu inicjujemy konektory:

  

Dla Redisa:

  

```python

    redis_connector = RedisConnector(

        host=os.getenv('REDIS_HOST'),

        port=os.getenv('REDIS_PORT')

    )

```

  

Dla Postgresa:

  

```python

    postgres_connector = PostgresConnector(

        host=os.getenv('POSTGRES_HOST'),

        port=os.getenv('POSTGRES_PORT'),

        database=os.getenv('POSTGRES_DATABASE'),

        user=os.getenv('POSTGRES_USER'),

        password=os.getenv('POSTGRES_PASSWORD')

    )

```

  

I żebyśmy mieli pewność że to faktycznie działa to spróbujmy sobie najpierw API uruchomić lokalnie:

  

## SPRAWDŹ CZY TO ZADZIAŁA, BO NIE URUCHOMIŁEŚ TEGO NA KOMPIE

## W DOCKER COMPOSE TRZEBA SIE TERAZ ODWOLAC DO ZMIENNYCH SRODOWISKOWYCH Z .env ZEBY TO ZADZIAŁAŁO

  

```bash

docker compose up

```

  

Jak widzicie działa.  Czyli po prostu za pomocą zmiennych środowiskowych teraz będziemy sterować połączenie z naszą bazą danych. 

  

To co jeszcze musimy zrobić to po prostu utworzyć nowy kontener i go wrzucić na naszą chmurę z tymi zmianami zmianami w naszym kodzie:

  

```bash

docker build -t europe-central2-docker.pkg.dev/GCLOUD_PROJECT/mrybinski-live-coding-api/api:with-services-env -f deploy/docker/api/Dockerfile .

```

 I go spushować do repozytorium:

  

```bash

docker push europe-central2-docker.pkg.dev/GCLOUD_PROJECT/mrybinski-live-coding-api/api:with-services-env

```

  

Okej w takim razie mamy nowy obraz to teraz musimy go użyć w naszym deeplaymacie.  Po pierwsze pozbądźmy się tych kontenerów które mają sobie redisa i Postgresa.

  

A w naszym deeplaymencie  zaktualizujmy Obraz którego używamy właśnie w naszym deeplemencie na ten nowy który teraz rzuciliśmy przed chwilą:

  

```yaml

    spec:

      containers:

        - name: api

          image: europe-central2-docker.pkg.dev/sotrender-rd/mrybinski-live-coding-api/api:with-services-env

          ports:

            - containerPort: 8080

              name: predictions

          readinessProbe:

            periodSeconds: 5

            timeoutSeconds: 5

            failureThreshold: 3

            successThreshold: 1

            httpGet:

              port: 8080

              path: /

```

  

Natomiast sama zmiana obrazu to jest niewystarczająca.  to co my musimy zrobić teraz to właśnie  ustawić nasze zmienne środowiskowe w deploymencie  i wskazać na nasze bazy danych które są w chmurze. I do tego służy parametr `env`, który jest listą zmiennych środowiskowych. Ustawmy  wszystko oprócz hostów na razie:

  

```yaml

      containers:

        - name: api

          image: europe-central2-docker.pkg.dev/sotrender-rd/mrybinski-live-coding-api/api:with-services-env

          ports:

            - containerPort: 8080

              name: predictions

          env:

            - name: REDIS_HOST

              value:

            - name: REDIS_PORT

              value: "6379"

            - name: POSTGRES_HOST

              value:

            - name: POSTGRES_PORT

              value: "5432"

            - name: POSTGRES_DATABASE

              value: monitoring

            - name: POSTGRES_USER

              value: monitoring

            - name: POSTGRES_PASSWORD

              value: "12345"

```

  

Hasło na razie wpisałem po prostu z Palucha  w naszym deploymencie natomiast to nie jest dobra praktyka, ale zajmiemy się tym później. 

  

Teraz co wpisać w `REDIS_HOST` i `POSTGRES_HOST`? Tutaj trzeba wskazać po prostu adres naszej bazy danych, teraz W zależności od tego czy ona będzie miała taką ładną nazwę hosta tak to było z naszym API,  czy ma tylko IP No musimy tu wpisać to co jest po prostu dostępne. 

  

Zacznijmy od redisa. Jak spojrzymy sobie teraz na te dane to Widzimy tutaj informacje o andpoint który ma informacje o ipku oraz porcie.  to co musimy zrobić po prostu to wrzucić ten IP tutaj do zmiennej środowiskowej `REDIS_HOST`

  

Tak samo robimy z Postgresem. Tutaj z kolei  Widzicie że macie rozróżnienie na Publiczne i Prywatne adres IP.  Generalnie rzecz biorąc przeważnie wasze bazy danych będą osiągane tylko i wyłącznie po prywatnym ip-ku schowanym w jakiejś sieci wewnętrznej No bo generalnie te bazy danych to są wasze dane i nie chcecie żeby one w jakikolwiek sposób były osiągalne z zewnątrz.  w tym przypadku znowu biorę tego ipka i wrzucam do `POSTGRES_HOST`.

  

Okej czyli ten sposób udało nam się skonfigurować wszystko co potrzebne jest  do tego żeby połączyć z naszymi bazami danych. Teraz słowo komentarza Dlaczego użyliśmy zmiany środowiskowych i czy jest jakiś inny sposób?  generalnie Niestety w kuberatesie jedyną możliwością żeby móc z poziomu manifestów w jakikolwiek sposób manipulować działaniem naszych serwisów postawionych są właśnie tylko i wyłącznie zmienne środowiskowe.  dlatego też tutaj my z tych zmiennych środowiskowych skorzystaliśmy.  i generalnie korzystanie ze zmiennych środowiskowych jest bardzo wygodne,  bo właśnie możemy nimi zarządzać z poziomu lokalnego komputera poprzez plik `.env`  co też jest bardzo często stosowaną praktyką i dobrą praktyką żeby zmieniać środowiskowe właśnie używać poprzez plik `.env` bo on przeważnie też nie jest w ogóle commitowany do repozytorium więc  możecie tam umieścić swoje hasła  Przez co nie  są nigdzie z hardcodowane w kodzie tylko po prostu pobierane są one z środowiska i każdy deweloper można sobie do tego wrzucić co chce,  ustawić swoje własne hasło i tak dalej przez co korzystanie z różnych rozwiązań jest po prostu bezpieczne.  a wtedy w przypadku diplometrów po prostu ustawiamy też zmienne środowiskowe  w naszym  manifeście i one są potem używane konkretnie w naszym API.  więc sterowanie naszymi dyplomatami poprzez zmianę środowiskowa jest właśnie powszechnie stosowaną praktyką.  Natomiast tutaj ja na razie wpisałem hasło z palca  co jest złą praktyką  ale tym zajmiemy się za chwilę najpierw sprawdźmy czy to działa. Wdróżmy nasz nowy deployment:

  

```bash

kubectl apply -f deploy/k8s/deployment.yaml

```

  

Jak widzicie udało się.  ale jest jeden problem.  Zobaczcie Czy wciąż w pozie mamy te kontenery z naszym redisem i postgresem,  a nie mamy ich w ogóle  w manifeście. Natomiast zobaczmy  sobie na manifest deploymentu w chmurze który jest  i zobaczycie że tutaj faktycznie nastąpiła aktualizacja naszego kontenera z API o ten nowy obraz oraz o zmianę środowi  ale wciąż  zostały te kontenery stare.  Dlaczego tak się stało?  caplay po prostu patrzy na różnicę pomiędzy tym manifestem który jest na produkcji  a tym który teraz wdrażamy  i po prostu widzi że nie było żadnych zmian w kontenerze z postgresem i redisem.  natomiast spodziewalibyśmy się raczej innego zachowania że skoro nie ma ich w ogóle w manifeście to znaczy że w ogóle nie powinno być go w podzie. Jak sobie z tym poradzić? Tak jak Wam na początku wspominałem  są komendy deklaratywne i imperatywne jeśli chodzi o sposób wdrażania na Kubernetesa. Apla jest komendą deklaratywną Czyli po prostu wskazujemy że chcemy żeby zaaplikował nasz manifest natomiast kubernetes sam z siebie zadecyduje czy  utworzyć nowy obiekt bo widzisz że tego już wcześniej nie ma,  Czy właśnie jest zaktualizować coś co już istnieje.  w tym przypadku on zaktualizował tylko nasz kontener z API,  pozostałymi kontenerami czyli Pocurlstgresem i Redisem  nic nie zrobił No bo nie było żadnych zmian w manifeście na ich temat bo ich w ogóle nie ma Natomiast on to potraktował że nic na nich nie zmieniamy.  żeby w takiej sytuacji sobie z tym poradzić to musimy użyć imperatywną komendę po prostu `replace`  Która wprost wskaże Komar razowi że chcemy zamienić deployment na ten nowy całkowicie:

  

```bash

kubectl replace -f deploy/k8s/deployment.yaml

```

  

W ten sposób mamy nową wersję naszego Poda już z tylko kontenerem  z naszym API. I nie obawiajcie się komendy replace bo ona też  zaktualizuje nasze diyployment korzystając z tej techniki RollingUpdate która sobie ustawiliśmy  i też ta zmiana zostanie zapisane jako kolejna rewizja Więc spokojnie można będzie wrócić do poprzedniej  rewizji jeżeli coś się nie uda. 

  

No dobrze w takim razie skoro  widzimy że to się świeci na zielono jest w sta `Running`  to upewnijmy się jeszcze że faktycznie nasz API będzie wysyłał dane do bazy danych. Wyślę requesta:

  

```bash

curl http://api.mrybinski.JAKAS_DOMENA.com/decisions -X POST -H "Content-Type: application/json" -d '{"installment_rate_in_percentage_of_disposable_income": 0.25, "age_in_years": 40, "foreign_worker": "yes", "present_employment_since": "unemployed", "personal_status_and_sex": "male: single"}'

```

  

I sprawdźmy sobie logi naszego Deploymentu:

  

```

kubectl logs deployment/credit-scoring-api --namespace=mrybinski

```

  

Widzimy że zostało to zapisane naszej bazy danych.  Możemy też to sprawdzić w konsoli związanej z bazami danych Redis i Postgres bo są tam wykresy  związane z  bazami np. W radiu można dostrzec że pojawił się nowy klucz,  czyli właśnie ten nasz zapis z tego requesta który Teraz  przyszedł do naszego API. 

  

Okej więc mamy omówioną kwestię związaną z  ustawianiem  naszych zmiennych  środowiskowych które pozwolą wam właśnie na sterowanie z którą bazą danych macie połączenie w zależności od tego czy jest uruchoma lokalnie czy  na produkcji.  natomiast Na sam koniec została nam kwestia tego hasła ponieważ nie chcemy żeby żadne hasła znajdowały się jakikolwiek kodach jako plain text.

**