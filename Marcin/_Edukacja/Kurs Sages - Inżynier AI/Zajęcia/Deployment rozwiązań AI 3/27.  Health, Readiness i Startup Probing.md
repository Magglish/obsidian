# Health, Readiness i Startup Probing

  

Okej Przechodzimy teraz do dwóch bardzo ważnych tematów bez których moim zdaniem żaden deeplayment nie powinien trafić na produkcję.  wcześniej kazałem wam dodać taki parametr jak `readinessProbe`, O której czas teraz żebyśmy porozmawiali.  Generalnie rzecz biorąc z samej treści parametru które tam ustawiliśmy można się domyślić o co chodzi.  wysyłany jest request  naszego serwisu na ścieżkę określoną w `path`  na porcie 8080. To o czym z wami Chciałbym porozmawiać teraz to właśnie probing w Kubernetesie,  czyli Innymi słowy mechanizm który kubernetes wykorzystuje aby określić czy nasze Pody są gotowe do przyjmowania ruchu.

  

Jeżeli nie ustawimy żadnego probingu, a są ich trzy rodzaje, To kubernetes będzie zakładał że wasz Pod jest gotowy do przyjmowania requestów  Generalnie od razu jak się pojawi i  jak pobierze kontener. Co nie do końca jest prawdą.  Bo jak dobrze wiemy zanim nasze API będzie przyjmowało requesty to musi  się zainicjować,  w tym musi po prostu  wgrać model oraz zainicjować połączenia z naszymi bazami danych  czyli To wszystko co zdefiniowaliśmy sobie w funkcji `startup`,  a to już  jakiś czas trwa,  Jest to krótki moment w którym nasze API jeszcze nie będzie w stanie przyjąć żadnego requesta,  a już otrzyma zapytanie które nie zostanie obsłużone i zwrócona zostanie 500-tka.  to jest bardzo prosty przykład od którego zaczniemy  aby ustawić nasz pierwszy probing który będzie mówił o tym kiedy nasze API będzie gotowe do przyjmowania requestów.

  

Tak jak  mówiłem mamy trzy rodzaje probingu. Jak spojrzymy sobie na dokumentację poda,  to cały ten promień zdefiniowany jest w  rozdziale `Lifecycle`.  wyróżniamy trzy probingi: `livenessProbe`, `readinessProbe` oraz `startupProbe` i omówimy je sobie wszystkie, ale zaczniemy od tego, który pierwszy następuje czyli od `startupProbe`. Jak widzicie każdy z tych parametrów Jest typem `Probe`,  więc jak nauczymy się teraz konfiguracji pierwszego próba to każdy kolejny będzie konfigurowany tak samo ale każdy z nich ma zupełnie inne cele. 

  

Probing to nic innego jak pewna  operacja która potwierdzi czy nasz pod jest zainicjowany,  czy nasz pod jest zdrowy i działa,  Czy nasz jest w stanie przyjmować requesty. To  jak zdefiniujemy sprawdzenie czy nasz Pod działa poprawnie  bardzo mocno zależy od tego jaką aplikację tutaj wdrażamy.   i te sprawdzanie  jego żywotności Pozwala na przykład na uruchamianie cyklicznej jakiejś komendy w `bash` która coś sprawdza i na tej podstawie możemy stwierdzić że nasze aplikacje działa -  i w tym celu na przykład służy parametr `exec`,  w którym podajemy właśnie tą komendę  i jeżeli komenda zwróci exit Code = 0  to oznacza to że nasza aplikacja działa poprawnie.

  

Innym sposobem sprawdzenia jest wysłanie requesta do naszego API  i my to będziemy robić w przypadku naszego API.  czyli kubernetes cyklicznie będzie odpytywał nasze API żeby sprawdzić czy wszystko jest okej.  i do tego służy parametr `httpGet`,  w którym właśnie będziemy definiować to jaki endpoint odpytać aby kubereca stwierdzić czy nasze API działa poprawnie.

  

Są też możliwości związane ze sprawdzeniem tego czy w ogóle port działa do tego służy parametry `tcpSocket`,  czy nawet jeżeli ktoś z was stworzy API,  który nie odpytuje się protokołem HTTP a na przykład grpc, to też jest do tego parametr `grpc`. 

  

Jest tutaj kilka parametrów do ustawienia natomiast  będę je omawiał  w trakcie ich definiowania. 

  

I bardzo ważne co chciałbym podkreślić to to że ten probing który będę omawiał będę omawiał w kontekście API REST-owego, stworzonego w Fast API. To ma też swoje pewne implikacje jak ten Probing będzie wyglądał. Jeżeli będziecie definiować inne API w innym frameworku, To te rzeczy  które będą omawiał musicie odnieść i sprawdzić czy w tym worku który wy będzie oficjalnie korzystać działa to podobnie czy może inaczej  i trzeba będzie wasz probing dostosować do tego jak ten framework działa. Niestety ale próbnik jest bardzo mocno zależy od tego właśnie w czym wasza aplikacja jest stworzona. 

  

Okej to w takim razie wróćmy naszego Manifestu z naszym Deploymentem.  usuńmy ten redines Pro żeby nam tutaj nie psuł widoku  i zaraz go na nowo zdefiniujemy.

  

Zaczynamy sobie od kolejnej definicji sprawdzenia,  czyli `livenessProbe`, Czyli w tym parametrze będziemy definiować jak Kubernetes ma sprawdzić, czy nasze API jest żywe i działa.

  

My w przypadku naszego probingu będziemy  bazować po prostu na requesta wysłanych do naszych API  i na bazie odpowiedzi z API będziemy wiedzieć czy API działa czy nie -  To jest najczęściej stosowana praktyka w próbniku w kontekście aplikacji który po prostu odpytuje się ptokołem HTTP,  czyli w naszym przypadku nasze API.  w tym parametrze HTP get jest wiele różnych opcji jak widzicie, ale wystarczył dwa na początek żeby nasze sprawdzenie działało:  jest to określenie portu i endpointa:

  

```yaml

          startupProbe:

            httpGet:

              port: 8080

              path: /health

```

  

To co zdefiniowaliśmy oznacza że do naszego API będzie wysyłane request protokołem HTTP i  będzie to request typu GET, Ten reque zostanie wysłany do API na port 8080  na endpoint o nazwie `/health`. Teraz Czym jest ten endpoint `/health`? Tutaj od razu zaspoileruję wam że w przypadku `startupProbe`  jak i `livenessProbe`, które poznamy później,  będziemy używać tego samego endpointa. Endpointy które właśnie używane są do określenia czy API działa czy nie są najczęściej nazywane jak `/health`, `/health_check`, `/ready`, `/liveness` itp. Ja postawie na endpoint o nazwie `/health`. 

  

My natomiast tego endpointa nie mamy jeszcze nasz API więc my musimy zdefiniować teraz logikę sprawdzenia czy nasze API działa,  Czyli Innymi słowy my musimy zdefiniować tego endpointa. 

  

Wróćmy sobie do naszego API do `src/service/main.py` i zdefiniujemy sobie endpoint `/health`, który będzie bardzo prosty w swojej budowie:

  

```python

@app.get("/health")

def health_check() -> PlainTextResponse:

    return PlainTextResponse("Healthy")

```

  

Teraz zaskoczę was zdaniem ale: powiem że to jest koniec naszego endpointa. I generalnie endpoint który używany jest do `livenessProbingu` Właśnie wygląda tak jak teraz patrzycie czyli  wraz z od pytaniem zwracamy od razu odpowiedź Healthy.  domyślnie każda  odpowiedź z fast API zwraca `status_code=200`,  Gdyby było inaczej to musielibyśmy to wprost wskazać dodatkowym argumencie `PlainTextResponse`  ale my właśnie chcemy tym zatkać więc nic tutaj nie wprowadzam. I generalnie jeżeli kubernetes wyśle nam zapytanie  do tego endpointa i dostanie status code 200,  to uznaje że nasze API działa poprawnie i bardzo ważne co teraz powiem - nie wymaga restartu. No właśnie?  Co się stanie jeżeli nasza API zwróci nam inny status Code niż 200?  i kiedy to się może stać bo tak naprawdę z samego Endpointa nie wynika kiedy możemy spodziewać się status code innego niż 200? Zaraz to wyjaśnię tylko jeszcze doprowadzimy ustawienia tego parametru do końca tak żeby mieć jego pełny obraz. 

  

 Wróćmy teraz do naszego Manifestu I ustalmy jeszcze pozostałe cztery bardzo ważne parametry tak żeby ten nasz probing działał tak jak chcemy. Są to parametry: `periodSeconds`, `timeoutSeconds`, `failureThreshold`, `successThreshold`. 

  

Zaczniemy sobie od początku:

  

1. `periodSeconds` -  jak sama nazwa wskazuje mówi o tym jak często kubernetes ma wysyłać zapytanie do naszego endpointa. defaultowa  wartość wynosi tutaj 10 sekund, I generalnie w praktyce odpytywanie co 10 sekund jest w zupełności wystarczające. Ustawmy to sobie.
    
2. `timeoutSeconds` - Czyli jak długo kubernetes czeka na odpowiedź z naszego endpointa.  on tutaj ma ustawioną wartość 1 sekundę. To też jest  wystarczające,  ale ja z własnego doświadczenia tym bardziej jak serwisy są mocno obciążone to jest większa sobie tą wartość na przykład do trzech czy pięciu sekund. 
    
3. `failureThreshold` - To liczba requestów które musi przyjść ze statusem innym niż 200, bardzo ważne, pod rząd, Aby kubernetes uznał wraca z uznał że ten nasz pod nie działa i należy go zrestartować. I domyśla wartość 3 też jest jak najbardziej rozsądna 
    
4. `successThreshold` - Liczba sukcesów czyli minimalna liczba requestów ze status code 200 Aby uznać że serwis działa poprawnie.  tutaj generalnie zawsze stawia się 1.  to dokumentacja nawet jeżeli jest Must be one for lifeness and startup. Ale nawet w readinessProbe 1 w zupełności wystarczy
    

  

```yaml

          livenessProbe:

            httpGet:

              port: 8080

              path: /health

            periodSeconds: 10

            timeoutSeconds: 5

            failureThreshold: 3

            successThreshold: 1

```

  

Okej czyli mamy nasz teraz Pełny obraz naszego pierwszego Probingu. Który ma za zadanie sprawdzić nasze API działa,  A będąc precyzyjnym - czy nasze API żyje. jak sama nazwa wskazuje - livenessProbing. Ten livenessProbing nie sprawdza czy nasze API działa funkcjonuje poprawnie to znaczy czy nasze API zwraca requesty bez żadnych błędów. Tego w zakresie liveness się nie robi. Generalnie nie ma próbingu który by mówił czy nasze API zwraca poprawnie odpowiedzi,  to już jest element monitoringu na przykład ustawienia alertów jeżeli właśnie wrzucone zostanie błąd, a błąd pojawi się dzięki temu że logujemy wszystkie zdarzenia które zadziały się w naszym API.  natomiast w Kubernetesowym probingu tego nie ustawimy, to już trzeba zrobić w dedykowanej innej usłudze. Ten probing który tutaj ustawiliśmy służy do tego czy  API żyje  i nie wymaga restartu.  to jest jego podstawowy cel. 

  

Kiedy w takim razie może się zdarzyć że nasze API nie żyje.  sprawa jest stosunkowo prosta. Jeżeli  wdrożycie Apis z jakimś błędem w kodzie które spowoduje to że wasze API nie jest w stanie nawet się zainicjować,  Załóżmy że zaimportowaliście jakąś bibliotekę której nie macie,  odwołujecie się do jakiejś zmiennej która  nie istnieje,  w efekcie czego No wasze API nawet nie będzie w stanie się zainicjować.   i załóżmy że to przegapiliście, wdrożyliście takie API na produkcję,  i w sytuacji gdy  kubernetes stworzy poda,  to co 10 sekund będzie wyśle zapytanie do endpointa `/health`,  będzie czekał 5 sekund na odpowiedź z naszego endpointa. Ale on odpowiedzi w ogóle nie dostanie, dlatego że w naszym API jest jakiś bug powodujący to że nawet API się nie uruchomi. Spróbuję tak odpytać waszego poda, aż  nie otrzyma żadnego requesta ze statusem 200 przez co najmniej  tyle ile określiliśmy `failureThreshold`  i w związku zaistniałą sytuacją, Kubernetes w takiej sytuacji będzie restartował poda z nadzieją że po restarcie będzie on funkcjonował poprawnie. Oczywiście  w takiej sytuacji restart Poda  nie rozwiąże  żadnych problemów. Bo po restarcie sytuacja się powtórzy. I pytanie teraz jak się dowiemy że mamy taki problem na produkcji?  Jeżeli taki Pod  będzie się wielokrotnie restartował i tak w tej sytuacji będzie,  że ten Pod będzie się restartował  w kółko, to Kubernetes to zauważy że jest taki problem i dostaniecie taki błąd o nazwie CrashLoopBackOff  i nagle Wasz serwis będzie świecił się na czerwono. I na taki błąd można ustawić alerty żeby dostać powiadomienie właśnie że nasz Deployment wpadł w pętle CrashLoopBackOff. I wtedy musimy zdiagnozować  w logach co takiego się dzieje że nie działa Pod.

  

drugi problem jaki macie się spotkać produkcji. Wdrażacie coś co już jest poprawne,  ale na przykład wysyłacie requesta do API i on wisi, nie otrzymujecie żadnej odpowiedzi.  gdybyście poczekali  ileś tam minut dokładnie ile to jest chyba 5  to dostajecie w końcu status code 503 Service Unavailable albo 504 Gateway Timeout. I tak samo będzie właśnie w przypadku liveness probuingu w takiej sytuacji,  te requesty  od kubernetesa Będą wisieć  i nie będzie on  odpowiedzi w założonym czasie `timeoutSeconds`  5 sekund. Jeśli będzie miał 3 takie requesty pod rząd, które nie dają odpowiedzi,  to znowu Kubernetes  zrestartuje nam poda z nadzieją że restart pomoże.  jeżeli dalej będzie restartował się w kółko no to znowu dostajemy błąd o nazwie CrashLoopBackOff  i można na to mieć ustawione alerty że jeżeli taki sytuacja się nastąpi to żebyśmy dostali maila i wtedy dostajemy informację zwrotą że coś jest nie tak na szybki.  Co może być powodem, Tego że wasze requesty wiszą - tzn. wysłaliście je ale w ogóle nie dostaliście odpowiedzi w założonym czasie? Powodów może być wiele ale w takiej sytuacji najczęściej  mogło to być związane kwestie z siecią. Może jest jakiś problem z ingresem?  A może jakiś jest bug w definicji serwisu i macie źle zdefiniowany LabelSelector w efekcie czego Service nie grupuje żadnych podów w sobie? Powodów może być wiele,  natomiast dzięki temu że ten liveness  został przez was skonfigurowany to  w efekcie Pod może wejść wtedy w ten status CrashLoopBackOff dzięki czemu Taki błąd zostanie wychwycony przez wasz monitoring. 

  

 Oczywiście są też sytuacje takie że faktycznie restart Poda naprawia problem. Natomiast co byśmy gdybyśmy nie mieli tego  livenessProbingu  w tych dwóch opisane przeze mnie sytuacjach? Akurat w pierwszej on nie byłby potrzebny Bo generalnie w takiej sytuacji nasze API by się po prostu wywaliło  i kubernetes widziałby że faktycznie serwis się wywalił,  bo generalnie  w pythonie jest tak że jeżeli jakiś kod się wywali to po prostu zwraca status  a dokładnie exit code różny od 0,  bo exit code równy 0 oznacza, że wszystko jest okej. Więc jakby logika działania Pythona powie kubernesowi że Słuchaj ten kod się wywala i on wtedy go restartuje. 

  

 natomiast z tym drugim przypadku  to niestety ale Wasz serwis cały czas byłby na zielono gdyby nie livenessProbing  i w takiej sytuacji dowiedzielibyście się o problemie dopiero od klienta.  albo na monitoringu serwisów zobaczylibyście że nagle żadne requesty do was nie przychodzą. W ten sposób też byście się dowiedzieli o problemie  ale znacznie później. 

  

Więc  jak najbardziej  warto  definiować `livenessProbe`.  w dodatku też zobaczycie jak `livenessProbe` funkcjonuje z `readinessProbe` bo one się wzajemnie bardzo fajnie uzupełniają I wtedy będzie jeszcze jeden argument za zastosowaniem livenessProbe. 

  

Natomiast jeszcze wrócę do  definicji endpointa. Bo jak widzicie Ona jest bardzo bardzo prosta.  ale  tak bardzo prosty endpoint już daje wam bardzo dużą informacji  w sytuacji gdy No po prostu nie będzie on odpowiadał.

  

Natomiast czytając o  health checkach Spotkacie się z podejściem takim żeby sprawdzić czy na przykład inne serwisy na których nasze API bazuje działają i na tej podstawie określić czy faktycznie nasze API jest gotowe. I to jest jak najbardziej zasadne żeby to sprawdzić,  natomiast  ma zdefiniowany inny probing pod taki use-case który działa zupełnie inaczej i teraz do tego przejdziemy - probing nazywa się `readinessProbe` I tam to będziemy definiować.  natomiast pytanie czy nasz prosty endpoint `/health_check` jest w zupełności wystarczające? Odpowiadam: tak. Ale wyjaśni się to dokładnie jak zdefiniujemy endpoint dla `readinessProbe`. 

  

Okej Przejdźmy sobie w takim razie teraz do drugiego próbiku,  czyli do `readinessProbe`, Który was z goła  odmienny cel niż `livenessProbe`  i kubernetes też inaczej zarządza w tej sytuacji Podami. Jak sobie spojrzymy na definicję  w dokumentacji No to on tutaj mówi nam że jest to sprawdzenie czy Nasz serwis jest gotowy.  A jeśli prop sfailuje to będzie on usunięty z serwis endpoints. No właśnie. Co to oznacza?

  

No właśnie Słuchajcie?  Spójrzmy jeszcze raz jak nasze API działa.  ono korzysta z modelu okej,  ale również korzysta z baz danych: z Redisa i z Postgresa. Generalnie rzecz biorąc jeżeli bazy danych nie działają,  to pytanie czy nasze API powinno przyjmować requesty?   oczywiście odpowiedź to brzmi to zależy,  bo jeżeli nie będzie redisa to wtedy nasze API będzie  oczywiście zwracało odpowiedzi tylko że będzie robiło wolniej bo nie będzie korzystało z cachea,  A jeżeli nie będzie Postgresa To oczywiście nasza API również zwróci odpowiedzi ale nie zapiszemy ich bazach danych  czyli utracimy dane do przyszłego monitoringu.  więc załóżmy jednak że Redis i Postgres to są kluczowe elementy naszego API  i jednak chcielibyśmy żeby te dwie bazy działały  i uzależniamy funkcjonowanie naszego API od ich stanu -  nasz API będzie działać tylko wtedy kiedy zarówno Redis I Postgres działają.

  

I do tego żeby sprawdzić czy ten Postgres i Redis działa w naszym API  możemy wykorzystać właśnie probing. Jak możemy sprawdzić czy nasz postgres I redis działają?  sprawa jest bardzo prosta bo w naszych klasach `RedisConnector` oraz `PostgresConnector`  Mamy zdefiniowane metody `is_alive()`  które sprawdzają czy po prostu  bazy danych odpowiadają.

  

Przepraszam was zapomniałem zdefiniować metodę w Postgresie  żeby sprawdzić czy połączenie jest gotowe.  ale wiecie co pomińmy to bo,  bo to jest tylko wywołanie jednej metody więc Załóżmy że  interesuje nas tylko i wyłącznie na ten moment połączenie z jedną bazą - Redisem.

  

Takie sprawdzenie  może wyglądać w następny sposób:

  

```python

@app.get("/health")

def health_check(request: Request) -> PlainTextResponse:

    request.app.state.redis_connector.is_alive()

    return PlainTextResponse("Healthy")

```

  

Wystarczy wywołanie metody `is_alive()`  jeżeli Redis nie będzie dostępny to implementacji jest raise’owany błąd `RedisConnectionNotAliveError`. A nasze API ma zaimplementowany exception handler `api_error_exception_handler` na górze API, Który wyłapuje takie błędy i po prostu zwraca 500. Więc w takiej sytuacji po prostu  endpoint `/health`  zwróciłby odpowiedź ze statusem code 500. 

Natomiast  umieszczanie tego w endpoincie `/health`, który używany jest w `livenessProbe`, Ma ten minus  że w takiej sytuacji  Pod z naszym API zostanie zrestartowany. Co jest bez sensu,  bo problem nie leży w naszym API,  tylko problem leży w bazie danych  po prostu nie jest ona dostępna.  i problem należy zinwestować w tej bazie danych a nie w naszym API.  gdybyśmy zostawili te sprawdzenie tutaj  w endpoincie `/health`  to w takiej sytuacji mielibyście to samo co wcześniej mówiłem czyli wasz Pod wszedły  w błąd CrashLoopBackOff  i generalnie to by wskazywało na to że problem jest w waszym,  w środku waszego kodu,  A tak w rzeczywistości nie jest.

  

Tak najbardziej zasadne jest to żeby sprawdzić czy inne serwisy działają, natomiast  w tym celu właśnie jest stworzony Pro `readinessProbe`,  który ustawmy sobie.  Może on być zdefiniowany tak samo jak `livenessProbe`  w zakresie jego parametrów do tego skopiujemy po prostu, ale zmieńmy path na endpoint `/readiness`:

  

```yaml

          livenessProbe:

            httpGet:

              port: 8080

              path: /health

            periodSeconds: 10

            timeoutSeconds: 5

            failureThreshold: 3

            successThreshold: 1

          readinessProbe:

            httpGet:

              port: 8080

              path: /readiness

            periodSeconds: 10

            timeoutSeconds: 5

            failureThreshold: 3

            successThreshold: 1

```

  

I teraz wróćmy do naszego kodu i zdefiniujmy endpoint `/readiness`, a `/health` przywróćmy do poprzedniej sytuacji. 

  

```python

@app.get("/readiness")

def ready_check(request: Request) -> PlainTextResponse:

    request.app.state.redis_connector.is_alive()

    return PlainTextResponse("Ready")

  

@app.get("/health")

def health_check() -> PlainTextResponse:

    return PlainTextResponse("Healthy")

```

  

 My w tej chwili w `readinessProbe`  umieściliśmy sprawdzenie czy nasze bazy danych działają.   ale w waszych API może być sytuacja  korzystacie z np. jakichś wewnętrznych serwisów w waszej pracy, które stworzyły inne zespoły, Albo z innych serwisów waszych.  tamte serwisy też powinny mieć zdefiniowane endpointy związane z `/health` i `/readiness`. W takiej sytuacji po prostu wasz endpoint `/readiness`  też powinien sprawdzić te serwisy czy one działają.

  

Okej to teraz jak kubernetes traktuje readinessProbe. tak jak jest to napisane w dokumentacji: Container will be removed from service endpoints if the probe fails. Oznacza to  że w takiej sytuacji  ten Pod  dla którego ten Readines failuje, zgodnie z naszymi ustawieniami w manifeście, Zostanie odłączony od serwisu. A jeżeli zostanie on odłączony od serwisu to będzie miał status na żółto UnReady  i w takiej sytuacji Pod nie jest restartowany,  tylko nie jest on w liście ipików dostępnych w danym serwisie.  czyli Innymi słowy serwis nie będzie przekazywał requestów do Poda, dla którego ten  readinessProbe  failuje. Dopóki nie będzie sukcesu na tym Podzie,  to znaczy Kubernetes nie dostanie status code 200 z endpointa `/readiness`,  dopóty żaden request nie zostanie wysłany do Poda. W takiej sytuacji również można ustawić monitoring i alerty  na logi które pojawiają się w API No i jeżeli te logi już błędami z endpointa `/readiness` to wtedy mamy informację, że Problem jest nie bo na stronie API a po stronie serwisów z których nasze API korzysta. 

  

`livenessProbe` i `readinessProbe` Wzajemnie się uzupełniają w tej sytuacji:

  

1. jeżeli `livenessProbe` jest OK i `readinessProbe` też jest OK - działa zarówno nasze API jak i serwisy z których korzysta 
    
2. jeżeli `livenessProbe` jest OK, a `readinessProbe` failuje, a - oznacza to problem z serwisami z których nasze API korzysta.
    
3. jeżeli `livenessProbe` failuje, a `readinessProbe` jest OK, a - oznacza to problem z naszym API, ale serwisy z których korzystamy są OK
    
4. jeżeli `livenessProbe` failuje i `readinessProbe` też failuje - to wiadomo wszystko nie działa. To z własnego doświadczenia rekomenduje wam sprawdzenie najpierw tego co jest  nie tak z waszym API,  bo często błąd w implementacji API, który powoduje failowanie `livenessProbe` też ma bardzo często wpływ na `readinessProbe` i propaguje się dalej i w takiej sytuacji polecam najpierw sprawdzenie najpierw API. A jeżeli naprawa bugów w API nie naprawiła `readiness` to w kolejnym kroku sprawdzamy serwisy, z których nasze API korzysta.
    

  

Bo teraz jeszcze jedno słowo komentarza  odnośnie definicji endpointa `/health`, Bo jak widzicie on jest taki bardzo mały,  w porównaniu  do `/readiness`. Przeważnie to antpoint `readiness` będzie bardziej rozbudowany -  z im więcej serwisów korzystacie tym ten `/readiness`  będzie bardziej rozwinięty. Natomiast generalnie ten `/health` pozostaje  Przeważnie tak jak widzicie Czyli po prostu  od razu zwracamy odpowiedź.  i to jest w zupełności wystarczające.  można się zastanowić nad tym czy tego endpointu `/health` nie powinniśmy  bardziej rozbudować.  bo zobaczcie.   my w `/readiness`  sprawdzamy  czy nasza baza danych po prostu odpowiada,  czy żyje. Natomiast nasz obiekt `redis_connector`  przechowuje połączenie z naszą bazą danych  i może problem będzie u nas  związany z tym że z jakiegoś powodu te połączenie utracimy. Generalnie baza danych działa,  ale te połączenie które my tutaj zainicjowaliśmy przestało działać. I na przykład takie sprawdzenie moglibyśmy zdefiniować  w endpoincie `/health`. Ale powiem wam że to nie jest potrzebne dlatego że w takiej sytuacji  przy pierwszym napotkanym riqueście który przyjdzie do API po prostu dostaniecie błąd w momencie kiedy Spróbujecie odczytać z  redisa  wartości -  tutaj na samym początku naszego endpointa `/decisions` widać to. W efekcie czego dostaniecie błąd.  python w takiej sytuacji zwróci exit Code różne od zera.  Kubernetes  to zauważy, w skutek czego po prostu zrestartuje nam naszego poda. I w takiej sytuacji restart spowoduje że API się zainicjuje ponownie,  stworzone  zostanie nowe połączenie i wszystko będzie działało poprawnie.  Czyli generalnie uzyskamy ten sam wynik jaki byśmy uzyskali w sytuacji gdybyśmy dodali jakieś sprawdzenie jeszcze na poziomie endpointa `/health`. Powiem szczerze że te API nasze jest w miarę proste,  Ale Wasze API może być jeszcze bardziej rozbudowane i takie sprawdzenie  zawartość obiektów może być trudne  i generalnie gra nie będzie warta świeczki. Jeżeli coś z waszymi obiektami będzie nie tak to po prostu  odpowiedzialnym za  rozwiązanie predykcji  dostaniecie błąd,  który spowoduje że Wasz Pod po prostu się zrestartuje. Nie ma potrzeby dodawania czegoś ekstra do `health_check`,  przez co taka banalna postać `health_checka` jest w zupełności wystarczająca. 

  

Jeszcze ostatnie zdanie w kwestii readinessa. Tak jak widzieliście on jest też używany  w sytuacji kiedy powstają nowe Pody w wyniku updateowania Deploymentu. Verdipromencie w parametrach `strategy`  ustawiliśmy sobie RollingUpdate  z parametra  parametrami `maxSurge` równym 2 oraz `maxUnavailable` równym 0. Czyli kubernetes najpierw dostawi dwa pod nowej wersji,  i wtedy kiedy one będą gotowe do przyjmowania requestów  dopiero wtedy w sumie dwa Pody ze starej wersji.  i właśnie słowo gotowe  jest istotne,  ponieważ w takiej sytuacji właśnie `readinessProbe`  jest wykorzystywane do tego żeby sprawdzić czy nasze API jest gotowe do przyjmowania requestów. Więc  generalnie wdrożenie Deploymentu z `readinessProbe`  dodatkowo zabezpiecza nas podczas update'owania naszego deploymentu z nowymi zmianami w naszym API.

  

Czy macie jakieś pytania odnośnie `livenessProbe` albo `readinessProbe`?

  

Okej to teraz nie przechodzimy do ostatniego rubinku, czyli do `startupProbe`,  który jest istotnie ważny w API z modelami MLowymi,  z racji tego że każde wasze API będzie miało krok związany z jego inizjalizacją.  teraz do momentu inicjalizacji i to czasu jaki potrzebuje API żeby właśnie się zinicjalizować można podejść na dwa sposoby:

  

1.  pierwszy sposób Polega na tym aby jednak w `livenessProbe` ustawić parametr  zwany `initialDelaySeconds`, Który oznacza to że te próby Sprawdzenia czy nasz kontener żyje będzie opóźniony o te Sekundy które tutaj ustawimy  na tym parametrze.  ten czas można wykorzystać właśnie do tego żeby te API się inicjalizowało.  ten parametr domyślny jest ustawiony na zero,  Czyli jeżeli nasz Pod się pojawi to od razu  Wykonywane są sprawdzenia `livenessProbe`.  i w sytuacji kiedy wasze API będzie się długo inicjalizować,   to w takiej sytuacji po prostu ten liveness nie będzie dostawał status_code = 200,  no bo  API jeszcze się nawet nie zinicjalizowało,  w efekcie czego po prostu będą rzucane timeouty błędy 503 albo 504  No i w ten sposób  wasze API Będzie w kółko restartowanym bo kubernetes będzie myślał że jest jej problem,  a tak na prawdę  to nie jest problem ponieważ po prostu wasze API potrzebuje więcej czasu żeby się zinicjować.  dlatego te sprawdzanie `livenessProbe`  można opóźnić Korzystając z tego parametru. Czyli na przykład lokalnie możemy zobaczyć o jakim czasie nasz kontener z naszym API będzie w tej kwestii i w ten sposób określić jaką wartość tutaj wstawić. Natomiast ja generalnie rekomenduje inne podejście czyli po prostu niekorzystnie z tego parametru. Parametrów jest taki że trzeba po prostu na sztywno tą wartość ustalić  i za każdym razem kiedy deployujecie nową wersję API,  No to trzeba też  sprawdzić czy  nie Wymagane są zmiany w tym parametrze.
    
2.  podejście jest troszkę bardziej dynamiczne i bardziej elastyczne  i skorzystanie w tym przypadku z dedykowanego probingu do sprawdzenia inicjalizacji naszego API, czyli skorzystanie z `startupProbe`.
    

Jak życie sobie na dokumentację to zobaczycie, że jest to type Probe,  więc skopiujmy sobie zawartość z `livenessProbe` i pozmieniajmy kilka wartości:

  

```yaml

          startupProbe:

            httpGet:

              port: 8080

              path: /health

            periodSeconds: 1

            timeoutSeconds: 1

            failureThreshold: 60

            successThreshold: 1

```

  

Teraz wartości i ustawiłem w `periodSeconds` na 1, `timeoutSeconds` na 1 generalnie oznaczają to że Kubernetes będzie co sekundę wysyłał requesta żeby zobaczyć czy nasze API zostało zainicjowane. `failureThreshold` na 60 Oznacza z kolei że  jeżeli jest 60 takich requestów  nie dostanie  odpowiedzi ze statusowem code 200 to po prostu  zrestartuje Poda.  czyli Innymi słowy `failureThreshold` na 60  oznacza że dajemy fotowi maksymalnie 60 sekund na inicjalizację. 

  

Dlaczego takie wartości zaproponowałem? Chcę po prostu jak najszybciej dowiedzieć się,  kiedy nasze API jest już zainicjowane i gotowe do przyjmowania requestów. 

  

Teraz druga sprawa jest taka że parametr `path` jest określony na `/health`  i powiem od razu że niepotrzebny jest w przypadku API budowany w FASTAPI Tworzenie dodatkowego etpointa dla `startupProbe` -  w zupełności wystarczy wam w tym celu endpoint stworzony do `livenessProbe`.  dlaczego? Dlatego że fast API zacznie obsługiwać requesty dopiero wtedy kiedy się zainicjuje,  czyli w naszym przypadku endpoint `/health`  zacznie zwracać odpowiedzi dopiero wtedy kiedy funkcja `startup`  która definiuje naszą inicjalizację  zakończy się pomyślnie. Dlatego niepotrzebny jest dedykowany  endpoint pod `startupProbe` bo nie ma możliwości żeby on działał w trakcie  Kiedy funkcja `startup`  jest wykonywana. Natomiast takie zachowanie FastAPI.  Jeżeli ktoś z was będzie tworzył w innym frameworku API,  to proszę na to zwrócić uwagę czy też tak to działa. Sytuacje gdybyście mieli framework który tak nie działa,  to rozwiązanie  jest proste po prostu trzeba stworzyć pewien parametr,  który na przykład na samym końcu działania waszej funkcji inicjalizującej API  zmieni np. wartość na True,  a wasz endpoint związany z `startupProbe`  będzie po prostu sprawca wartość tej zmiennej jeżeli ona jest True to wtedy zwrócić status code 200.  Natomiast w przypadku FastAPI wystarczy oprzeć się o Ed Point który jest  stworzony pod `livenessProbe`.

  

Bardzo ważne: Sytuacje kiedy macie zdefiniowany `startupProbe`  to najpierw wykonywany jest ten probing,  i dopiero wtedy kiedy kubernetes widzi że  API jest zainicjowane,  zacznie wysyłać prowingi `liveness` oraz `readiness`. 

  

I w przypadku `startupProbe`,  jeżeli inicjalizacja nie zakończy się zamierzonym czasie to Kubernetes restartuje poda,  czyli działanie jest takie same jak  w przypadku `livenessProbe`.

Okej to było tyle jeśli chodzi o ten probing.  natomiast  jeszcze przy okazji żeby powiedzieć o tym jak ten Pod jest restartowany.  Nie wiem czy pamiętacie ale na zajęciach z dockera mieliśmy takie ćwiczenia związane z tym żeby go zatrzymać i albo go zabić. I w przypadku zatrzymania kontenera  widzieliśmy że ta operacja wywoływała naszą funkcję związaną z `shutdown`,  w której to zdefiniowaliśmy żeby nasze przejazd bazami danych po prostu się zakończyły.  Natomiast w przypadku kiedy chcieliśmy zabić kontener to nie widzieliśmy tej operacji `shutdown`, żeby się uruchomiła. 

  

Podobne operacje wykonuje Kubernetes. Pamiętajcie o tym że w sytuacji kiedy z `livenessProbe` albo `startupProbe`  wyniknie że wasz Pod musi być zrestartowany  to  następuje terminacja Podów, czyli zakończenie ich działania, aby potem postawić nowego. W takiej sytuacji Kubernetes wysyła sygnał SIGTERM, Który wysyłaliśmy komendą `docker stop`,  albo komendą `kill -s SIGTERM PID_ID` I w takiej sytuacji uruchomi się wasza funkcja `shutdown`, Czyli wszystko co zdefiniujecie w  tym momencie zostanie uruchomione.  natomiast pamiętajcie o tym że  domyślnie  Kubernetes  będzie czekał 30 sekund na to aż te wszystkie operacje czyszczące zostaną zakończone przez wasze PODy.  jeżeli zdarzy się tak że jednak wasz shutdown trwa dłużej,  to Po 30 sekundach Kubernetes wysyła sygnał SIGKILL,  czyli  to samo co uzyskali byśmy komendą `docker kill`,  a w takiej sytuacji żadna te operacje już nie będą wykonywane,  będą wręcz przerwane.  więc pamiętajcie o tym że jeżeli będziecie mieli długie operacje związane właśnie z zakończeniem pracy waszego API,  i przekraczają one 30 sekund  to na szczęście możemy  ten czas zmienić,  Korzystając z parametru `terminationGracePeriodSeconds`

  

```yaml

    spec:

      terminationGracePeriodSeconds: 60

      containers:

```

  

Ustawimy sobie na 60 to po prostu Kubernetes będzie czekał 60 sekund na to  aż Pod się zakończy swoją pracę,  a jeżeli wciąż będzie pracował to po prostu go zabije.  Natomiast jeżeli wasz pod zakończy się szybciej niż 60 sekund,  No to się znaczy, że praca się zakończyła i Kubernetes może spokojnie usunąć Poda - On nie będzie stał i nic nie robił przez te pozostały czas aż dojdzie do 60 sekund.  Jeżeli masz pod szybciej zakończy swoją pracę,  to od razu po zakończeniu zostanie usunięty.

  

Okej to teraz  Chciałbym krótko podsumować to wszystko co chciałbym przekazać:

  

1.  wyróżniamy trzy probingi: `startupProbe`, `livenessProbe` oraz `readinessProbe` I rekomendowana jest to żeby ustawić je wszystkie trzy.  najpierw uruchomi się `startupProbe`  i jeżeli  Nasz serwis z sukcesem się zainicjował  to w dalszej kolejności uruchamiane są `livenessProbe` i `readinessProbe` Które wysyłane przez przez cały czas życia  naszego poda  Zgodnie z tym co ustaliliśmy parametrach.
    
2. `startupProbe` odpowiada  za sprawdzanie tego czy nasz  Pod jest zainicjowany -  W przypadku porażki Pod jest restartowany
    
3. `livenessProbe` odpowiada za sprawdzenie tego czy nasz Pod żyje -  w przypadku porażki pod jest restartowany
    
4. `readinessProbe` odpowiada za sprawdzenie tego czy nasz Serwis jest gotowy do przyjmowania requestów -  w przypadku porażki Pod nie jest restartowany, tylko wykluczany jest z listy Podów dostępnych w obiekcie Service,  przez co nie są kierowane do niego żadne requesty 
    
5. `livenessProbe` z `readinessProbe` uzupełniają się i Mając zdefiniowane dwa te parametry  to możemy uzyskać informacje czy on jest naszym API czy problem jest z innymi serwisami z których  nasze API korzysta. 
    
6. W sytuacji restartu poda,  która może nastąpić w wyniku porażki na `livenessProbe` lub `startupProbe`, Kubernetes najpierw wysyła SIGTERMa  co może  procesy  kończące pracę API,  jeżeli takie są oczywiście zdefirowane,  a jeżeli trwa to zbyt długo to Kubernetes  wysyła potem SIGKILL  aby  przerwać działanie naszego API natychmiast.  jeżeli Potrzebujemy więcej czasu na  nasze procesy kończące pracę API,  to możemy  ten czas zwiększyć poprzez parametr `terminationGracePeriodSeconds`.
    

  

Czy macie jakieś pytania odnośnie probingu?

  

Okej to na koniec teraz Musimy zbudować na obraz naszego  API z tymi nowymi endpointami:

  

```bash

docker build -t europe-central2-docker.pkg.dev/GCLOUD_PROJECT/mrybinski-live-coding-api/api:with-services-env-probing -f deploy/docker/api/Dockerfile .

```

  

I go zpushujmy:

  

```bash

docker push europe-central2-docker.pkg.dev/sotrender-rd/mrybinski-live-coding-api/api:with-services-env-probing

```

  

I wskażmy go w naszym manifescie:

  
  
  
  
  
  
  

```yaml

      containers:

        - name: api

          image: europe-central2-docker.pkg.dev/sotrender-rd/mrybinski-live-coding-api/api:with-services-env-probing

```

  

I wdróżmy nową wersję:

  

```bash

kubectl apply -f deploy/k8s/deployment.yaml

```

  

**