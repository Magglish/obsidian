# Service

**Przed przedyskutowaniem Serviceów, pozbądź się wszystkich external IPs utworzonych przez Terraform oraz zarejestrowane rekordy DNS typu A, bo może trafić Ci się quota limit. A one sa potrzebne, żeby utworzyć load balancery.**


## TUTAJ PRZY SERWISACH TRZEBA BEDZIE PROOBIC SLAJDY Z GRAFAMI JAK PRZEBIEGA WYSYLKA REQUESTÓW DO SERWISÓW ROZNEGO TYPU GDY WYSYLAMY REQUESTA.

  

Okej Przechodzimy sobie teraz dane w sumie Moim zdaniem najtrudniejszego tematu w kontekście kubernetesa to znaczy poznamy sposoby na to jak możemy udostępnić API na zewnątrz to znaczy jak możemy  wysłać request z naszą komputera do API działającego na klastrze Kubernetesowym.

  

 na początek wyświetlmy sobie jakie mam Pody:

  

```bash

kubectl get pods --namespace=mrybinski

```

  

I następnie podejrzyjmy szczegóły jednego z nich:

  

```bash

kubectl describe pod credit-scoring-api-6fd55f4bd4-pxnv8 --namespace=mrybinski

```

  

Jak widzimy ten pod ma IP,  czyli jest w jakiś sposób identyfikowalny w sieci.  na jednym z żadnych ćwiczeń robiliście to że odpytywaliście takiego poda Korzystając z tego IP za pomocą `curl`.  czyli jest jakiś sposób na to żeby wysłać requesa do naszego poda w którym jest nasz kontener z naszym API.  Jednakże  te pod osiągalne za pomocą tych ipków które to widzicie  są widoczne tylko i wyłącznie z poziomu klastra.  czyli Innymi słowy tylko zasoby znajdujące się na klastrze waszym są w stanie skorzystać z API która działają na tych podach. W takim razie może powiedzieć okej Ale jeżeli nasze inne usługi które korzystają z Z naszego API są zdeployowane na naszym klastrze to generalnie mógłby z tego API z naszego skorzystać.  to prawda,  ale generalnie w rzeczywistości nie będzie tak że będzie istniał tylko i wyłącznie jeden klaster na którym będą działać wszystkie możliwe usługi w waszej firmie dzięki temu mogłyby się komunikować po tych ipkach,  tylko spotkacie Się z sytuacją  w której będzie wiele klastrów,  każdy klaster ma swoją własną sieć więc pod z jednego klastra mogą nie widzieć podów ineu klastra,  oczywiście można skonfigurować tak sieć żeby wszystkie klastry miały wspólną sieć I wtedy wszystkie Pody będą się widzieć nawzajem,  więc można to jakoś rozwiązać  i ewentualnie w tym kontekście zostać tylko i wyłącznie przy tych ipkach wewnętrznych.   Natomiast są inne problemy  związane z takim bezpośrednim odpytywaniem Podów poprzez ich IPki.  No bo zobaczycie że mamy W tej chwili 10 Podów więc mamy 10 różnych IPków.  A my w naszym kodzie przykładowym w którym wysyłamy requesta No wskazany jednego IPka,  więc generalnie Gdybyśmy chcieli skorzystać z innych Podów musielibyś wprowadzać zmiany w kodzie. Ale oprócz tego musielibyście mieć  jakąś logikę po prostu sprawdzania IP Podów które są teraz dostępne  w dodatku też pamiętajcie o tym że wasze body mogą się skalować w górę być ich więcej,  albo skalować w dół i pod którego skorzystaliście i jego IP macie wskazane w kodzie generalnie  znika  i wasze requesty do niego już nie dochodzą bo po prostu nie istnieje.  może być też tak że pod który działał i ma się dobrze Po prostu się zrestartował i w wyniku czego jego IP też się mógł zmienić.  więc generalnie takie odpytywanie naszych deeplementów po ipkach Podów  jest bardzo niewygodne  i w praktyce nie spotykane.

  

Żeby móc skorzystać z naszych podów i nie mieć problemu z tym że te ipki się zmieniają  właśnie ze względu na to że nowe Pody są dostawiane,  albo Pody są ubijane  Kto może być związek właśnie zeskalowaniem jej liczby albo po prostu samą aktualizacją. Dlatego istnieje  dedykowany  obiekt w Kubernetes o nazwie Service  który ma w sobie zaimplementowaną logikę Grupowania Podów ale pod względem  sieciowym,  to znaczy on sobie będzie miał z całym logikę związaną właśnie z sprawdzaniem tego jakie są Pody dostępne,  pod jakimi ipkami,  czy Pod jest gotowy do tego żeby wziąć requesta czy nie,  będzie automatycznie aktualizował IPki W zależności od tego czy te pody będą się skierować w górę czy właśnie w dół - On całą tą logikę będzie miał zaimpletowaną w sobie.  w dodatku serwis będzie dostępny dla nas pod jednym konkretnym IP. Czyli innymi słowem my będziemy wysyłać requesta do serwisu Pod jednym konkretnym IP,  A z kolei on będzie miał zaimplementowaną logikę  przekazania tego requesta do jednego z naszych Podów.  Czyli jak widzicie  serwis dostarcza też pewnej podstawowej funkcjonalności tak zwanych Load Balancerów,  czyli obiektów które w pewien sposób rozdysponowują o ruch sieciowy do naszych serwisów które ten ruch sieciowy będą obsługiwać,  czyli w tym przypadku  serwis  po otrzymaniu requesta,   przekażę go dalej do losowego poda  który ten request przyjmie przetworzy I zwróci odpowiedź. O Load Balancingu  powiemy sobie troszkę więcej  później.

  

Czyli podsumujmy to sobie to zaraz to powiedziałem porównajmy go z naszym Deploymentem. Deployment  grupuje nasze Body i dba o to aby  była ich odpowiednia liczba taką jaką chcemy,  w dodatku też  ma zaimplementowaną logikę  aktualizacji  naszych Podów kiedy wprowadzamy zmianę.  natomiast serwis też grupuje pod ale jego działanie skupia się tylko i wyłącznie na kwestiach sieciowych,  czyli grupuje je w taki sposób żeby ułatwić nam do nich dostęp.  w dodatku też ma zaimplementowaną logikę zarządzania listą Podów i ich IPków W zależności od tego czy Pojawiają się nowe poty czy istniejące już pod umierają o tą listę cały czas aktualizuje  dla nas.  w dodatku sam z siebie udostępnia konkretne IP,  i my tak naprawdę Korzystamy z IP Service’u,  aby wysłać request do naszego serwisu a on odpowiednio  dalej to wysyła do podów które przetwarzają nasze zapytanie.  

  

teraz pytanie jakie może powstać w waszej głowie to to czy IP serwisu też się może zmienić.  tak może się zmienić, W szczególności jeżeli usuniecie serwis i go zdeployujecie na nowo,  wtedy Istnieje ryzyko że faktycznie jego IP się zmieni. Nnatomiast Kubernetes, A dokładnie ten obiekt który kiedyś wspominałem który znajduje się na Nodzie czyli `kube-dns`   zarządza całą siecią i  z kolei on dostarcza nam możliwość  skorzystania z serwisu zarówno po jego IPkow ale również tworzy dla niego hosta o nazwie `SERVICE_NAME.NAMESPACE.svc.cluster.local`, Co zaraz sobie zobaczymy.

  

W takim razie Przejdźmy sobie do naszego Manifestu i zdejmujemy nasz pierwszy serwis I zobaczmy jak to działa.

  

Stwórzmy sobie w `deploy/k8s` plik o nazwie `service.yaml` i również otwórzmy dokumentację na stronie z Servicem.

Zobaczcie że znowu z serwisem jest podobnie jak w poprzednim obiektami mamy cztery klucze do zdefiniowania:

  

```yaml

apiVersion: 

kind:

metadata:

spec:

```

  

Czyli `apiVersion` to będzie `v1` tak jak w dokumentacji, `kind` to po prostu `Service`, metadata to jest ten sam obiekt, który przerabialiśmy i generalnie możemy sobie skopiować znowu te same wartości.

  

Mamy zatem:

  

```yaml

apiVersion: v1

kind: Service

metadata:

  name: credit-scoring-api

  namespace: mrybinski

  labels:

    phase: live-coding

    app: rest-api

```

  

Spójrzmy sobie teraz na speca.  widzimy że pierwszy parametrem jest `selector`  jednakże On nie ma  rozróżnienia tak jak to było wcześniej na regex i na labelki.  tutaj domyślnie jest używany selektor na bazie labelków,  na tym przypadku selektora po prostu wskażemy labelki które nadaliśmy na Deploymencie:

  

```yaml

spec:

  selector:

    phase: live-coding

    app: rest-api

```

  

Następnie mamy parametr `ports`  który jak widzicie jest listą ServicePort.  i to co mi w tym parametrze musimy wskazać to właśnie porty które są otwarte na naszych modach,  ale również port który my otwieramy na servisie, Czyli w tym przypadku jest to `ports.port` oraz `ports.targetPort` W sumie generalnie dwa najważniejsze parametry do dwóch musisz ustawić dalsze rzeczy są przez używane  i mniej istotne w tej chwili. Więc wróćmy sobie do naszego manifestu i ustawmy ten parametr:

  

```yaml

  ports:

    - port: 80

      targetPort: predictions

```

  

Teraz ja ustawiłem sobie że port który będzie otwarty na serwisie to będzie 80, natomiast w targetPort ustawiłem nazwę `predictions`. Teraz Czym jest te predictions,  generalnie można tutaj wstawić wartość i moglibyśmy tutaj wstawić wartość 8080  bo taki port jest otwierany u nas na kontenerze,  natomiast wstawiłem nazwę  tego portu  po to żeby odwołać się do jego nazwy i jeżeli on się zmieni to wtedy będę musiał go zmienić tylko w jednym miejscu.  Wróćmy na chwilę do naszego deploymentu i w portach wprowadźmy tą zmianę

  

```yaml

          ports:

            - containerPort: 8080

              name: predictions

```

  

Czyli ja po prostu Nadałem nazwę mojego portowi jako `predictions`  dla portu 8080.  i wskazując nazwę portu  w Service  po prostu odwołujemy się do 8080.  ten zabieg pozwala wam na to że jeżeli z jakiejś przyczyn zmienicie numer portu,  to wystarczy go zmienić tylko i wyłącznie `Deployment`  i nie musicie wykonywać dalszych zmian w `Service`. 

  

I na końcu jeszcze jeden ważny parametr w przypadku `Service` czyli parametr o nazwie `type` Który określa jakiego typu będzie to serwis.  i przy typach serwisu troszeczkę poświęcimy czasu bo jest to bardzo ważny temat.   i też od typu jakie ustawicie no zależą dalsze parametry jakie Możecie ustawić na serwisie.  Nazwijmy sobie do najprostszego typu serwisu o nazwie `ClusterIP`:

  

```yaml

spec:

  type: ClusterIP

```

  

Klaster IP to najprostszy tryb serwisu który mówi o tym że serwis który powstanie  tak naprawdę będzie tylko i  wyłącznie osiągalny przez inne serwisy znajdujące się na tym klastrze.  Krótko mówiąc te ustawienie Kubernetesowi mówi  jedną rzecz,  Przyporządkuj ipka temu serwisowi,  ten IP który on przyporządkuje będzie ipikiem wewnętrznym to znaczy będzie on dostępny tylko i wyłącznie dla innych serwisów które działają na tym klastrze.  Czyli jeszcze ten serwis nie będzie dostępny poza klasą - tym zajmiemy się później. Ten typ Service  powoduje że na razie dostępny jest ona wciąż tylko wewnątrz klastra,  ale ten serwis ma te wszystkie zalety i funkcjonalności o których wam wspominałem wcześniej.

  

Pełny yaml:

  

```yaml

apiVersion: v1

kind: Service

metadata:

  name: credit-scoring-api

  namespace: mrybinski

  labels:

    phase: live-coding

    app: rest-api

spec:

  type: ClusterIP

  selector:

    phase: live-coding

    app: rest-api

  ports:

    - port: 80

      targetPort: predictions

``` 

  

Okej mamy  określone nasz pierwszy serwis w takim razie wróćmy go I zobaczmy co uzyskujemy:

  

```bash

kubectl apply -f deploy/k8s/service.yaml

```

  

Teraz przejdźmy sobie do naszego konsoli w Google CLoud  i Nasz serwis został utworzony w innym miejscu w zakładce Networking pod sekcja `Gateways, Services & Ingress`. I w sekcji Services powinien być widoczny `credit-scoring-api`. To co tutaj powinien być widoczny To właśnie jego status,  jaki to jest typ  czyli nasz Cluster IP.  macie od razu zapisanego IP do niego  w kolumnie Endpoints.  Ile Podów  jest dostępnych pod tym serwisem,  Jaki jest namespace i jaki kluster.  Wejdźmy sobie do naszego serwisu.

  

I to Macie podobne rzeczy które widzieliście wcześniej czyli właśnie wykresy związane z CPu, Memory i Dyskiem. Macie niżej wskazany jego IP z którego zaraz skorzystamy.  następnie listę Deploymentów.  czyli  To oznacza że serwis może grupować w sobie wiele różnych Podów z różnych deploymentów - to wszystko zależy od tego  jak zdefiniujemy sobie te selektory które definiują identyfikację kodów. 

  

 na dole mam też listę Podów które  wchodzą właśnie w skład naszego serwisu.  i zwróćcie uwagę na to że teraz Widzicie endpointy  czyli IPki  wszystkich Podów które funkcjonują.

  

 na dole też macie informacje o tym które porty są otwarte w serwisie,  i które porty wskazujemy w kontenerze  na naszych Podach. 

  

Zobaczmy co nam `kubectl` zwróci na temat naszego service’u:

  

```bash

kubectl describe service credit-scoring-api --namespace=mrybinski

```

  

Czyli widzimy tutaj te podobne informacje które widzieliśmy w konsoli,  natomiast  to co ja wam mówiłem właśnie serwis grupuje te body i ich ipiki co widzicie w konsoli jak i też tutaj w outpucie z `kubectl` w kluczu `Endpoints`  i po prostu w zależności od tego ile będzie podłóg to te lista Ed pointów będzie się odpowiednio aktualizowała w czasie rzeczywistym,  więc generalnie w takiej sytuacji możemy skorzystać tylko i wyłącznie z naszego dedykowanego ipka przypisanego dla serwisu,  i zawsze nasz request zostanie wysłany do działających podów.  takim razie sprawdźmy czy tak faktycznie jest.  to co zrobimy to po prostu zditujemy sobie tymczasowego poda z `curl`-em  żeby móc to sprawdzić:

  

```bash

kubectl run curl --image=radial/busyboxplus:curl --namespace=mrybinski --rm -it --restart=Never

```

  

Okej jesteśmy w naszym Podzie więc wyślijmy sobie requesta typy GET do naszego service i zobaczymy co nam odpowie:

  

```

curl -X GET IP_SERVICE

```

  

Jak widzicie mamy odpowiedź z naszego  serwisu,  a dokładnie z jednego poda którego losowo serwis wysłał tego requesta żeby go przetworzył.  No i my dostajemy tę odpowiedź z naszego poda, z naszego kontenera z API,  a dokładniej właśnie dostaliśmy tą odpowiedź którą zdefiniowaliśmy sobie w kodzie w endpoincie `/`. 

  

Wyślijmy sobie też requestu naszego endpointa `decisions` i zobaczmy czy dostaniemy odpowiedź

  

```bash

curl SERVICE_IP:80/decisions -X POST -H "Content-Type: application/json" -d '{"installment_rate_in_percentage_of_disposable_income": 0.25, "age_in_years": 40, "foreign_worker": "yes", "present_employment_since": "unemployed", "personal_status_and_sex": "male: single"}'

```

  

Tak mu powiedziałem IP servisu może się zmienić w sytuacji kiedy byśmy go usunęli i Postawili na nowo dlatego też kubernetes dla waszych serwisów dostarcza hostów  dla serwisów.  możemy to sobie sprawdzić komendą:

  

```bash

nslookup SERVICE_IP

```

  

W efekcie czego  dostajemy między innymi  hosta naszego serwisu,  i w ten sam sposób możemy spróbować odpytać Nasz serwis właśnie po nazwie:

  

```bash

curl -X GET credit-scoring-api.mrybinski.svc.cluster.local

```

  

Więc jeżeli chcemy zabezpieczyć się przed potencjalną zmianą ipka w serwisie,  to po prostu odwołujemy się do niego poprzez nazwę.  i generalnie w pracy z kubernetesem w niektórych momentach definicji pewnych manifestów możecie spotkać się właśnie z odwołaniem do serwisu poprzez jego nazwę bo będzie to wymagane na przykład w jakimś parametrze.  Generalnie też możecie spotkać się z sytuacją w której jakiś Aplikacje które właśnie działają na tym samym klastrze będą korzystały z waszych serwisów właśnie poprzez hosty nadawane przez `kube-dns`, czyli tak jak tutaj widzicie poprzez wskazanie do `credit-scoring-api.mrybinski.svc.cluster.local`, Możecie się z tym spotkać kiedy  Wasz serwis jest dostępny zarówno z zewnątrz czyli spoza klastra jaki też wewnątrz,  i w jakiś sposób ruch z zewnątrz Może być odpowiednio filtrowany,  monitorowane i tak dalej i tak dalej  I żeby po prostu  serwisy które działa ten klastrze nie przychodziły przez filtry,  bo nie muszą bo jest to ruch z naszych wewnętrznych serwisów a nie z serwisów klientów zewnętrznych i nie potrzebują tej jakiejś filtracji czy dodatkowego specjalnego monitoringu to w takiej sytuacji po prostu możemy skorzystać  właśnie z tego hosta żeby odpytać serwis działający na klastrze ale po wewnętrznej sieci Kubernetesa.  

  

Ok wyjdźmy z naszego Poda z `curl`-em poprzez `exit`

  

Okej zatem omówiliśmy sposób na to Jak udostępnić nasze API dla aplikacji wewnątrz klastra.  teraz przejdziemy do pierwszego ze sposobów na udostępnienie API na zewnątrz czyli tak żebyśmy my mogli z naszych laptopów odpytać API. 

  

 na końcu zjazdu odnośnie kontenerów  mieliśmy takie ćwiczenie W ramach którego omawiałem pierwsze podstawowe  elementy związane z siecią,  w którym to musieliśmy sobie wejść na wirtualną maszynkę uruchomić ręcznie kontener  na konkretnym porcie i jeżeli ten port na maszynce wirtualnej był dostępny z zewnątrz to mogliśmy wysłać do niego odpowiedź.  i W kubernetesie się możemy zrobić to samo.  nie będziemy odpowiedzialni oczywiście za uruchamianie tego na ręcznie bo to robi Kubernetes,  Jednakże jest możliwość taka żeby wskazać serwisowi który teraz przed chwilą stworzyliśmy żeby  nasze API udostępnił na porcie maszynki wirtualnej,  czyli Innymi słowy każdy Note będzie miał port dla naszego serwisu Jeżeli do tego Porto wyślemy dane czyli nasze zapytanie to zostaje to przekierowane do naszego serwisu a potem serwis do jakiegoś poda i dostanie odpowiedź zwrotną z naszego API.  Czyli to co robisz Właśnie w ramach tego ćwiczenia na poprzednim zjeździe.  przy czym tutaj zaletą będzie to że jeżeli powstaje nam nowe maszynka,  czyli nowy Node,  który może na pojawić się w tej sytuacji kiedy zabraknie nam zasobów na Nodzie żeby postawić Pody i potrzebujemy więcej. 

  

Sprawa W tym przypadku jest prosta bo w naszym serwisie Wystarczy że typ zmienimy z `ClusterIP`  na `NodePort`:

  

```yaml

spec:

  type: NodePort

```

  

Możemy również w liście portów  wskazać który port na naszym Nodzie  ma być otwarty. Np.

  

```yaml

  ports:

    - port: 80

      targetPort: predictions

      nodePort: 30080

```

  

Czyli w parametrze nodePort możemy wskazać bezpośrednio który port na maszynce ma być otwarty. Ale nie chciałbym żeby się zrobili,  bo ten parametr jest opcjonalny No i że oni go nie ustawimy to Kubernetes sam znajdzie port pomiędzy wartościami 30000 - 32572,  w związku z tym że jest nas kilka osób No to nie ustawiajcie tego parametru.

  

I to jest z wolności wystarczające żeby  przypominam na każdy mną czy na którym będzie działał jakikolwiek Pod,  zostanie otwarty port  dla naszego serwisu. 

  

W takim razie wdróżmy nową wersję serwisu:

  

```bash

kubectl apply -f deploy/k8s/service.yaml

```

  

### JEŚLI COŚ JEST NIE TAK Z POŁĄCZENIEM, TO WEJDZ NA VMKE OD GKE, ODPAL: `sudo iptables -L` I ZOBACZ CZY NA SAMYM DOLE NIE MASZ CZEGOS TAKIEGO: `mrybinski/credit-scoring-api has no endpoints */ tcp dpt:http reject-with icmp-port-unreachable` JĘSLI TAK TO NAJLEPIEJ ZAKTUALIZUJ DEPLOYMENT, USUN SERVICE, I JESZCZE RAZ GO POSTAW I SPRAWDZ CZY NA VMCE POTEM TEN PROBLEM ZNIKNIE.

  

Jeżeli spojrzymy sobie teraz na naszą konsolę google-owską  to widzimy że serwis teraz jest typu Node Port,  ale ten endpoint który tutaj jest zaznaczony,  czyli nasze IP  wraz z portem  to nie jest ten IP  po której będziemy mogli odpytać nasze API.

  

Jeżeli wejdziemy sobie na nasz serwis to wciąż widzicie tutaj  Cluster IP  o wartości … . A na samym dole informacje o tym który port na Nodzie jest otwarty.   teraz słowo komentarza:  to że ustawicie NodePort na serwsie  to nie oznacza to że on straci IP  po którym można go zidentyfikować w klastrze.  serwis musi być jakoś identyfikowany wśród innych obiektów które istnieją na komputerze,  zatem ten ClusterIP zawsze będzie  przyporządkowane dla danego serwisu. 

  

To samo możemy sprawdzić korzystając z `kubectl`:

  

```bash

kubectl describe service credit-scoring-api --namespace=mrybinski

```

  

## DODAJ TUTAJ SLAJD Z PRZYKŁĄDOWYM OBRAZKIEM JAK IDZIE WYSYŁKA REQUESTA Z LAPTOPA DO SERWISU NODEPORT.

  

Ok mamy informacje o tym jaki port jest otwarty  na maszynce wirtualnej.  serwis typu NodePort  na każdym Nodzie  otworzy ten port.  Zatem musimy odnaleźć IP naszych Node’ów. 

  

Od razu wam powiem że znacznie łatwiej  znaleźć jest IP Node’a Korzystając z komendy `kubectl`   niz wyjklikując to tutaj w komendzie googlowskiej.  generalnie jak pozna się komendy  `kubectl` ale to lepiej jest używać ich po prostu niż klikać cały czas.

  

Zobaczmy jakie mamy node’y:

  

```bash

kubectl get nodes

```

  

Weźmy sobie jakiegoś Node’a  i jego nazwę i po prostu sprawdźmy jego szczegóły:

  

```bash

kubectl describe node gke-test-cluster-dev-e2-standard-2-no-bfac1842-h623

```

  

Informacje jest cała masa ale to co nas interesuje w tym stosie informacji to adresy  i dokładnie ExternalIP,  który właśnie oznacza IP po który możemy odpytać naszego Node z zewnątrz.

  

Zatem nasze IP Nodea to np. 34.116.150.57 a NodePort to np. 31076.

  

W takim razie jak już mamy te dwie podstawowe informacje to spróbujmy wysłać curl-em  requesta:

```bash

curl 34.116.150.57:31076

```

  

Okej widzę że mamy  wiadomość witającą nas

  

```bash

curl NODE_EXTERNAL_IP:NODE_PORT/decisions -X POST -H "Content-Type: application/json" -d '{"installment_rate_in_percentage_of_disposable_income": 0.25, "age_in_years": 40, "foreign_worker": "yes", "present_employment_since": "unemployed", "personal_status_and_sex": "male: single"}'

```

  

I udało się. Mamy odpowiedź. Ale niestety żeby to było osiągalne to nie wystarczy tylko i wyłącznie ustawienie serwisu typu NodePort.  jeżeli działamy na chmurze to w takiej sytuacji pamiętajcie o tym że ruch sieciowy jest zablokowany domyślnie do wszystkich portów.  to co ja jeszcze musiałem zrobić żeby to było możliwe żebyśmy mogli wysłać  requesta do naszego Node’a tutaj na klastrze  to  odblokować w Firewall googlowskim właśnie te porty. Więc jeżeli będziecie pracować na chmurze to musicie jeszcze wykonać ten jeden krok. Ja to zrobiłem już za nas żebyś mnie zaoszczędzili na tym czasu,  pokażę Wam gdzie to można na ustawić  ale  nie będziemy się na tym skupiać na naszym zjeździe,  w sensie na konfiguracji firewalla  bo generalnie jest to poza skąpem naszego zjazdu i w ogóle  takie kwestie sieciowe  są bardziej domeną  innych osób niż nas Machine Learning Engineerów,  Dlatego też w takich kwestiach będzie współpracować raczej z  innymi osobami z Waszej firmy, którzy są ekspertami w kwestiach sieciowych - to po pierwsze. Po drugie w zależności od tego w jakiej może pracujecie to może wyglądać zupełnie inaczej.  a jeżeli będzie w ogóle pracować na  w klastrach zdypiowanych na waszych serwerach wewnętrznych, firmowych  to na pewno nie będzie to tak łatwe do zrobienia i tylko sobie wyklikacie -  tym będą zarządzać dedykowane  zespoły  DevOpsów i System Administratorów. 

  

 w przypadku chmury Google’owiej Mamy tak dedykowaną zakładkę W tym celu “VPC Network”  w której jest pod zakładka “Firewall”. U góry jest opcja “Create Firewall Rule”. Na początku można przeczytać takie zdanie jak: “Firewall rules control incoming or outgoing traffic to an instance. By default, incoming traffic from outside your network is blocked. Learn more” I w tej zakładce Musimy ustawić kilka opcji żeby  ruch z zewnątrz przychodzi na naszych Node-ów. Natomiast tak mówiłem,  tak innych chmura będzie to pewnie do ustawienia zupełnie inaczej,  na klastrach  zdeployowanych na waszej infrastrukturze wewnętrz  tak tego nie będzie na pewno stawiać,  i najważniejsze rzecz generalnie,  że service typu NodePortnie nie jest stosowany Powszechnie stosowane jako sposób na udostępnienie swojej aplikacji działających na produkcji. NodePorta  Można wykorzystać w sytuacji wtedy kiedy chcemy coś przetestować i zobaczyć czy faktycznie to naszego serwisu przychodzi ruch z zewnątrz w trakcie developmentu,  ale przy produkcyjnym wykorzystaniu to nie jest stosowane głównie z dwóch powodów:

  

1.   po pierwsze,  pamiętajcie o tym że Noddy podobnie jak Pody mogą się zrestartować,  zeskalować w dół bądź w górę  i w takiej sytuacji  występuje ten sam problem z ip-kami Jaki był przy Podach  to znaczy one cały czas będą się zmieniać.  a Zobaczcie że tutaj musimy wskazać konkretne ipk naszej maszyny wirtualnej,  niestety nie mamy dostępu do takiego ładnego hostnejma tak jak to mieliśmy w przypadku naszego serwisu,  więc generalnie  korzystanie z  takiego serwisu działającego na NodePorcie jest niewygodne. 
    

Tak samo jest z portami,  kubernetes sam przyporządkowuje porty w przedziale 30000-32527. Możemy oczywiście Wskazać bezpośrednioportu jednak nie chcemy otworzyć tylko jest takie ryzyko że niestety ale jakaś inna aplikacja można na tym porcie działać  i przez co Nasz serwis  Nie wdroży się poprawnie  i trzeba potem aktualizować to w serwisie i następnie w aplikacjach które korzystają z tego serwisu aby wskazać Nowy Port który potencjalnie jest wolny.

2.  natomiast Drugą rzeczą  która jest istotna to są rzeczy związane z security i zabezpieczenie naszych  obiektów  działających na naszym klastrze. Krótko mówiąc,  noteboard oznacza to  że osoby korzystające z waszego API będą bezpośrednio uderzać requestami do waszych maszynek wirtualnych wchodzących w skład klastra. To może rodzi tutaj wiele różnych problemów związanych z zabezpieczeniem takiego ruchu sieciowego i w ogóle z ich monitoringiem  i możecie być podatni bardziej na ataki z zewnątrz.
    

  

Generalnie rzecz biorąc NodePort nie jest używany na systemach produkcyjnych,  spotkać się z nim możecie w przypadku po prostu testowania tego czy Wasz serwis będzie dostępny z zewnątrz.

  

natomiast  mówienie NodePortu jest istotne ponieważ stanowi on podstawę innego  typu serwisu który już może być wykorzystywany produkcji,  ale on nie jest jeszcze tym docelowym rozwiązaniem. 

  

Okej teraz pytanie jak możemy zrobić to lepiej.  kolejnym typem serwisu który mówimy jest typ o nazwie LoadBalancer,  Jednakże od razu powiem na wstępie że to działa tylko i wyłącznie na chmurze.  potem pod koniec  tematu LoadBalancera powiem jak może by to zrobić po prostu na klastrze kubernetowym zipperowany na jakimś waszym wewnętrznym serwerze.

  

 zacznijmy od tego żeby sobie powiedzieć Czym jest ten cały load balancing bo jest to bardzo istotne w szczególności w klasach bo jest on wykorzystywany  intensywnie. Load Balancing jak sama nazwa może wskazywać,  jest w technikum polegającą na tym żeby rozdysponować ruch sieciowy po naszych serwisach.  Rozdysponowanie tego ruchu sieciowego  i już  Widzicie na przykładzie naszego serwisu.  przy okazji omawiania serwisu typu ClusterIP  widzieliście że jest tam llista ipików naszych Podów.  Czyli jeżeli przychodzi request do naszego serwisu,  to serwis w tym przypadku losowo wysyła go do jakiegoś Poda,  który ten request  będzie przetwarzany i zostanie zwrócona odpowiedź. Teraz Jakie są zalety z takiego balancingu:

  

1. Skalowalność - W przypadku skalowalności,  load balancing bezpośrednio nam nie dostarcza skalowania tylko bardziej chodzi o to  że w momencie kiedy Pojawiają się nowe Pody,  to po prostu taki LoadBalancer  ma zaimportowaną u siebie logikę związaną z tym żeby te Pody wykrywać,  okresie z które są gotowe do tego żeby requesta,  albo te które nie są  więc generalnie zarządza on sieciowymi związanymi z naszymi Podami.  Natomiast w ramach LoadBalancera można zdefiniować  sposób w jaki te requesty będą rozdysponowane  po naszych podach.   domyślnym wariantem jest to żeby zrobić to w sposób równomierny czyli  prawdopodobieństwo  tego że dany pot otrzyma requesta jest taki sam Dla każdego poda  i równy jest 1/n gdzie n to liczba podów.  Można też robić bardziej wyspecyfikowane losowanie oparte o jakieś warzenie, albo nawet  bezpośrednio wskazać  że 30% ruchu idziesz do tego poda a 70% do pozostałych. 
    
2. Bezpieczeństwo i kontrola ruchu sieciowego -  Druga kwestia  związana jest z bezpieczeństwem.  ten LoadBalancer  to będzie dedykowana usługa  zdeployowana w chmurze  która ma właśnie za zadanie kontrole ruchu sieciowego i w ramach niej możemy zaimplementować różne reguły sieciowe  dotyczące naszej serwisów,  zablokować na przykład jakieś porty które nie pozwalam na to żeby były dostępne,  stworzyć Jakąś białą listę ipików  która określa  z których ipików  akceptujemy nasz ruch sieciowy, sTworzy tak zwany rate-limiting  czyli określać to na przykład ile  requestów może przyjść z danego źródła w ciągu minuty. LoadBalancer jest też automatycznie proxy  dla naszych serwisów,  czyli Innymi słowy jest dedykowana usługa która jest przed naszymi serwisami i przyjmuje cały ruch zatem będzie miała też jeden dedykowany IP do którego możemy wysłać requesty a on będzie miał całą logikę zaimplementowaną czyli pozbywamy się tego problemu  o którym mówiłem przy okazji na odportu że każda maszynka wirtualna ma inne IP i odnoszę się zmieniać z czasem. Tutaj z kolei będzie jedna usługa  która ma 1 IPków  i jak zobaczycie Możemy też mu wtedy przyporządkować jakąś konkretną nazwę hosta więc nie będziemy musieli odpytywać bezpośrednio po IP a po jakieś ładnej nazwie naszego service’u.
    

  

I jeszcze jedną rzecz podkreślam że ten LoadBalancer którego teraz sobie po prostu zbudujemy,  jest możliwy tylko i wyłącznie w chmurach.  o co chodzi?  zmiana znowu polega tylko i wyłącznie na  nazwie typu serwisu:

  

```yaml

spec:

  type: LoadBalancer

```

  

I wdróżmy to sobie:

  

```bash

kubectl apply -f deploy/k8s/service.yaml

```

  

W efekcie czego po prostu kubernetes nasz googlowski  zobaczy że  został stworzony na nim serwis typu `LoadBalancer`  I to automatycznie uruchomi wszelkie inne procesy na naszej chmurze żeby taki LoadBalancer powstał.  i tak samo zadzieje się w przypadku AWSa czy Azure. 

  

Teraz przejdźmy sobie do naszej konsoli Google i zobaczymy co dostaliśmy.  w zakładce z serwisami widzimy że teraz typ już jest `External load balancer`  oraz widzimy że jest jakiś przyporządkowany temu naszemu serwisowi.  Wejdź mi jeszcze na razie  do specyfikacji serwisu. Widzimy że mamy sekcje Load Balancer  i zobaczcie proszę że mamy: `ClusterIP`  przyporządkowane  do tego żeby identyfikować serwis wśród innych obiektów kuberetesie.  jest Też IP naszego Long balancera  i  to jest IP po którym możemy odpytać nasz LoadBalancer  żeby dalej przekazał requesta do naszego poda.  to zaraz to zrobimy,  jest coś do niego link Zaraz zobaczymy co to jest.  natomiast Zjedźcie na sam dół  i zobaczycie że mamy zakładkę `Ports`  i widzimy NodePorta.  LoadBalancer tak naprawdę  to dedykowana usługa której celem jest rozdysponowanie naszego ruchu sieciowego po klastrze a dokładniej po nocach na których znajdują się naszym body z naszym API,  i będąc precyzyjnym można powiedzieć, że LoadBalancer to dedykowana usługa zbudowana wokół  serwisu typu NodePort, Która rozwiązuje te wszelkie  problemy związane właśnie z NodePortem o których wcześniej wspomniałem,  i rozwiązanie to wszelkich problemów które wspominałem zostawiamy naszych chmurze na której to diplorujemy  i Ona ma w sobie tylko  usługę żeby takiego LoadBalancera.

  

Więc Wejdźmy sobie w link do niego w powyższej sekcji LoadBalancer. Teraz zwróćcie uwagę na to że Znajdujemy się teraz w usłudze Network Services,  czyli właśnie googlowskiej usłudze dedykowanej do tworzenia  rozwiązań sieciowych  i znajdujemy się w sekcji Load Balancing.  i tutaj mamy na przykład ustawienia naszego LoadBalancera.  informacje o tym  po jakim IP jest dostępny.  kwestia pakietu sobie zostawimy bo to są zaawansowane rzeczy.  natomiast na dole macie listę naszych nodeów,  do których ruch będzie przekazywany dalej jeżeli odpytamy naszego LoadBalancera.

  

 zatem Wróćmy do slajdu i zobaczmy jak to wygląda dokładnie

  

1.  wysyłam requesta z naszego komputera do LoadBalancera
    
2.  trafia on do usługi dedykowanej na chmurze  który nam dostarczył implementacji LoadBalancera
    
3.  LoadBalancerBalance przechowuje w sobie informacje  o tym jakie są Node dostępne na klastrze -  ich IPki  wraz z właśnie NodePort-em  na którym działa Nasz serwis.  request zostanie wysłany do jednego z Nodeów  i do dedykowanego Portu.
    
4.  ten request trafi do nosa  i do Portu,  który dalej przekazany zostanie do serwisu i do Porta serwisu.
    
5.  a ten serwis przekaże dalej ten request do jednego z Podów  który finalnie  zapytanie  I zwróci odpowiedź tą samą drogą. 
    

  

Okej w takim razie wróćmy sobie do naszego okienka z serwisem  i Kliknijmy sobie w link `External endpoints`  i zaczekajmy chwilę.  powinniśmy zobaczyć w naszej przeglądarce  przywitanie z naszego API. 

  

Spróbujmy też wysłać  proste zapytanie z naszego komputera

  

```bash

curl -X GET 34.118.22.224:80

```

  

 i widzimy że działa:

  

Spróbujmy odpytać API z danymi do predykcji

  

```bash

curl EXTERNAL_LOAD_BALANCER_IP:80/decisions -X POST -H "Content-Type: application/json" -d '{"installment_rate_in_percentage_of_disposable_income": 0.25, "age_in_years": 40, "foreign_worker": "yes", "present_employment_since": "unemployed", "personal_status_and_sex": "male: single"}'

```

  

I dostajemy odpowiedź. Widać że to wszystko działa  i udało nam się w ten sposób udostępnić nasze API na zewnątrz.  ten IP teraz będzie stały i niezmienny,  Oczywiście pod warunkiem że tego balancera nie usuniemy i nie postawił na nowo.  to jest pewien problem jeszcze rozwiązania tak żebyśmy zawsze mieli ten sam adres albo ten sam IP to tym zajmiemy się później. 

  

Ja wrócimy sobie jeszcze do tego slajdu naszego związanego z schematem  requesta przez low balancera do naszych Podów, To generalnie to rozwiązanie może już być wykorzystywane w Systema produkcyjnych.  Jedyne czego tutaj brakuje to  rejestracji tego ip-a na jakimś hostingu żeby  odpytywać po jakieś konkretnej nazwie ten serwis oraz  zdobyć certyfikat  TLS żeby móc odpytywać  serwis po protokole HTTPS. Jeżeli mielibyśmy to zapewnione to moglibyśmy iść z tym rozwiązaniem już na produkcję Ale są pewne wady o których musicie wiedzieć:

  

1. Przede wszystkim dla każdego serwisu zostanie stworzony dedykowany LoadBalancer -  oznacza to wzrost waszych kosztów na chmurze dlatego że będziecie mieli tych LoadBalancerów ile macie dedykowanych serwisów. 
    
2. Drugi Problem jest taki że load balancer jest to dedykowana usługa dostarczona przez chmurę Więc jesteście ograniczeni do tego co w ramach tej usługi Możecie ustawić.  jeżeli będziecie chcieli ustawić coś bardziej customowego a nie będzie to możliwe tutaj to niestety tego nie osiągniecie  I musicie zastanowić się nad alternatywami.  
    

  

Aby to uzyskać musimy użyć innego dodatkowego obiektu w Kubernetesie  który w większości nam te kwestie rozwiąże przede wszystkim będzie on wdrożony na naszym klastrze  i  pozwoli nam Na znacznie więcej ustawień  ale o tym za chwilę.

  

Zapomniałem ci jeszcze informacje o tym LoadBalancerze -  tak jak mówiłem to co teraz zrobiliśmy i jest  możliwe w sytuacji kiedy deployujemy na chmurę.  chmura automatycznie stworzę dla nas takiego LoadBalancera.  Natomiast w przypadku klastrów które będą działać na naszych wewnętrznych serwerach,  takie rozwiązanie nie zadziała.  jeżeli ustawiliście typ na LoadBalancer I wdra żyje taki serwis właśnie na klastrach  bare-metalowych,  to nic się nie dzieje,  a jedynie zostanie utworzony Node Port dla serwisu.  Czyli generalnie wtedy ustawienie LoadBalancer będzie tożsame z NodePort. Istnieją dedykowane  rozwiązania pod klastry bare-metalowe czyli właśnie zdeployowane na własnych serwerach,  natomiast Machine Learning Engineerowie  nie będziemy zajmować   się takimi tematami  sieciowymi to już będzie należało do zespołów  DevOpsów czy też System Administrators w waszej firmie.  Natomiast jeżeli kogoś to będzie interesowało to odsyłam do dwóch źródeł:

  

[https://kubernetes.github.io/ingress-nginx/deploy/baremetal/](https://kubernetes.github.io/ingress-nginx/deploy/baremetal/)

[https://metallb.universe.tf/](https://metallb.universe.tf/)

  

I poczytać sobie o tym po prostu w wolnej chwili żeby zobaczyć z jakimi wyzwaniami  można się zmierzyć w sytuacji kiedy ktoś próbowałby nasze rozwiązanie  opublikować na bare metalowym klastrze.  

  


    

**