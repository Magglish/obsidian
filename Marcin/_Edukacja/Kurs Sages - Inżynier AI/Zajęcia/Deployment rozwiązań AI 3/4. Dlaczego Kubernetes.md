# 4. Dlaczego Kubernetes

**

Takie usługi które mają w sobie jakby cały ten element zarządzania wybudowany w komponent tak jak ten właśnie nasz Vertex AI i są  określane jako usługi serverless, Ale nie należy tego interpretować że pod spodem nie ma żadnej infrastruktury,  nie ma żadnego serwera. To że my sobie Vertex wyklikaliśmy jakieś opcje to oznacza że one później są tłumaczone Odpowiednio aby wdrożyć je na jakimś vmce, na jakimś W zestawie kilku wiemek Co można po prostu określić jako klaster -Pod spodem wciąż jest jakaś infrastruktura na której ten model będzie działał tylko po prostu w usługach serverless chodzi o to że wy nie macie za bardzo z nią kontaktu bezpośrednio cała rzecz związana z zarządzaniem właśnie serwerami,  infrastrukturą na którym to będzie działać zostawiacie usłudze które korzystacie,  wy natomiastć się na tym dokładnie co ma być wdrożone,  który model, która wersja i tak dalej. 

  

Jednakże te usługi serwer less  do zarządzania  infrastrukturą która jest tworzona na potrzeby naszych żądań tak po prostu wyklikując w UI jest Również zarządzana przez pewne inne usługi dedykowane pod zarządzane infrastrukturą. Tak się składa że Vertex AI pod spodem zarządza całą infrastrukturą, którą dla Was tworzy, korzystwa właśnie z Kubernetesa. Jest też inna usługa która nie jest dedykowana stricte pod wdrożenia modeli MLowych, Ale można ją też wykorzystać w tym celu ona jest bardziej ogólna można z niej skorzystać też podczas wdrożenia jakichkolwiek innych serwisów,  ona nazywa się Cloud Run I też tam się wszystko wyklikuje natomiast jej na przykład zaletą jest również to że możemy podejrzeć manifesty Jakie powstały żeby wdrożyć nasz model.  manifesty czyli Innymi słowy ten plik konfiguracyjny który będziemy ci się uczyć utworzyć to definiuje to jak dany obiekt ma powstać na kubernetesie.  Vertex Ai z tego co tutaj badałem na to nie pozwala Aby spojrzeć bezpośrednio do Manifestu które powstają,  natomiast na przykład taki Cloud Run na to pozwala, Aby zobaczyć cały plik konfiguracyjny naszego wdrożenia który powstał  i możemy nawet go ręcznie zmienić jeżeli mamy potrzebę ustawienia czegoś customowego.   Innym przykładem mu takie usługi na Google Cloud jest Dataflow  czy też Cloud Composer, Który pozwala na przenoszenie wszelkich worklów zdefiniowanych w Apache Airflow  na chmurę googlową.  i tam też pod spodem działają klastry zarządzane przez Kubernetes. Także Podsumowując usługi serweles pod spodem mają infrastrukturę, Która jest zarządzana przez jakieś  dedykowany do tego narzędzie,  tylko cały  ten Management infrastruktury jest po prostu schowany i użytkownik Korzystając z tego serwisu nie ma z tym styczności  i jest to robione po prostu za niego. Dzięki temu ten Time to deploy jest znacznie prostszy,  łatwiejszy Jeśli ktoś nie ma w tym doświadczenia ale kosztem jest to że poczucie znacznie więcej  i możliwości Dostosowywania tych wdrożonych modeli do waszego jest znacznie znacznie ograniczona.

  

Więc dzisiaj cały ten zjazd jest poświęcony narzędziu/ technologii o nazwie Kubernetes. Tak jak wspomniałem o tym,  na Google cloudzie pod spodem w tych usługach serwerlosowych  infrastruktura Która powstaje na wasze potrzeby jest właśnie zarządzana przez kubernetesa.  i to nie tylko chodzi i wyłącznie o chmurę googlował na które tej działamy,  tak samo jest w przypadku AWSa czy Azure. W przypadku AWS popularnym jest AWS SageMaker, który również pozwala na używanie wtyczek do tego, żeby Wasze joby uczące szły na klaster, czy też żeby Wasze API zostało zdeployowane bezpośrednio na klaster Kubernetesowy. Tak samo jest w przypadku Azure Machine Learning, Natomiast od razu przyznaje się Nie mam dużej wiedzy w aws-ie w azurze więc generalnie bazuje tutaj na informacji które zawarte w dokumentacji i one pozwalają na to żeby  wszelkie Joby czy API było deployowane na klaster Kubernetes.  Natomiast jeżeli skorzystacie z bezpośrednio z AWS Makera, czy Azure Machine Learning i zdecydujecie się na ich domyślny sposób Wdrożenia modeli  to tutaj dokładnie nie wiem jakiej technologii Oni używają pod spodem,  żeby zarządzać infrastrukturą którą specjalnie dla was stworzyli.  znając powszechność jakby  kubernetesa to na pewno zaryzykował stwierdzenia że też pewnie używają  go żeby zarządzać infrastrukturą która specjalnie dla was stworzyli ale to wymagałoby jeszcze w ich serwery w sercu czy na pewno w 100% jest.

  

Druga sprawa jest taka że generalnie powstaje bardzo dużo dedykowanych bibliotek,  albo pewnego rodzaju frameworków które mogą was wspomóc w procesie wdrażania modeli uczenia masztowego, czy nawet samego procesu uczenia modeli i przygotowywania danych, właśnie na klastry zarządzane przez Kubernetes. I przykładowymi takimi usługami które was  mogą wspomóc i na pewno  spotkacie się z nimi kiedy będziecie czytać coś w internecie, Usłyszycie o nich na konferencjach,  spotkacie się z nimi na codzień w pracy. Takimi bardzo popularnymi bibliotekami, skupionymi wokół uczenia maszynowegom są na przykład 

1. Kubeflow -  jest to biblioteka która pozwala wam tworzyć potoki czyli pewny proces od A do Z,  od początku do końca który odpowiedzialny może być już nawet od samego branie danych przygotowanie danych, uczenie modeli, optymalizacja hiperparametrów. Czyli generalnie cały proces który możecie Wykonać w ramach eksperymentów może być zautomatyzowane,   każdy krok może być właśnie wliczany na klastrze kubernetes,   te rozwiązania również dostarczają możliwości wizualizacji tego jak ten cały proces wygląda.  jedna rzecz istotna odnieśli chodzi o kubeflow bo on będzie często się pojawiał generalnie on był chyba pierwszy takim frameworkiem który jakby pozwala przenieść naszą pracę w zależności stworzeniem modeli na klastry Kubernetes. Natomiast ja bym raczej trzymał się od niego z daleka,  a generalnie z trzech powodów Po pierwsze pisanie w nim tych wszelkich kroków  przygotowania danych,  uczenia modeli jest bardzo inwazyjne w stosunku do naszego kodu oznacza to że musielibyście przepisać sporo rzeczy tak żeby kubeflow mógł to uruchomić.  Dla przykładu każdy krok musi być oddzielną funkcją i w dodatku w tej funkcji musicie w środku importować wszystkie biblioteki na nowo.  więc generalnie kod napisany w kubeflow jest straszny. W dodatku wiele funkcji które teoretycznie cukru ma uruchomić trzeba odpowiednio dekorować za pomocą dedykowanych dekoratorów od nich, Co znacznie utrudnia czytelność wszonkowie.  i niestety ale kubeflow  nie pozwala na definiowanie skomplikowanej logiki i zależności pomiędzy pewnymi etapami. Gdybyście dany etap uzależnieni od poprzednich  10 etapów na przykład.  bo to nie jest tak że te etapu podajesz w jakiejś liście  tylko musisz naprawdę napisać 10 ifów zagnieżdżonych Jeden pod drugim żeby to zadziałało. I Trzecia rzecz najważniejsza jest taka że jeżeli spożycie sobie do dokumentacji Cube flow to są wersje druga i pierwsza I generalnie ta druga wersja teoretycznie miała dawno temu wyjść a nie wyszła,  i dokumentacja sama w sobie jest kiepska.  w dodatku dowiedziałem się proszę nie ma roku na konferencji Data Science Summit, Że core’owy człowiek który tworzył Kubeflow, człowiek od Google bo to jest biblioteka od Googlea, Odszedł i generalnie nie widać za bardzo jakichkolwiek zmian  od  jego odejścia więc jest ryzyka że ta bierze taka została po prostu zostawiona. Generalnie Ja wam polecam trzymanie się z Daleko od kuflu nawet jeżeli widzicie pewno tutoriali że nastąpią taką,  może Chcesz pojawiać się jako pierwsza Wyszukiwanie no bo tak jak wam powiedziałem tak było taka istnieje od dawna i generalnie chyba jako pierwsza więc jakby najwięcej jest o mnie w internecie ale obecnie na dzisiejszy czas jest wiele innych frameworków które mają wtyczki aby nasze pipeline działał na klastrze i ja generalnie polecam wam framework Kedro - Który ma wtyczki do wszystkich chmur,  możecie też uruchamiać sobie dotyczące lokalnie więc generalnie stworzycie coś raz i jest to transferowalne na dowolne środowisko., 
    
2. Seldon, KServe - Kolejne biblioteki, Seldon, KServe Skupiają się stricte wokół wdrożach naszych modeli już na klaster kubernetes tak żeby można było z nich korzystać. Cześć logiki już jest schowana pod  Pod pewnymi obiektami które ona tworzą natomiast one pozwalają na dużą modyfikowalność w zależności od tego co co musimy jest to dobry kompromis pomiędzy tą łatwością i customizowalnością, Ale one wymagają już znajomości pisania manifestów czyli tych skryptów określających jak nasze obiekty muszą powstać na placu Więc ona już wymagają pewnej wiedzy o Kubernetesie
    
3. Knative - Jest bardziej ogólnym narzędziem nie tylko wykorzystywanym w kontekście czyli maszynowego Ale w ogóle diplojowania serwisów ale również można go użyć do deployowania waszych modeli. 
    

  

A tam Krótko mówiąc są to przykładowe biblioteki/frameworki, jest ich oczywiście znacznie więcej, które mogą wspomóc was w pracy podczas właśnie definiowania wszelkich potoków uczenia maszynowego. I generalnie rzecz biorąc każda biblioteka, która w jakiś sposób “wdraża” cokolwiek, czy to kontenery z API czy po prostu joby, które przygotowują dane, mają wtyczki, które pozwalają Wam na wdrożenie bądź uruchomienie czegoś na klastrach zarządzanych przez Kubernetes. oczywiście ułatwiają one pewne czynności związane z wydarzeniem na klastry Kubernetes ale również pozwalają na modyfikowanie ich pod nasz Case jeżeli musimy zrobić coś niestandardowego. 

  

Więc generalnie Kubernetes wokół którego jest poświęcony ten zjazd można zaryzykować stwierdzenie, że jest wszechobecny,  w szczególności jeżeli będziecie pracować na chmurze. Dlaczego powiedziałem, że w w szczególności jeżeli bęðziecie pracować na chmurze. Dlatego że konfiguracja i stworzenie klastra kubernetes na chmurze jest bardzo proste,  niestety nie jest tak łatwo Jeżeli mamy swoją własne serwery onprem i tam chcemy zarządzać klasą Kubernetes. Wam powiem że ja nie mam dostatecznej wiedzy doświadczenia w budowaniu klas comborates od zera całkowicie w szczególności środowiskach od premii dlatego tutaj opieram się na doświadczaniu moich kolegów  którzy wymieniali się ze mną doświadczeniami w tym zakresie.  No on-premie jest to trudne. Na chmurze jest to zdecydowanie łatwiejsze. Czy Machine Learning Engineer  musi mieć tak szczegółowo wiedzę o ale to czego bardzo ta sama że móc go postawić od zera na on-premie? Generalnie to oczywiście były duży atut, ale nie jest oczekiwane. I że będzie pracować na chmurze to jest na tyle proste że sobie z tym poradzicie,  a Będziecie pracować na odprawie na swoje własne serwerach i tam będziecie musieli postawić klaster to zapewniam wam, Że na pewno w tym temacie dostaniecie wsparcie  i Generalnie to będzie zadanie DevOpsa czy System Administratora. Bo zawiłości wokół budowania klastra  na on-premie jest bardzo dużo  i jest to bardzo złożony proces. Natomiast to czego dokładnie będziemy się uczyć na tym zjeździe powiem za chwilę.

  

Jeżeli zwróci też uwagę na w ogóle oferty pracy na stanowisko Machine Learning czy AI Engineer Słowo Kubernetes przewija się praktycznie w każdym stanowisku pracy. Dlatego że on jest eneralnie powszechnie używany,  czy to pod spodem w usługach serwer less,  czy  czy właśnie stworzone są specjalne biblioteki do deployowania naszych modeli uczeń Masz nowego które też są zbudowane wokól Kubernetesa. Czy też w ogóle będzie pisać wszystko od zera, w manifestach, dlatego, że chcecie mieć jak największą kontrolę nad tym co jest wdrażane i jak jest wdrażane. Generalnie znajomość Kubernetesa   jest oczekiwana na stanowiskach Machine Learning/AI Engineer. Dlatego też na naszych zajęciach nie będziemy uczyć się konkretnych usługi serwer less, albo wykorzystania konkretnej biblioteki która działa na bazie Kubernetesa. Będziemy uczyć się pisać niskopoziomowe wszelkie pliki konfiguracyjne czyli manifesty Które będą bezpośrednio definiować to jak nasz obiekt ma powstać na klastrze kubernetesowym. Takie podejście niskopoziomowe po prostu pozwoli wam zrozumieć to jak to działa dokładnie. W dodatku też umiejętność definiowania takiej manifestów  niskopoziomowo pozwoli wam też Na po prostu dowolne customowanie waszych manifestów do tego do czego potrzebujecie. Po prostu zobaczycie jak to w środku Działa. Po drugie też Umiejętność definiowania takich niskopoziomowych manifestów i jeżeli wam to się spodoba i generalnie pójdziecie w tym kierunku,  pozwoli wam na zaoszczędzeniu pieniędzy,  dlatego że z tą wiedzą  nie będziecie  decydować się na usługi serwer less,  zatem nie będziecie płacić za tą sferę zarządzania dlatego że wy sami będzie tymi obiektami powstałymi  na klastrze Kubernetesowym zarządzać poprzez właśnie manifesty oraz debugowanie jeśli coś nie działa. Więc skorzystanie z własnego klastra i definiowanie na nim swoich własnych zasobów poprzez manifesty generalnie kosztowo się opłaci to znaczy zapłacić je znacznie mniej gdybyście skorzystali z usługi serwer less.  w dodatku też macie większe pole do manewru i do customizacji waszych wdrożeń w zależności od tego co potrzebujecie.  ale cena jak za to płacicie jest związana z tym że wymagane są większe kompetencje do tego żeby to po prostu ogarniać i  Wymaga to od nas znacznie więcej pracy Niż wyklikanie czegokolwiek w jakimś tam interfejsie graficznym. 

  

Także jeszcze raz potwórzę, w procesach wdrożeniowych, niezależnie czy wdrażanie model MLowy czy jakąkolwiek inną usługę, zawsze musicie ważyć - ten time-to-deploy z kosztami (pieniężnymi i czasowymi) jakie musicie ponieść. Nawet jeżeli będzie ekspertami w Kubernetesie i po prostu definicja wszystkich obiektów na nich przyjdzie Wam z łatwością to i tak będzie czasami czuli, że to co wdrażacie np. działa na tak małą skalę, że generalnie może łatwiej po prostu wrzucić to w usługę serverless i zapłacić troche więcej, ale oszczędzicie sporo swojego czasu jeśli chodzi o deployowanie. Natomiast w przypadku modeli działających na dużą skalę, które są istotnymi elementami w waszym produkcie warto rozważyć coś co pozwoli Wam na pełną customizację wszystkich elementów istotnych dla działania waszego serwisu. Podsumowując, Kubernetes jest wszechobecny - w usługach serverless, są dedykowane frameworki na niego, a nawet jeżeli framework nie skupia stricte się na Kubernetesie to i tak dostarcza wtyczki żeby tam to uruchomić. I znajomość Kubernetesa jest też jednym z podstawowych kwalifikacji wymaganych na stanowisku Machine Learning/AI Engineer.

**