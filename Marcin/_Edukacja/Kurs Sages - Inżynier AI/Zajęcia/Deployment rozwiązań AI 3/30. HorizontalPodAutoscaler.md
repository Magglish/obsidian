# HorizontalPodAutoscaler

  

Przechodzimy zatem do ostatniego tematu naszego zjazdu i zarazem bardzo istotnego w kontekście API MLowego.

  

 Zwróćmy okiem sobie na deployment i mamy tam taki parametr `replicas`  który stanowi o  w liczbie Podów jaka ma działać.  natomiast obecnie ta wartość jest ustawiona statycznie  i jeżeli chcemy jakiś dokonać jakiś zmian to po prostu ręcznie musimy zmodyfikować naszą manifest i wdrożyć w miarę.  to to teraz poznamy to obiekt który będzie odpowiedzialny za to żeby automatycznie skalować,  w dół bądź w górę,  ilość naszych replik.  Czyli generalnie poznamy teraz obiekt w Kubernetesie  który realizuje główny cel w jakim Kubernetes został stworzony,  czyli właśnie autoskalowanie. 

  

Teraz dlaczego nam te autoskalowanie może być potrzebne  i kiedy możemy rozważyć używanie go? Auto skalowany jest zalecane w sytuacji kiedy korzystanie z waszych serwisów jest po prostu zmienne w czasie,  czyli raz serwisy odpytywane na mniejszą skalę a raz na większą skalę. Gdybyśmy nie używali auto skalowania No to możemy rozwiązać ten problem na dwa:

  

1.  po pierwsze możemy po prostu  na bazie danych historycznych zobaczyć kiedy mniej więcej ruch wzrasta a kiedy jest mały  i Na przykład Napisać prostego dzioba który w odpowiednich godzinach będzie  skalował liczbę waszych replik
    
2.  drugi rozwiązanie prostsze jest takie aby  zidentyfikować sytuację w której jest największy ruch na wasze serwisach i ustawić liczbę replik taką żeby ten najbardziej wzmożony ruch mogła obsłużyć i zostawić tą wartość ustawioną.
    

  

Natomiast to nie jest generalnie idealne rozwiązanie.  w przypadku japa no musicie ręcznie takie rzeczy przeanalizować  i ustawić  aktualizację replik w danym okresie czasowym.  i  Jeżeli wasze serwisy Będą inaczej używane No to będziecie musieli te johoby aktualizować na bieżąco i ustalać  nowe godziny kiedy taka zmiana powinna nastąpić.  w przypadku drugim narażacie się na większe koszty dlatego że cały czas będzie działała duża liczba replik która na przykład tylko i wyłącznie Potrzebna będzie o 15:00 każdego dnia.  więc takie sytuacje najlepiej skorzystać jest z obiektu który automatycznie będzie skalował liczbę replik na bazie pewnych metryk.  i generalnie przy API,  w sumie niezależnie od tego czy to jest jakiś API do modeli MLowych czy inne Warto definiować dodatkowo taki obiekt który będzie odpowiedzialny właśnie za skalowanie naszej  liczby replik. Dzięki czemu liczba replik będzie automatycznie i dynamicznie zmieniana w zależności od tego jak dużo ich potrzeba żeby  obsłużyć wzmożony ruch.  wiec  takie auto skyler odciąży was nie będzie musieli definiować jakiś dziobów która ręcznie zmieniają replik w zależności od godziny i pory dnia,  i też  Dzięki niemu zaoszczędzić ci pieniądze bo po prostu wtedy kiedy wasze serwisy są używane w mniejszej skali on liczbę replik zredukuje. 

  

 obiekt który poznamy nazywa się HorizontalPodAutoscaler, Czyli ten autoscaler podów w wymiarze horyzontalnym.  Otwórzmy sobie dokumentację w sek Kubernetes API -> Workload Resources.  i teraz tutaj napotkacie się z dwoma wpisami odnośnie naszego HorizontalPodAutoscaler.  różnica Jaka jest między nimi to w wersji  `V1` oraz `v2`,  my otworzymy sobie na wersji `v2`,  wersja V2 jest najnowszą wersją  i różni się od wersji V1 tym że po prostu ma więcej możliwości.  o tych iększych możliwościach powiem troszkę później możliwościach powiem później -  I generalnie zalecane jest to żeby używać już HorizontalPodAutscalera w wersji V2. 

  

Okej w takim razie zacznijmy sobie od definicji HorizontalPodAutoscalera i Powolutku będziemy przechodzić przez pewne parametry które Musimy ustawić i będę też wam tłumaczył co one oznaczają.

  

Stwórzmy sobie w folderze `deploy/k8s` plik o nazwie `hpa.yaml`. Standardowo jak widzicie zaczynamy od podstawowych czterech pierwszych parametrach

  

```yaml

apiVersion:

kind:

metadata:

spec:

```

  

Które ustawimy odpowiednio: `apiVersion` jako `autoscaling/v2`, `kind` jako `HorizontalPodAutoscaler`, w `metadata` to samo co było wczesniej na deploymencie.

  

```yaml

apiVersion: autoscaling/v2

kind: HorizontalPodAutoscaler

metadata:

  name: credit-scoring-api

  namespace: mrybinski

```

  

I zostaje nam do określenia parametr `spec` czyli specyfikacja naszego HorizontalPodAutoscalera. Jak sobie teraz przejdziemy do tego co możemy na nim ustawić i rzucimy tak szybko okiem jakie ile jest tych parametrów to jest ich trochę. Natomiast jakbyśmy sobie rzucili szybciutko okiem na HorizontalPodAutoscalera  w wersji `v1`  to zobaczymy nagle że specyfikacja jest bardzo krótka. Zaraz powiem Z czego wynika różnica.

 parametrów jest sporo w wersji `v2` do  ustawienia  i generalnie dobre ustawienie HPA  bardzo mocno zależy od API Dla jakiego definiujecie HorizontalPodAutoscaler I ostrzegam was przed tym że dosyć trudno jest na początku zdefiniować dobre parametry dla HorizontalPodAutoscalera,  po prostu to wszystko będzie wychodzić w trakcie obserwacji działania wasze serwisów i to jak one są  używane i to jak ten hPa reaguje właśnie na ruch na serwisach i jak będzie nam skalował te liczbe Podów. Więc to że będziecie w przyszłości po prostu tweakować parametry w HPA  żeby go jeszcze lepiej ustawić to jest rzecz normalna. 

  

Te parametry w dokumentacji są troszkę tak rozsiane więc ja nie będę omawiał mnie w kolejności tak jak one są w dokumentacji tylko po prostu od fundamentalnych i łatwych po coraz trudniejsze. 

  

Zaczniemy sobie od podstawowej rzeczy   jaką jest  określenie dla którego diploymentu nasz HorizontalPodAutoscaler  będzie działał czyli param `scaleTargetRef`.  mamy w nim takie rzeczy jak `kind`,  `name` oraz `apiVersion`. Najlepiej po prostu spojrzeć sobie do naszego diploymentu i zobaczyć te wartości i po prostu  ustawić takie same na naszym  HPA:

  

```yaml

spec:

  scaleTargetRef:

    kind: Deployment

    name: credit-scoring-api

    apiVersion: apps/v1

```

  

Jak już mamy określone z jakim Deploymentem bęðzie działać nasze HPA,  teraz musimy określić zakres w jakim pozwalamy mu na to żeby on skalował liczbę naszych płodów i do tego służą parametry `minReplicas` oraz `maxReplicas`:

  

```yaml

spec:

  scaleTargetRef:

    kind: Deployment

    name: credit-scoring-api

    apiVersion: apps/v1

  minReplicas: 1

  maxReplicas: 5

```

  

Ustawmy je sobie od jednego do pięciu. 

  

Okej Jesteśmy już prawie na końcu  bo musimy teraz ustawić parametr na podstawie którego nasze HPA będzie skalowało nasze rozwiązanie.  i tutaj robi się troszeczkę bardziej skomplikowanie bo metrykę możemy wybrać praktycznie teraz dowolną i to jaką metrykę wybierzemy bardzo mocno zależy od tego czy faktycznie hPa będzie dobrze skalował nasze rozwiązanie. 

  

Zescrollujmy sobie w dół dokumentacji na parametr o nazwie `metrics`  i pierwsze zdanie jakie was przywita to właśnie informacja że metryka to specyfikacja na podstawie której wliczane będzie docelowa liczba replik. Czyli w tym przypadku musimy wsadzić metrykę na podstawie której nasz HorizontalPodAutoscaler będzie skalował nasze rozwiązanie. 

  

Taką podstawową metryką która od zawsze była dostępna w HorizontalPodAutoscaler  jest poziom wykorzystania CPU przez nasze Pody. Możemy zarówno mówić o bezwzlędnym wykorzystaniu CPU,  albo względem wykorzystania CPU czyli w jakim procencie. Natomiast w praktyce w kontekście CPU najczęściej spotkacie się z podejściem względnego wykorzystania CPU,  czyli prostymi słowami ile procent CPU jest wykorzystywane przez nasze Pod i taki wariant rozpatrzymy:

  

Na początek w takim razie ustawmy sobie tą wartość manifeście:

  

```yaml

  metrics:

    - type: Resource

      resource:

        name: cpu

        target:

          type: Utilization

          averageUtilization: 70

```

  

Jak widzicie `metrics` jest listą,  zatem można powiedzieć HorizontalPodAutoscaler-owi  żeby patrzył na dwie dwie metryki  na raz natomiast  z racji tego że jest to pierwszy kontakt z  HPA to my skupimy się tylko na jednej metryce. 

  

W przypadku CPU w `type` wpiszemy sobie `Resource`.

  

 Następnie musimy dokładnie określić o Resource  nam chodzi - w tym przypadku `cpu`.

  

 następnie w `target` Musimy ustawić wartość `Utilization`  i następnie w para `averageUtilization`  ustawmy sobie 70, czyli 70%.

  

 Teraz co mówi te ustawienie  które sobie przed chwilą zdefiniowaliśmy?  hPa będzie tak skalował liczbą replik,  w górę bądź w dół,  aby średnie wykorzystany CPU na waszych Podach  wynosiło 70%. . idealnie Nie będzie 70 dlatego że zawsze będą jakieś zawahania,  tylko domyślnym  z zakresem błędu jest 10% z danej metryki,  czyli będą precyzyjnym hPa będzie celował wywartość 63% do 77% wykorzystania CPU.

  

Teraz pytanie najważniejsze jak kalkulowane jest wykorzystanie CPU na naszych podach.  średnie wykorzystanie spiłu liczone jest jako  wykorzystanie CPU przez poda w miliCPU podzielone przez miliCPU zarequestowane w manifeście w parametrze `requests`.  to jest liczone na pojedynczy Podzie. natomiast  w sytuacji kiedy na diplomacie będzie więcej Podów niż jeden to  to średnie wykorzystanie CPU na całym dyplemencie to po prostu średnia wartość ze wszystkich procentowych wykorzystań CPU na Podach. 

  

I dysponując tą wartością średniego wykorzystania CPU na wszystkich podach  HPA  będzie skalował waszymi replikami Na podstawie poniższego wzoru:

  

$$ desiredReplicas = ceil[currentReplicas * ( currentMetricValue / desiredMetricValue )] $$

  

Gdzie właśnie ten currentMetricValue to wartość średnia wykorzystania wszystkich Podów w Deploymencie.

  

 łatwej będzie to zrozumieć na tym schemacie który Wam teraz pokazuje:

1. Wyobraźmy sobie że mamy deployment który Startuje z jedną repliką,  czyli nasz obecny Case  bo w diploymencie mamy określoną liczbę replik na 1.  określiliśmy sobie że request dlaczego poda to jest właśnie 200 miliCPU. 
    
2. Pojawia się pierwszy ruch na naszym serwisie i wychodzi na to że obecnie jest on zbyt duży i nasze body potrzebują około 100 miliCPU żeby go obsłużyć.
    
3.  wykorzystanie procentowe CPU naszego poda to 100/200 = 50%.
    
4.  Póki co na razie w naszym deeploymencie jest tylko jeden Pod,  zatem  średnia  z procentowego wykorzystania CPU przez nasze body to po prostu 50%/1 = 50%.
    
5. HPA widzi to,  wstawia to sobie do wzoru:
    

$$ desiredReplicas = ceil[1 * ( 50\% / 70\% )]$$

Z którego wychodzi że $desiredReplicas = 1$

Zatem nie wykonuje żadnej operacji dlatego że $desiredReplicas == currentReplicas$.

6. Ruch do naszego serwisu się zwiększa.  teraz nasz pod wykorzystuje 180 miliCPU.  zatem jego średnie wykorzystanie 180/200 = 90%.
    
7. HPa cyklicznie sprawdza wykorzystanie podów,  A będąc precyzyjnym hPa co 15 sekund sprawdza ten stan  i widzi   wykorzystanie CPU przez podykcie i według wzoru:  
    $$ desiredReplicas = ceil[1 * ( 90\% / 70\% )] $$
    

wychodzi, że $desiredReplicas = 2$

Zatem wykonuje operację  dostawiania nowego poda  żeby sięgnąć liczby 2.

8. Nowy Pod powstaje,  zostaje dodany do Service. W związku z tym ruch sieciowy jest równomiernie  rozkładany pomiędzy te dwa Pody.  Załóżmy że ruch się nie zmienił a wody są dwa,  więc Teoretycznie można założyć że każdy z podów wykorzystuje teraz tylko i wyłącznie 90 miliCPU, zatem %-owe wykorzystanie CPU na obu Podach wynosi 90/200 = 45%.
    
9. Teraz są dwa pod dyplomacie więc hPa uśrednia te wartości i wykorzystanie CPU na całą deploymencie wynosi (45%+45%)/2 = 45%.
    
10. Znowu stawia sobie do wzoru  i mamy:
    

$$ desiredReplicas = ceil[2 * ( 45\% / 70\% )] $$

wychodzi, że $desiredReplicas = 2$, które równe jest $currentReplicas$ zatem HPA nic nie robi.

11.  No i kontynując przykład dalej,  Załóżmy że teraz ruch do serwisów jest bardzo duży i wykorzystanie CPU jest na maksymalnym 100% poziomie na obu Podach. Wtedy HPA według wzoru:
    

$$ desiredReplicas = ceil[2 * ( 100\% / 70\% )] = 3 $$

Dostawia kolejnego Poda. 

12. No i ten proces postępuje tak iteracyjnie aż osiągniemy mniej więcej zakładany poziom utylizacji CPU. 
    
13. Jeżeli w przyszłości w momencie działania się serwisów  po prostu ruch się zmniejszy,  to hPa zobaczy że  wykorzystanie CPU od razu jest też mniejsze i odpowiednio zgodnie z tym wzorem będzie te repliki zmniejsza tak żeby cały czas pozostawać wokół tej wartości CPU. 
    

  

To masz w przypadku stosowania HPA i jego definicji  musicie wziąć pod uwagę dwie istotne rzeczy. Spójrzcie na to że we wzorze na wykorzystanie CPU na waszych podach   w mianowniku jest podane request  na CPU,  czyli to jest to co my wcześniej ustawiliśmy na manifeście. Oznacza to że my ustawiając za duży request spowodujemy że praca horyzonta nie bęðzie taka jakiej się spodziewamy, albo nawet w ogóle nie będzie działał  ponieważ przy dużym mianowniku  wartości związane ze średnim wykorzystaniem CPU na wszystkich podach w Deploymencie  będzie po prostu bardzo niska i ze wzoru hPa  stwierdzi że nie ma co zwiększać liczbę Podów.  

  

Tak samo jest z metryką związaną ze średnią poziomu utylizacji czyli nasze nasz cel  który określiliśmy w `averageUtilization`.  kubernetes domyślnie ustawia tutaj wartość 80%. I powiem szczerze że ta wartość jest w przypadku wykorzystania CPU  dobrym kompromisem pomiędzy ilością podów a po prostu kosztem jakim będziecie ponosić za wykorzysanie zasobów CPU i RAMu przez liczbe Podów, które hpa będzie dostawiał aby osiągnąc ten cel.

  

Natomiast powiem szczerze że  te wartości najlepiej sprawdzić jest na testach obciążeniowych które zaraz będziemy robić.  bo musicie pamiętać że ten horyzontal pod HPA który teraz definiujemy  jest sposobem na osiągnięcie pewnego celu. Naszym celem w przypadku serwisów API  jest to aby Odpowiedzi z naszych serwisów były zwracane w akceptowalnym czasie. Teraz co oznacza ten akceptowalny czas? To wszystko zależy od tego W jakich warunkach będzie pracować ale generalnie to będzie jakoś z góry określone,  czy to przez biznes który współpracujecie,  czy to przez samych deweloperów, Którzy będą korzystać z waszych serwisów jako pewien element całego ekosystemu.  więc generalnie to będzie mocno zależeć od tego po prostu z jakim problemem na co dzień będziecie pracować,  i te akceptowalne czasy  mogą być naprawdę różne,  czy to rzędu kilkudziesięciu milisekund, czy też kilku sekund. 

  

Zatem  naszym celem jest to żeby zawsze móc osiągnąć ten zamierzony akceptowalny czas.  jak to osiągamy?  po prostu skalując liczby naszych podów. Natomiast ten nasz HorizontalPodAutoscaler który patrzy na wykorzystanie CPU jest jednym z sposobów na osiągnięcie naszego celu.

  

Weźmy sobie pewien przykład  żeby sobie to łatwiej zwizualizować:

  

1.  Wyobraźmy sobie że naszym celem jest to aby odpowiedzi były związane w ciągu 2 sekund.   przeważnie takie cele są  definiowane jako 95-percentyl  czasu odpowiedzi powinien wynosić dwie sekundy.  czyli 95% odpowiedzi z naszego serwisu  powinno zostać zwrócone w czasie nie większym niż 2 sekundy,  czyli w drugą stronę akceptujemy żeby tylko 5% odpowiedzi  zostało zwrócone w czasie większym niż 2 sekundy.  to jest Najczęściej spotykany schemat,  możecie też  bardziej restrykcyjne cel zakładający że to 99 percentyl będzie wynosił 2 sekundy,  Ale weźmy ten scenariusz najczęstszy  czyli 95%. 
    
2. Startujemy z jednym Podem.  Wyobraźmy sobie że  czas odpowiedzi z naszego poda wynosi jedna sekunda.  do naszego serwisu przyszło requestów na raz. Nasz pot będzie to przetwarzał pojedynczo, request po requescie,  zaczynając od tego kto przyszedł szybciej.  praktycznie niemożliwe jest to żeby ta requesce przyszły o tym samym czasie idealnie co do mikrosekundy zawsze jest jakaś różnica,  dlatego Można je wyobrazić sobie jako po prostu pewną kolejkę.  skoro mamy 10 requestów,  i każdy reques przetwarzany jest jedną sekundę,  to generalnie czasy przetwarzań tych wszystkich requestów wynoszą,  poczynając od tej lewej strony czyli od tego ostatniego requesta który sobie przetworzony, od 10 sekund do 1 sekundy. 95 percentyl z takich czasów przetwarzania  wynosi 9.55 sekund, Co jest znacznie znacznie więcej  niż zakładany cel.
    
3. W takiej sytuacji moglibyśmy dostawić nowego Poda.  Wyobraźmy sobie teraz że mamy dwa Pody. Działanie takie same - każdy z nich przetwarza request w 1 sekundę. I Wyobraźmy sobie że znowu  przychodzi 10 requestów,  i I każdy z powodów dostaje równomiernie po 5 requestów.  w takiej sytuacji requesty zostaną przetworzone dwa na raz,  ale jest ich pięć w kolejce.  więc czasy przetwarzania tych requestów będą wynosić od 5 do 1 sekund.  95 percentyl dla takiego przypadku  wynosi w tej chwili już 5 sekund, ale wciąż znacznie więcej niż 2 sekundy
    
4. Dostawiając trzeciego poda,  może mieć sytuację w której dwa pory mają po trzy requesty, a trzeci 4 requesty. W takiej sytuacji percentyl 95 wynosi 3.55.
    
5. Z czwartym Podem, mamy percentyl 95 równy 3.0.
    
6. Dopiero przy pięciu Podach osiągamy percentyl 95 równy 2.0.
    

  

Czyli w taki sposób skalowanie podów pozwoli wam osiągnąć zamierzony cel w postaci akceptowalnego czas odpowiedzi wyrażonego jako 95 percentyl najczęściej. No dobra czas odpowiedzi czasem odpowiedzi,  a wykorzystanie CPU wykorzystaniem CPU. Jak jedno ma się do drugiego? Tej relacji nie da rady tak łatwo sobie skwantyfikować żeby sobie zapisać to jako wzór,  natomiast w sytuacji w której mamy małopodów czyli ten początek w którym  jednego poda,  to na takim Podzie który musi przyjąć więcej requestów,   wykorzystanie CPU po prostu będzie wyższe,  dlatego że cały czas pracuję i cały czas jest pod pewnym obciążeniem.  w przypadku Podów które przyjmują mniej requestów np. sytuacja z 5 Podami, Wykorzystanie CPU na nich Będzie znacznie mniejsze.  Dlaczego mniejsze?  dlatego że Pamiętajcie że wykorzystanie CPU to jest pewna agregacja w jednostce czasowej. 

  

 tak jak wam mówiłem  CPU  jest raportowane przez Kubernetesa  średnio co 15 sekund. Zatem w wariancie pierwszym kiedy macie jednego poda,  on pracuje przez 10 sekund a przez 5 sekund jest w stanie spoczynku,  w przypadku pięciu podów  potów każdy z Podów Pracuję tylko przez dwie sekundy,  a 13 sekund jest w stanie spoczynku Dlatego jak się uśredni wykorzystanie CPU w tym okresie czasowym,  to pojedynczy pod obsługujący 10 requestów będzie miał tą wartość średnią sCPUybiu znacznie wyższą niż pod który musi obsłużyć tylko i wyłącznie dwa requesty. Czyli bezpośrednio liczba requestów która musi pod cały czas obsługiwać ma wpływ na wykorzystanie CPU przez niego. To też potwierdza fakt który  można bardzo łatwo zobaczyć w naszej konsoli googlowskiej,  w tej Chwili nie przychodzi żaden reku jest do naszego serwisu dlatego widzicie wykorzystanie CPU na bardzo niskim poziomie,  Jeżeli zaczniemy do niego wysyłać requesty No to on musi wykonać pracę i wykorzystanie CPU czy zwiększy.  Im więcej reque Musi przetworzyć,  tym więcej pracy musi wykonać  i tym  większe będzie wykorzystanie jego CPU.

  

 Dlaczego metryka którą ustawiliśmy na manifeście jest Jednym ze sposobów na osiągnięcie zamierzonego celu w postaci akceptowalnego czasu odpowiedzi.

  

Natomiast musze Was ostrzec przed tym że,  żeby uzyskać to co chcemy musimy trochę  mam potestować działania naszego HPA. Bo problem z jakim możecie się spotkać jest następujący: Wróćmy sobie do naszego kejsa z Team requestami.  może być tak że macie już trzy powody,  percenty dla takiego Case'a wynosił 5 sekund  co jest dużo za dużo powyżej waszego celu.  ale wykorzystanie CPU na tych podach nie będzie na tyle wysokie żeby HorizontalPodAutoscaler dostawił kolejnego poda.  I macie problem?  jak to rozwiązać:

  

1.  pierwsze proste rozwiązanie będzie takie żeby w nim zmniejszyć jednak wartość `averageUtilization` Na znacznie mniejszą wartość,  w ten sposób można zaadresować ten problem i będzie on skalował wasze rozwiązanie  i wtedy trzeba zaobserwować że czy faktycznie osiągneliśmy ten cel.
    
2.  natomiast stosując hPa w wersji drugiej którą właśnie teraz używamy  możemy skorzystać z faktu że no Jest on teraz w wersji drugiej a nie pierwszej.  pierwsza wersja pozwala tylko i wyłącznie na skalowanie na podstawie właśnie CPU,  natomiast druga wersja pozwala wam na używanie dowolnych metryk. I bardziej zaawansowanym case'em w tym przypadku byłoby skorzystanie z dedykowanej metryki związanej właśnie z czasem odpowiedzi z waszych serwisów.  jeżeli przeszlibyśmy sobie teraz na przykład do widoku na naszego Ingressa. Jestem zakładka o nazwie Telemetry i mamy wykres latency,  który będzie wam pokazywał czasy odpowiedzi z waszego serwisu. Natomiast Muszę was  zmartwić  że to  Czy możecie uzależnić HPA  od Customowych metryk jest bardzo mocno zależne od tego w jakich chmurze pracujecie,  czy pozwala wam na dostęp do tych metryk.  Jeżeli nie pracujecie na chmurze,  albo pracujecie na chmurze która nie ma takiej możliwości,  to Tyle trzeba dostawić dedykowany serwis który zbiera te metryki,  potem pewne  inne usługi które pozwalają na skorzystanie z  innych metrów waszym hPa,  albo nawet dedykowanego frameworku do customowych hPa na przykład Keda [https://keda.sh/](https://keda.sh/) . Więc niestety praca jako trzeba będzie włożyć żeby móc używać customowych metryk  w hPa może być duża. Ale na przykład jeżeli będziecie pracować na Google cloudzie  to nie musicie nic robić, Bo jestem bardzo proste I dla osób zainteresowanych zostawię taki tutorial [https://cloud.google.com/kubernetes-engine/docs/tutorials/autoscaling-metrics#pubsub_8](https://cloud.google.com/kubernetes-engine/docs/tutorials/autoscaling-metrics#pubsub_8)   jak to można zrobić.  My  z racji tego że pracujemy z hPa po raz pierwszy po prostu skupimy się na tym wymiarze CPU,  który też najczęściej jest używany.  kwestie innych metryk są już bardziej zaawansowane I generalnie rzecz biorąc zawsze zaczyna się od CPU żeby zobaczyć czy uda nam się w ten sposób uzyskać nasz cel. Jeżeli jest to trudne osiągalne to wtedy możemy zastanowić się nad czymś bardziej customowym.
    

  

Okej zanim  przejdziemy do testów obciążeniowych naszego serwisu,  Chciałbym Poruszyć jeszcze jeden bardzo ważny temat  a mianowicie kwestie parametru o nazwie `behavior`, Która dokumentacja wskazuje definiuje zachowania hPa podczas skalowania w dół bądź w góre. 

  

W trakcie działania HPA możecie zaobserwować  duże fluktuacje w ilości podów,  to znaczy są one często ubijane i często powstają nowe.  to może wynikać po prostu z natury używania waszych serwisów.  HorizontalPodAutoscaler dla serwisów które działają  pod naprawdę bardzo różnym natężeniem  po prostu będzie miał dużo pracy do wykonania  i   w związku z czym będzie często podjął decyzję odnośnie usunięcia podów i ich do stawiania.  więc może dojść do takich absurdalnych sytuacji w których hpa usunie Pody które zaraz musi na nowo postawić.  dlatego też istnieje właśnie taki parametr  jak `behaviour`,  który ma zniwelować ten problem. 

  

Parametry te są dosyć trudne w ustawieniu I bardzo mocno zależą po prostu od waszej aplikacji.  omówienie ich  zaczniemy od tego co sam kubernetes proponuje jako wartości domyślne.  wartości domyślne w Kubernetesie to:

  

```yaml

behavior:

  scaleDown:

    stabilizationWindowSeconds: 300

    policies:

    - type: Percent

      value: 100

      periodSeconds: 15

  scaleUp:

    stabilizationWindowSeconds: 0

    policies:

    - type: Percent

      value: 100

      periodSeconds: 15

    - type: Pods

      value: 4

      periodSeconds: 15

    selectPolicy: Max

```

  

Przekopiujmy je sobie do naszego manifestu.

  

Zacznijmy sobie od `scaleDown`  i  parametrów `policies`.  w tym parametrze Police ustalamy to jak bardzo pozwalamy HPA  na skalowanie w dół.  domyślna wartość której kubernetes sam proponuje nam,  chodzi o to że gdybyście nic nie ustawili w tym parametrze to takie ustawienie mielibyście na Waszym HPA. 

  

Te wartości które to są ustawione mówią że o tym że w oknie czasowym 15 sekund  to pozwalamy na to żeby HorizontalPodAutoscaler mógł Wszystkie nasze Body, czyli 100%,  mógł po prostu wyłączyć. Czyli  Przy tych ustawieniach możemy dostrzec taką sytuację w której w jednym momencie  redukowane są wszystkie body dowartości określonej w `minReplicas`  czyli w naszym przypadku 1. 

  

Te policy pozwala na bardzo dużo. A co Gdybyśmy chcieli ograniczyć tą dynamikę skalowania w dół?  zamieńmy sobie tą domyślną wartość na coś innego,  coś mniej zmiennego:

  

```yaml

      policies:

      - type: Pods

        value: 4

        periodSeconds: 60

      - type: Percent

        value: 10

        periodSeconds: 60

      selectPolicy: Max

```

  

Parametry które teraz proponuje są troszeczkę inne I w tej sytuacji mamy teraz dwie polityki.  Pierwsza z nich mówi że w ciągu 60 sekund możesz maksymalnie zmniejszyć liczbę Podów o 4.  a druga polityka mówi o tym że możesz maksymalnie zmniejszyć liczbę Podów o 10%  w czasie 60 sekund.  W przypadku stosowania takich wielu polityk musimy też ustalić parametr `selectPolicy`   którą wartość z której polityki weźmiemy.  czyli załóżmy że mamy 60 podów  i jest decyzja o tym żeby obniżyć ich liczbę.  w takiej sytuacji pierwsza polityka powie nam o tym że możemy zmniejszyć o cztery Pody,  a druga polityka procentowa powie nam o tym że możemy zmniejszyć o 6 Podów,  Zatem zgodnie z parametrem `selectPolicy` HPA zredukuje liczbe Podów o 6.

  

### TUTAJ PRZYDAŁBY SIĘ SLAJD JAK W CZASIE ZJEZDZA LICZBA PODÓW.

  

Z kolei parametr o nazwie `stabilizationWindowSeconds` Oznacza to na jaki okres czasowy wasze hPa ma patrzeć w tył i brać pod uwagę Jaki był  maksymalny docelowy stan  liczby podów czyli wartość  parametru `desiredReplicas` w tym czasie. Czyli to jest trochę taki Rolling maximum w tym czasie.  Ten parametr też można troszeczkę inaczej zinterpretować. mianowicie - po jakim czasie wasze hPa  zacznie skalować liczby płodów w dół, po ostatnim skalowaniu Podów w górę. Czyli załóżmy że wasze hPa powiedziało że teraz trzeba zwiększyć liczbę Podów do 70. Więc przez 300 sekund  HPA  będzie widział że no ten stan stylowy Jaki był do osiągnięcia wynosi 70,  i będzie to respektował  nawet pomimo tego że z metr Wychodzi na to że trzeba to zmniejszyć.  dopiero jak minie 300 sekund,  to wtedy już nie będzie widział  tej decyzji o zwiększeniu do 70  bo będzie poza oknem czasowym  i wtedy rozpocznie skalowanie w dół,  zgodnie z naszymi `policies` które ustawiliśmy,  czyli zredukuje o 7 podów,  następnie za minutę o sześć,  potem o 5  i tak dalej i tak dalej żeby po prostu zejść z liczby płodów do zamierzonego celu w metrykach.

  

Jeśli chodzi o `scaleUp`  No to tutaj  parametry działały tak samo tylko w innym kontekście. `stabilizationWindowSeconds` równe 0 oraz policies ustawione tak, że pozwalamy na natychmiastowe duże dostawienie nowych Podów. 

  

Generalnie rzecz biorąc w przypadku  skalowania w górę chcemy pozwolić HPA na  to żeby mógł szybko zareagować na  wzmożone ruch do serwisów.  natomiast w sytaucji kiedy mówimy o `scaleDown` To chcemy żeby jednak troszkę go zwolnić w skalowaniu w dół.  Dlatego że chcemy uniknąć sytuacji w której jakiś pod zniknie żeby zaraz musiał być ponownie dostawione chcemy tego jak za wszelką cenę uniknąć dlatego Korzystając z `policies` oraz `stabilizationWindowSeconds` Ten proces możemy zniwelować. Proponuję zacząć od Default wartości które Kubernetes sam tutaj ustawia  i jeżeli faktycznie widzimy jakieś duże fluktuacje w ilości płodów w trakcie trwania naszych serwisów możemy wtedy zastanowić się nad tym żeby je  dostosować do naszego usecase.

  

Wróżmy sobie w takim razie naszego horyzontal pod auto z Kellera z domyślnymi ustawieniami, czyli z: 

  

```yaml

  behavior:

    scaleDown:

      stabilizationWindowSeconds: 300

      policies:

        - type: Percent

          value: 100

          periodSeconds: 15

    scaleUp:

      stabilizationWindowSeconds: 0

      policies:

        - type: Percent

          value: 100

          periodSeconds: 15

        - type: Pods

          value: 4

          periodSeconds: 15

      selectPolicy: Max

```

  

Wdróżmy go:

  

```bash

kubectl apply -f deploy/k8s/hpa.yaml

```

  

I na przykład można zobaczyć go w Konsoli Google’owskiej  w naszym Deploymencie i w zakładce `Details`.**