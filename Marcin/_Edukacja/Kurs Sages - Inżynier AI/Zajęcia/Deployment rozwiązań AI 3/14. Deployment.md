# Deployment

  

Okej w takim razie przechodzimy teraz do  to najważniejszego obiektu, Z którym najczęściej spotkacie się podczas waszej pracy i obcowania z klastrami Kubernetes,  czyli obiektu o nazwie Deployment,  który właśnie używany jest w celu wdrażania  serwisów/usług/API cokolwiek na klastry Kubernetes.

  

 w dokumentacji jest to tutaj po lewej stronie w zakładce Workload Resources.  szukamy obiektu o nazwie Deployment.  

I zobaczcie znowu mamy to samo co mówiłem wcześniej czyli podstawowe cztery klucze które musimy ustawić  w naszym manifeście.

  

 czyli Przechodzimy sobie teraz Zamów do folderu `deploy/k8s` i tworzymy plik `deployment.yaml` i zaczynamy od naszych czterech pierwszy parametrów:

  

```yaml

apiVersion: 

kind:

metadata:

spec:

```

  

I analogicznie wstawiamy wartosci w `apiVersion` i `kind`  takie jakie są w dokumentacji. 

  

```yaml

apiVersion: apps/v1

kind: Deployment

```

  

Parametr `metadata`  jest tym samym co wcześniej więc generalnie ustawimy sobie to samo co wcześniej mieliśmy ustawione. 

  

W przypadku parametru `spec` Widzimy że jest to teraz DeploymentSpec, Jak klikniemy to przejdziemy sobie żeby zobaczyć dokładnie czym  czym ta specyfikacja jest.  jeśli Chodzi o status to przypominam że tego się pani wejście nie ustawia,  bowiem jest to informacja przekazywana przez Kubernetes żebyśmy mogli sobie spojrzeć jaki jest status naszego dyplomu.

  

 Przejdźmy sobie do `DeploymentSpec` I zobaczcie że ta specyfikacja jest praktycznie tym samym co dzieli się przed chwilą w `ReplicaSet`. Z tą jedną różnicą że mamy teraz parametr stratag który mówi nam o tym właśnie jak ma wyglądać proces aktualizacji naszych podów z naszym API.  Dobra  To ustawmy sobie te parametry które już znamy a parametr `strategy` weźmiemy sobie na koniec. `minReadySeconds` pomijamy, ustawmy `replicas` teraz na 10. 

 Spójrzmy już raz na selektora. Ja to będę używał parametru matchLabels  który po prostu wskaże nasze labelki, których używamy do tej pory. 

  

`template` też jest praktycznie taki sam bo jest to obiekt `PodTemplateSpec`,  Który widzieliśmy przed chwilą też w `ReplicaSet`. Czyli składa się właśnie z `metadanych` i ze `speca`. Jak widzimy te dane znowu są `ObjectMeta`, a `spec` jest `PodSpec`, Czyli wracamy z powrotem do  specyfikacji naszego poda.  jest generalnie deployment jest praktycznie prawie tym samym co `ReplicaSet` .

  

Wróćmy sobie w takim razie do naszego Manifestu określającego `Deployment`. I generalnie ten `template`  z replika set możemy sobie po prostu wziąć i przekopiować do deploymentu. Przywróćmy na razie wartość container port na 8080. 

  
  

```yaml

apiVersion: apps/v1

kind: Deployment

metadata:

  name: credit-scoring-api

  namespace: mrybinski

  labels:

    phase: live-coding

    app: rest-api

spec:

  replicas: 10

  selector:

    matchLabels:

      phase: live-coding

      app: rest-api

  template:

    metadata:

      name: credit-scoring-api

      namespace: mrybinski

      labels:

        phase: live-coding

        app: rest-api

    spec:

      containers:

        - name: api

          image: europe-central2-docker.pkg.dev/sotrender-rd/mrybinski-live-coding-api/api:single

          ports:

            - containerPort: 8080

``` 

  

Czyli jak spojrzycie sobie teraz na  manifest to jest dosłownie copy paste Naszej `ReplicaSet`,  przy czym mamy jeszcze ten parametr `strategy` mówiący O sposobie aktualizacji naszych Podów do nowej wersji. W takim razie omówmy sobie ten parametr bo on jest bardzo istotny dla nas.

  

### TUTAJ PRZYGOTUJ FAJNY SLAJD JAK DZIAŁAJĄ METODY RECREATE ORAZ ROLLING UPDATE

  

W przypadku deploymentu mamy dwie strategie aktualizacji naszych Podów. Teraz generalnie pytanie powstaje Kiedy następuje aktualizacja? Generalnie rzecz biorąc w procesie Deploymentu i dalszego rozwoju Waszego API No może zmienić się wszystko w tym manifeście które tutaj napisaliśmy. Może dodać jej jakąś zmienność środowiskową która będzie potrzebna do działania.  może zmienicie port na coś innego.  ale najczęściej aktualizowanym parametrem  w waszej Deploymentach będzie wskazanie obrazu.  teraz wskazujemy na API w wersji która nie korzysta z serwisów Postgres i Redis,  ale potem oczywiście skorzystamy z obrazu który z tych serwisów korzysta.  ale naturalnie na produkcji na co dzień będziecie operować obrazami które będą odpowiednio wersjonowane -  czy to będą tagi gitowe czy commity sha. Generalnie jest tak że jakakolwiek zmiana parametrów w manifeście powoduje to że wasze Pody zostaną odtworzone na nowo.  oczywiście są wyjątki niektóre parametry nie powodują ich ponownego odtworzenia,  to są parametry związane z metadanymi,  ale powiem szczerze że ciężko jest zapamiętać które dokładnie to są parametry więc najlepszym założeniem dla was będzie to że jakakolwiek zmiana na manifeście spowoduje odtworzenie waszych Podów. Co oznacza odtworzenie?  oznacza to że po prostu te które istnieją będę musiały zostać ubite,  a w ich miejsce musi powstać nowy Pod z nową konfiguracją. I generalnie tak jak aktualizacje będą przeprowadzane co jakiś czas w zależności od tego  na takim problemie gdzie pracować i jak często będą wprowadzane zmiany do Waszego API,  ale musicie rozważyć przypadek że takie aktualizacje waszego API muszą się odbywać w trakcie kiedy wszyscy inni z nich korzystają. Aktualizacja waszych podów  odbyć się w miarę nieinwazyjnie dla działania pozostałych serwisów które korzystają z naszego API czy klientów korzystających z Waszego API. Oczywiście nie uda się zrobić tego w 100% to znaczy żeby każdy miał zmiany,  ale trzeba to w miarę możliwości zniwelować. 

  

 Dlatego też w deplomacie mamy dwie strategie,  i generalnie używa się w praktyce jednej.  Pierwsza z nich to jest po prostu `Recreate`,  czyli wszystkie Pody ze starszą wersją naraz zostaną zatrzymane  i jeżeli mamy wystarczająco zasobów na VMkach to po prostu na raz zostaną utworzone nowe pody. 

  

I zobaczmy to sobie w akcji. ustawmy w naszym deploymencie wartośc `strategy` na `recreate`:

  

```yaml

  strategy:

    type: Recreate

```

  

I utwórzmy sobie nasz `Deployment`:

  

```bash

kubectl apply -f deploy/k8s/deployment.yaml

```

  

Okej to w takim razie Przejdźmy sobie teraz do naszej konsoli GKE i zobaczmy  czy faktycznie to powstało. Jak widzimy mamy teraz nasz obiekt typu `Deployment`  który ma 10 Podów.  Wejdźmy sobie do niego.

  

Widok Jest bardzo podobny do tego co widzieliście wcześniej,  są te same wykresy z wykorzystaniem CPU, RAM i Dysku.

  

Na dole widzimy 10 podów które powstało z naszym API. Ale oprócz tego pojawiła się informacja o tak zwanych rewizjach,  i widzimy że te pody są z rewizji nr 1.  ta Rewizja  to tak naprawdę ReplicaSet.  czyli deployment pod spodem tak naprawdę  zarządza ReplicaSet,  a rewizja  to nic innego jak wersja ReplicaSet,  i w tym wypadku jest ona pierwsza,  bo przed chwilą wdrożyliśmy. To będziemy robić niedługo ale odezwą zdradzę fakt że deployment przechowuje historię waszej ReplicaSet,  czyli gdybyście wdrożyli jakąś nową zmianę do waszych podów zaraz spowodowałaby to że przestały one działać to bez problemu jesteście w stanie przywrócić poprzednią wersję waszego poda,  zrobić tak zwany rollback. Więc dzięki tym rewizjom które diplomy to sobie przetrzymuje mamy historię naszych zmian i bez problemu będziemy w stanie przywrócić  poprzedni stan jeśli coś nie działa,  ale to będziemy robić później na ćwiczenia. 

  

 Wróćmy do naszego parametru `strategy`. Ustawiliśmy na recreate.  więc teraz spróbujemy wprowadzić zmianę do naszego  poda  i zobaczymy co się teraz stanie u nas w konsoli.  jak Kubernetes sobie z tym poradzi.  Zmieńmy sobie nasz port na wartość 5555. 

  

```yaml

    spec:

      containers:

        - name: api

          image: europe-central2-docker.pkg.dev/sotrender-rd/mrybinski-live-coding-api/api:single

          ports:

            - containerPort: 5555

```

  

I wdróżmy zmiany:

  

```bash

kubectl apply -f deploy/k8s/deployment.yaml

```

  

Teraz szybko musimy odświeżyć naszą konsolę i jak zobaczymy w konsoli, jeżeli nam się to uda oczywiście, To ta strategia powoduje to że najpierw on ubija wszystkie Pody,  i dopiero Pojawiają się nowe,  z naszymi nowymi zmianami.  i zobaczcie proszę od razu że rewizja ma numer 2. Tutaj też jest zakładka jak Revision History  Gdzie możemy sobie podejrzeć właśnie nasze  poprzednie ReplicaSets I zobaczyć jakie były wtedy ustawione  parametry. Niestety przywrócenie proszę nie repliki nie jest możliwe do wyklikania  trzeba to zrobić  po prostu komendami w terminalu,  ale to później będziemy robić.

  

Okej jaki jest problem z tą strategią. No tak naprawdę wszystkie serwisy padną,  więc każdy kto korzysta z waszego API czy to klient czy serwer  generalnie odczuje że coś się stało z serwisami.  w naszym przypadku  nowe pody zostały bardzo szybko postawione więc generalnie  może by tego za bardzo nie odczuli,  ale każdy z was może pracować z innymi modelami i do ustawień nowych Podów może trwać znacznie dłużej,  więc  generalnie niech za bardzo się korzysta z tej strategii. 

  

Bardziej odpowiednia jest druga strategia o nazwie `RollingUpdate`. Hej idea jest prosta: krótko mówiąc, nowe pody są tworzone jeden po drugi, Przy czym z każdym nowym Podem usuwany jest stary Pod. Jest to proste takie gradualne albo inaczej iteracyjne dostawianie nowych wersji. 

  

W takim razie ustawmy sobie ten parametr w  naszej strategii i zobaczmy jak to działa:

  

```yaml

spec:

  strategy:

    type: RollingUpdate

```

  

Oraz prowadźmy jeszcze jakąś zmianę typu port:

  

```yaml

    spec:

      containers:

        - name: api

          image: europe-central2-docker.pkg.dev/sotrender-rd/mrybinski-live-coding-api/api:single

          ports:

            - containerPort: 8080 

```

  

I obserwujmy sobie w konsoli googlowskiej Jak wygląda proces wdrażania nowej wersji.

  

To spowiedźmy dotrze to to że zobaczycie mamy jakby od razu dwie rewizje,  czyli dwie `ReplicaSet`  i sposób tworzenia nowych Podów jest po prostu iteracyjny. Czyli dostawiane są pod z nowej rewizji czyli tej w której ty prowadziliśmy zmiany,  i jednocześnie  usuwane są pody które są w Starej rewizji czyli w tej starej wersji. W naszym przypadku Dzieje się to na tyle szybko że generalnie ciężko jest dostrzec ten proces tak i iteracyjnie.  Natomiast możemy nim sterować  dwoma parametrami które są istotne w tej strategii.

  

Jak wrócimy sobie do Naszej dokumentacji To zobaczymy że mamy takie dwa parametry `maxSurge` oraz `maxUnavailable`. Opis jest dosyć długi i może być nie do końca jasne,  dlatego przestaję wam krótko co te parametry oznaczają

1. `maxSurge` - Oznacza Ile maksymalnie nowych podów z nowej rewizji czyli po tych naszych nowych zmianach może być utworzonych
    
2. `maxUnavailable` -  A z kolei ten drugi parametr oznacza ile tych starych podów,  z tej poprzedniej rewizji  może być usuniętych.
    

  

Żeby wam to zwizualizować Wyobraźmy sobie że ustawiliśmy sobie parametry `maxSurge` równe 3 oraz `maxUnavailable` równie 3  i załóżmy że mamy 10 podów które musimy z update'ować:

  

1.  w takiej sytuacji na początku  Kubernetes  utworzy trzy Pody z nowej wersji  i jednocześnie usunie trzy Pody ze starej wersji.
    
2. Jeżeli nowo utworzone trzy Pody są już gotowe  i funkcjonują poprawnie  oraz te trzy Pody stare już zostały usunięte,  to kontynuują swoją pracę czyli po prostu dalej zostawia trzy  nowe Pody  i usuwa trzy stare Pody.
    
3. I tak to się dzieje aż finalnie 10 Podów będzie w tej nowej wersji.
    

  

 I na przykład defaultowe wartości dla tych  parametrów wynoszą `maxSurge` 25% oraz `maxUnavailable` 25% , czyli w naszym przypadku 10 podów 25% to 2,5 Poda. To w takiej sytuacji Kubernetes będzie usuwał i dostawiał po 2 nowe i stare Pody.

  

Natomiast ja wam powiem szczerze że takie defaultowe wartości parametrów które są ustawione Z mojego doświadczenia troszkę się gorzej sprawują i chciałbym zaproponować inne  ustawiania niż domyślne. 

  

Pamiętajcie o tym że update jakie będziecie wykonywać na waszych serwisach będą wykonywane serwisach które działają i przyjmą requesty,  i tak jak Wam powiedziałem wcześniej Chcielibyśmy żeby te aktualizacje były jak najmniej odczuwalne przez inne systemy czy przez innych klientów którzy korzystają z waszych API.

  

Problem przy defaultowych wartościach związanych jest z parametrem `maxUnavailable`  który wynosi 25%  Default,  więc w naszym przypadku to są dwa PODy.

  

# TUTAJ DODAJ TAKI SLAJD GDZIE ITERACYJNIE TO JEST POKAZYWANE

  

Sprawa jest następująca: 

  

1. Załóżmy właśnie że ten parametr wynosi dwa,  czyli maksymalnie dwa pody ze starej rewizji mogą być usunięte w trakcie aktualizacji.  czyli Innymi słowy w trakcie aktualizacji  suma sprawnych Podów które będą przyjmować wasze requesty  będzie wynosić 8.  dlatego że pozwalam na to żeby dwa Pody maksymalnie były usuwane.
    

Czyli Innymi słowy  w trakcie aktualizacji waszych podów ilość waszych instancji jest mniejsza niż jest to wymagane żeby wasze serwisy funkcjonowały  tak jak chcecie. Co na myśli tak chcecie No chodzi tutaj  przede wszystkim jak szybko Wasz serwis wróci odpowiedź. Po prostu w trakcie wzmożonych ruchów do waszego serwisu Poproszę tą praktą jest praktyką jest to żeby dostawać sobie nowe instancje które ten ruch po prostu przejmą i on rozłączy się równomiernie po wszystkich instancjach więc wtedy jesteście w stanie ten ruch obsłużyć w konkretnym czasie.  więc  więc załóżmy sobie że właśnie te  10 Podów To jest własnie  ta liczba instancji która spowoduje to że jesteście w stanie przyjąć duży ruch i to was satysfakcjonuje.  więc w sytuacji kiedy będzie aktualizacja i liczba Podów będzie schodziłą do 8mu  Podów To w konsekwencji w trakcie tych aktualizacji po prostu zobaczycie,  że na przykład czas odpowiedzi są coraz dłuższe dlatego że jest mniej instancji niż jest to wymagane.  więc generalnie  ta aktualizacja może być odczuwalna  w działaniu innych serwisów czy przez klientów  dlatego że czasy odpowiedzi się wydłużyły. 

2. A druga kwestia jest taka że jeżeli z jakiegoś powodu  te nowe Pody mają w sobie jakiś błąd  to Kubernetes zobaczy że nie są one gotowe,  zatem wasze aktualizacja  utknie w miejscu  dlatego że ona postępuje iteracyjnie i trwa ona do końca tylko pod warunkiem że   kolejna dostawiona nowe pody  z nową wersją  działają.  Jeżeli nie działają,  to Wasza aktualizacja utknie  i zastaniecie przez ten czas cały czas z 8-mioma działącymi Podami  Czyli mniej niż 10,  które ustaliliśmy że będzie w stanie obsłużyć nasz ruch do serwisów. 
    

  

To co ja Chciałbym zaproponować to ustawienie parametrów `maxUnavailable` zawsze na 0, W efekcie jakby aktualizacja będzie trochę wolniejsza niż gdyby tam była wartość większa niż  ale Z punktu widzenia  serwisów które  korzystałem z waszego API czy klientów   zmiany które wprowadzacie będą znacznie mniej odczuwalne. 

  

 Wyobraźmy sobie że ustawimy teraz `maxUnavailable` na 0 i `maxSurge` na 2 i startujemy z 10-ma Podami.

  

1. W takiej sytuacji kubernetes najpierw dostawi nowe 2 Pody,  i dopiero jak one będą gotowe  i funkcjonowały prawidłowo  dopiero wtedy podejmie decyzję o usunięciu dwóch starych Podów -  czyli w efekcie czego zawsze będziecie mieli liczbę 10 podów funkcjonujących w trakcie aktualizacji. 
    
2.  druga sprawa jest taka że  to was Zabezpiecza przed wpadką.  dlatego że jeżeli  będzie jakiś błąd w nowej wersji Poda  i on po prostu nie będzie działał,  Czyli nie będzie gotowy,  to Kubernetes nie ubije wam starych.  dzięki czemu zostaniecie przy 10 Podach, które działają. Pozostałe dwa będą sypać błędami ale dzięki temu  zostajecie przy tych starych Podach które funkcjonują.  więc w ten sposób może to wszystko się zabezpieczyć przed wpadką  z wgraniem czegoś co nie działa.
    

  

W takim razie ustawię sobie te parametry i zobaczymy jak one działają Faktycznie w praktyce.

  

```yaml

spec:

  strategy:

    type: RollingUpdate

    rollingUpdate:

      maxSurge: 2

      maxUnavailable: 0

```

  

 i wdróżmy to

  

```bash

kubectl apply -f deploy/k8s/deployment.yaml

```

  

I Spójrzmy sobie do konsoli Googleowskiej. Ale muszę was zmartwić tym faktem że to się dzieje tak szybko w naszym Case że niestety trudno jest to dostrzec. 

  

Natomiast teraz chciałbym żebyś w drugi ten drugi case czyli załóżmy że nasza  nasza druga wersja ma jakiś błąd.  w tym celu chciałbym żebyśmy użyli obrazu z serwisami ale on nie zadziała dlatego że redisa i Postgresa jeszcze nie ma, Ale dzięki temu zobaczymy że zabezpieczymy się przed wpadką  i też pokażę wam jak w takiej sytuacji zrollbackować do poprzedniej działającej wersji. Zmieńmy obraz:

  
  
  
  
  

```yaml

    spec:

      containers:

        - name: api

          image: europe-central2-docker.pkg.dev/sotrender-rd/mrybinski-live-coding-api/api:with-services

```

  

Natomiast żeby to zadziałało to musimy dodać jeszcze jedną rzecz do naszego Manifestu,  która będziemy dopiero omawiać na części bardziej zaawansowanej,  ale  to tam jest to sobie na chwilę tylko żebyście zobaczyli działanie tego:

  

```yaml

    spec:

      containers:

        - name: api

          image: europe-central2-docker.pkg.dev/sotrender-rd/mrybinski-live-coding-api/api:with-services

          ports:

            - containerPort: 5555

          readinessProbe:

            periodSeconds: 5

            timeoutSeconds: 5

            failureThreshold: 3

            successThreshold: 1

            httpGet:

              port: 8080

              path: /

``` 

  

Daliśmy sobie tak zwany probing  dzięki czemu kuberetes wie jak sprawdzić czy nasz serwis jest gotowy. Na razie bez tłumaczenia  skokujcie tylko to sobie  do swojego kodu  i Zobaczymy czy Kubernetes pozwoli wdrożyć coś co nie działa.

  

i wdróżmy to

  

```bash

kubectl apply -f deploy/k8s/deployment.yaml

```

  

Teraz tutaj możemy zobaczyć, że faktycznie te body powstały i  Ten proces trwa trochę dłużej bo on musi teraz pobrać z repozytorium Nowy obraz którego nie ma jeszcze na naszych Nodeach dlatego troche to dłużej trwa  ale dzięki temu też zobaczymy ten proces Jak wygląda. 

  

I teraz Zobaczcie że mamy sobie dwa nowe Pody,  które  są w statusie Running Ale z takim trójkątem  Co oznacza że nie są gotowe.  Czyli jak widzicie wasze pody które istniały do tej pody  nie zostaną usunięte dopóki te nowe Pody nie będą poprawnie działały,  dzięki temu możesz zabezpieczyć się przed właśnie jakąś wpadką i uderzeniem czegoś co nie działa.  Ale Ale wymagane jest zdefiniowanie `readinessProbe`,  który wam dokopiować do waszego,  ale  spokojnie omówimy sobie co to dokładnie oznacza później,  ale  musieliśmy to dodać dlatego że bez tego by to nie zadziałało. 

  

Po pewnym czasie ten status powinien się zmienić na czerwony i dostać error `CrashLoopBackOff` Który będzie wam się bardzo często pojawiał w sytuacji kiedy właśnie Huberta jest cały czas próbuje postawić kontener A on cały czas  nie działa i kubernera spróbuję w kółko restartować go  i w efekcie  czego tak naprawdę zapętlił się w swoim działaniu. 

  

Wejdźmy sobie do naszego poda który właśnie teraz nie działa. Następnie zakładka logs. No i możemy zobaczyć właśnie co się dzieje w naszym powie. my że po prostu nie ma Redisa czy też nie ma Postgresa  dlatego nasz Pod nie działa.  w tych logach możecie zobaczyć cały tribak który pamiętam rzucił oraz też nasze customowe błędy na przykład `RedisConnectionError`, Czyli te same błędy które sobie zdefiniowaliśmy na pierwszym zjeździe poświęconym API. 

  

No dobrze takiej sytuacji co możemy teraz zrobić.  Jedyne co mu zostaje to po prostu zrobienie rollbacka  i wrócenie do wersji która działa.

  

Jeżeli chcemy wrócić do ostatniej rewizji,  czyli do ostatniej replika set możemy użyć w tym przypadku takie komendy

  

```bash

kubectl rollout undo deployment/credit-scoring-api --namespace=mrybinski

```

  

I jak sobie teraz  spojrzymy to wróciliśmy do naszej poprzedniej rewizji.  przy czym tutaj mała zmiana zwróćcie uwagę na to że wróciliśmy do tej  poprzedniej rewizji która działała ale Kubernetes na Google Cloudzie  określa to jako nową rewizję Zobaczcie że tutaj ta wartość rewizji się zinkrementowała o jeden - niestety taki urok, wolałbym osobiście powrót do starej rewizji, ale tak to tutaj działa niestety. 

  

No właśnie czyli widzicie deployment przechowuje historię rewizji,  i jak wrócimy sobie dokumentacji to właśnie pod tym parametrem strategy, Mamy parametr `revisionHistoryLimit` Który wynosi defaultowo 10,  czyli 10 poprzednich rewizji będzie pamiętane w deeplaymencie i generalnie Ja zostaję przy tej wartości to w zupełności wystarczy.

  

 jest też parametr `progressDeadlineSeconds` który określa czas po jakim  proces wdrażania zmian na Deployment jest zatrzymywane bo coś się stało.  generalnie ten wartość domyśla jest zupełności wystarczająca A ja nigdy nie miałem potrzeby żeby je zmieniać,  natomiast Zobaczymy gdzie mają tego parametru na późniejszych ćwiczeniach i tam będziemy go zmieniać.**
  

Parametrem `paused` Możemy też sterować żeby zatrzymać deployment, no, w połowie aktualizacji. Ale generalnie nic nie miałem okazji żeby z tego skorzystać.

Wracając do naszej komendy:

  

```bash

kubectl rollout undo deployment/credit-scoring-api --namespace=mrybinski

```

  

To powoduje powrót do poprzedniej rewizji. Zamiast takich rewizji jest więcej,  możemy Sobie spojrzeć do zakładki Revision History  i Gdybyśmy chcieli wrócić do konkretnej telewizji to używamy tej samej komendy  ale z argumentem który Vision `--to-revision`:

  

```bash

kubectl rollout undo deployment/credit-scoring-api --namespace=mrybinski --to-revision=6 

```

  

Czyli wróciliśmy do poprzedniej rewizji ale one zawsze są inkrementowane do przodu  niestety tutaj w Google Cloudzie. 

  

Okej Słuchajcie w takim razie obiekt `Deployment` który teraz omówiliśmy Kończ tam generalnie część związaną właśnie z  utworzeniem naszych podów na klastrze kubernetes.

  

 Wróćmy sobie do naszego slajdu i podsumujmy to co do tej pory zrobiliśmy.

  

 oceniliśmy sobie od definicji poda czyli dla przypomnienia podstawowej fundamentalnej jednostki obliczeniowej w kubertesie w którym możemy dopuścić wszystko to co chcemy wdrożyć.  w naszym przypadku umieściliśmy tam kontener z naszym API. Natomiast ty mi poda mi musimy jakoś zarządzać,  odpowiednio je skalować do konkretnej liczby jaką chcemy no i też zarządzać aktualizacjami naszych podów A najczęściej aktualizowany będzie po prostu obraz z nową wersją kodu. Dlatego też w praktyce to wdrażania podów używany jest obiekt deployment,  który tak naprawdę pod spodem zarządza obiektami o nazwie replikaset odpowiedzialnymi za odpowiednią replikację naszych Podów do liczby którą chcemy, Jednakże deployment dostarcza jeszcze tą dodatkową zaletę Gdzie możemy ustalić strategie aktualizacji naszych modów.  i w momencie aktualizacji naszych podłóg tworzona jest nowa replika set z nowym butami i odpowiednio te pod iteracyjne są zamieniane, to znaczy usuwane są stare wersje i dodawane inkrementacyjne nowe wersje. 

  

Więc na razie do tej pory nauczyliśmy się w postawić na klastrze nasze Pody z naszym API. Natomiast one nie są jeszcze dostępne dla nikogo z zewnątrz.  to co będziemy robić niedługo to teraz uczyć się udostępnić nasze API dla kogoś z zewnątrz także mógł z tego sobie skorzystać. Niestety Moim zdaniem wystawienie naszego API na świat i zrobienie tego na klastrach Kubernetes  jest moim zdaniem najtrudniejsze jeśli chodzi o jakiekolwiek deployowanie rzeczy na klastrze  I to sprawia Moim zdaniem najwięcej trudności bo proces jest dosyć zawiły i skomplikowany. Ale zanim przejdziemy sobie do kwestii właśnie związanych z udostępnieniem naszych modeli na świat,  chciałbym  żebyście w ramach ćwiczeń właśnie przeszli sobie przez to co teraz robiliśmy i postawili takie Pody, ReplicaSets oraz Deploymenty  dla naszego modelu tekstowego.  potem też popracujemy sobie na podach i popróbujemy sobie na nie wejść i wchodzisz mi interakcje czyli zrobimy  ćwiczenia bardzo podobne do tych jakie robiliśmy na zajęciach z kontenerów gdzie tam wchodziliśmy sobie do kontenera, usuwaliśmy je, tworzyliśmy, dodawaliśmy volume itd. itd. I sami się przekonacie o tym że interakcja z podami jest bardzo podobna do interakcji z kontenerami więc generalnie wiedza o kontenerach bardzo mocno przydaje się przy pracy z Kubernetesem.

  

Okej w takim razie Przejdźmy sobie do ćwiczeń w ramach których chcę żebyście otworzyli sobie te pierwsze obiekty na klastrze sami na własną rękę.**