# Budowa obrazów w Cloud Build


### TEN OPIS PONIŻEJ POWSTAŁ W TRAKCIE PRZYGOTOWYWANIA LEKCJI O CICD, ALE ODPUŚCIŁEŚ

**

Okej w takim razie zajmujemy się naszym Pierwszym etapem czyli etapem Build w którym to będziemy definiować proces budowy kontenera z naszymi nowymi zmianami które zpushowaliśmy do repozytorium.  i teraz od razu Wam powiem że jesteśmy rzuceni od razu na głęboką  wodę ponieważ na etapie budowy obrazu napotykamy pewien istotny problem.

  

tak jak  widzieliście w tym wyniku działania joba, tam działanie było takie że gitlab uruchamia kontener do którego dorzuca nasze repozytorium.  My na bazie tego naszego repozytorium musimy po prostu zbudować kontener wersją. Czyli dosłownie będziemy budować kontener w kontenerze ale to nie jest  żaden problem.  to problem jest inny.  w naszym repozytorium brakuje jednej istotnej rzeczy która stanowi kod działania naszego API. 

  

Czy ktoś z was widzi  którego obiektu nie mamy w repozytorium?

  

No właśnie brakuje nam modelu.  i tego modelu w repozytorium nigdy nie będzie,  bo jest po prostu za duży i git docelowo nie był utworzony z myślą o tym że przechowywać duże pliki tym bardziej jeszcze binarne i w jakiś sposób je wersjonować.  Oczywiście istnieje git LFS,  Ale generalnie modele  nie będą przechowywane w repozytoriach,  raz że Oczywiście chodzi o ich rozmiar a dwa że naprawdę im będzie dużo,  dlatego że w trakcie pracy  Nad rozwojem modelu  powstanie Wiele różnych wersji modelu i one na pewno będą przechowywane żeby zachować po prostu historię zmian i prac nad konkretnymi wersjami.  modele nie będą w repozytorium,  A będą trzymane na jakimś storyżu No i tutaj w przypadku naszym nasze modele po prostu są trzymane na chmurze w Cloud Storage. Nawet jeżeli będziecie korzystać z jakichś dedykowanych usług do rejestracji modelu na przykład ML Flow Model Registry,  czy jakieś dedykowane usługi od dostarczyciela chmury,  to i tak i tak one gdzieś  muszą być przechowywane i przeważnie będą właśnie na jakimś storyczył w chmurze, w przypadku Google Cloud jest to Google Storage, na AWS S3 itd. itp.

  

Jeżeli wejdziemy sobie teraz na naszą chmurę do usługi Cloud Storage to tam zobaczymy Folder `inzynier-ai-models` z naszymi modelami. 

  

Okej w takim razie mamy nasze repozytorium z kodem na git,  modele na chmurze i jak sobie teraz z tym poradzić?

  

Pierwsza myśl jaka można przyjść do głowy to pobierzmy nasz model do naszego kroku w pipeline CICD i mając ten model możemy zbudować nasz kontener. Niestety ten pomysł jest kiepski.  

1. po pierwsze Modele z którymi będziecie pracować na co dzień może być naprawdę duże,  To wszystko zależy od tego jaki problem rozwiązywać No i co ostatecznie stworzyć.  akurat w naszym przypadku naszych zajęciach nasze modele które wykorzystujemy na zajęciach Są dosyć małe.  ten model klasyfikacyjny z Live-codingu, on waży kilkadziesiąt kilobajtów, YOLO też nie jest zbyt duży,  gpt2  waży 1,5 GB. Natomiast w praktyce możecie spotykać się znacznie większymi modelami. Teraz rozmiar modelu wpływa przede wszystkim na to ile pieniędzy zapłacicie za przesył danych bo jednak chmury działają tak że jeżeli do nich wysyłamy dane to nic nie płacimy,  ale jeżeli z nich pobieramy cokolwiek  to już płacimy.  z kolei im większy rozmiar tym też ten przesył dany Będzie znacznie znacznie dłużej trwał,  Tym bardziej że ten GitLab będzie w innej lokalizacji A na przykład Story czy to tłumaczę też zupełnie innej lokalizacji
    
2. Po drugie jeżeli korzystamy z GitLaba w wersji SaaS  to to by oznaczało że w sumie nasze modele lądują na ich maszyny wirtualne, w Tamtejsze kontenery.  wiadomo że później jak to krok w pipeline CICD się zakończy to wszystko jest wyczyszczone, No ale Załóżmy że  takie wysyłanie  naszych modeli na zewnątrz to po prostu narusza jakieś zasady bezpieczeństwa więc ten pomysł by odpadał.
    
3.  po trzecie jeżeli korzystamy z  GitLaba naszego A tak pewnie będzie w większości  sytuacji jeśli korzystacie z GiTlaba u Was w pracy, To w zależności od tego  jak te maszynki wirtualne są skonfigurowane to takie wysyłanie dużych modeli po prostu może zapchać maszynę, wykorzystując jej przestrzeń dyskową i zasoby. A znając życie na takich wirtualnych maszynkach tych jobów CICD będzie wykonywanych wiele.
    

  

Więc Podsumowując krótko, Wysłuchaj tego modelu na GitLaba kosztuje Was pieniądze,  może być długie im większy model,  kwestia bezpieczeństwa jeśli używacie GitLaba w wersji SaaS,  A jeśli w self-managed to mamy ryzyko po prostu  zapchania maszyny.

  

Najlepszym w tym przypadku rozwiązaniem jest to żeby wykonać te zadanie budowy obrazu właśnie w chmurze.  i my w tym przypadku właśnie tak zrobimy czyli  tak naprawdę Nasz gitab zleci pracę Może po to żeby zbudować tam obraz i będzie ją monitorował,  i się wszystko pójdzie pomyślnie ja to pipeline będzie szedł dalej,  a jeśli nie to oczywiście się zatrzyma.

  

Teraz dlaczego takie rozwiązanie  jest lepszy niż ten wariant pobrania tego modelu na git laba?

1.  po pierwsze  koszty są znacznie mniejsze dlatego że  będziemy działać w wewnętrznej sieci chmury i generalnie za przesyłanie danych  wewnątrz chmury praktycznie się nie płaci.  w dodatku też  przesyłając dane w wewnętrznej sieci chmury ten przesył jest znacznie znacznie szybszy  i to w szczególności będzie odczuwalne Przy dużych modelach.
    
2.  jeśli chodzi o bezpieczeństwo No to sprawa jest prosta modele zostają na tych murze na której są, nie wysyłamy ich nigdzie na zewnątrz
    
3.  i usługi do budowy obrazów na chmurze są bardzo łatwe skalowalne to znaczy my możemy sami sobie wyznaczyć  jakiej mocy ma być maszynka wirtualna na której to się uruchamia,  jest ona tylko i wyłącznie na nasze Joby,  więc nie ma wpływu na inne no i po prostu później  ona się usuwa po zakończonej pracy. 
    

  

My w tym przypadku skorzystamy z usługi o nazwie Cloud Build, które właśnie stosowała stworzona z myślą o budowie obrazów kontenerowych.

**


### TEN OPIS PONIŻEJ POWSTAŁ W TRAKCIE PRZYGOTOWANIA DRUGIEJ LEKCJI, KIEDY ZDAŁEŚ SOBIE SPRAWĘ Z TEGO, ŻE LEPIEJ PRZENIEŚĆ CLOUDBUILDA NA ZJAZD 4-TY A NIE ROBIĆ GO NA DRUGIM, BO NA DRUGIM BEDZIE NA TO ZA MALO MIEJSCA I W DODATKU Z TEGO CLOUDBUILDA AZ TAK MOCNO KORZYSTAC NIE BEDZIECIE. W ZAMIAN PO PROSTU WTEDY PUSH DO REPO BYL RECZNIE, A CALA AUTOMATYZACJA Z CLOUDBUILDEM BEDZIE WYKONANA NA 4-TYM ZJEZDZIE. ALE PONIZSZY OPIS DODALES PONIEWAZ NIE CHCIALES ZEBY POMYSL Z GLOWY CI WYLECIAŁ.

### TEŻ TRZEBA BEDZIE ZAKTUALIZOWAC KOD W REPO NA NAJNOWSZY JAK TUTAJ DOJDZIESZ, BO KOD Z REPO ZOSTAL SKOPIOWANY Z DRUGIEGO ZJAZDU, W POŁOWIE, WTEDY KIEDY CHCIAŁEŚ WŁAŚNIE ZROBIĆ MODUŁ ZWIĄZANY Z CLOUD BUILDEM

  

W takim razie przechodzimy do następnego etapu.  do tej pory cały czas budowaliśmy kontenery lokalne,  na naszym laptopie.  ale w rzeczywistości tak nie będzie, w pipeline  cicd musi zadziać się wszystko automatycznie. Do budowy kontenerów w sposób zdalny,  czy na jakiś serwerach po prostu są stworzone do tego dedykowane usługi.  na Google na którą teraz pracujemy jest usługa zdefiniowana jako Cloud Build [https://console.cloud.google.com/cloud-build/dashboard](https://console.cloud.google.com/cloud-build/dashboard) Która po prostu buduje kontenery.  generalnie pod spodem to działa tak że uruchamia wirtualną maszynkę,  buduje kontener zgodnie z tym jak to zdefiniujemy,  wyślę go na naszego repozytorium które wskażemy  i wirtualna maszynka po prostu się wyłączy.  usługa jest bardzo tania, Ma dobre maszynki na których  zbudowane są kontenery więc za bardzo wymagających buildów jest to super rozwiązanie  no i te maszynki są znacznie lepsze niż defaultowe maszynki które mamy na GitLabie. Generalnie gitlab będzie takim miejscem zbierania wszystkich informacji,  a my odpowiednie joby będziemy wysyłać do odpowiednich miejsc. 

  

W takim razie zaczniemy sobie od początku.  przejdź naszego folderu deploy/docker I dodatkowo stwórzmy sobie jeszcze jeszcze folder python.  na drugich zajęciach z kontenerów wrzuciliśmy sobie obraz pythona Zgodnie z tym co wam mówiłem Czyli że mieć pewność że pobieramy całość to auto samą wersję,  oraz żeby nie  przekroczyć limitów na docker hubie. Natomiast teraz będziemy też ten proces sobie automatyzować.

  

Będziemy budować obrazy na Google cloudzie  i podobnie jak obrazy budowano lokalnie używają `.dockerignore`,  tak obrazy budowane na chmurze będą używać `.gcloudignore`:

  

(W PONIŻSZYM .gcloudignore NIE MOZE BYC Dockerfile BO COS SIE WALI Z BUDOWANIEM OBRAZU)

  

```

venv/

.venv/

.poetry_cache/

data/

.git/

.idea

**/__pycache__

.ipynb_checkpoints

.vscode/

.coverage

.cache

**/.pytest_cache

**/*.html

.dockerignore

.gitignore

```

  

W `deploy/docker/api` stwórzmy sobie plik `cloudbuild.yaml`, który definiować będzie to jakie kroki mają być wykonane w Cloud Build, żeby zbudować nasz obraz.

  

Definicję pipelinu który  ma się uruchomić na cloudbildzie Aby zbudować nasz kontener zaczynamy od argumentu  wartości `steps`:

  

```yaml 

steps:

```

  

Steps będzie listą Listą czynności które musimy wykonać. Teraz jakie będziemy to wykonywać czynności?  takie same jak byśmy robili na komputerze tak naprawdę.  przy czym tutaj trzeba pamiętać o tym  że ten pipeline będzie wykonany na nowej maszynce,  na czystej maszynce wirtualnej. A Przypominam o tym że najlepiej budować Jest tak kontenery Żeby korzystać z casha po to aby ten proces był szybszy. Niestety,  nie wiem czy pamiętacie ale na drugim zjeździe tłumaczyłem o tym że są dwa rodzaje silników budowy kontenerów.  w Cloud Buildzie który teraz będziemy używać, Niestety działa jeszcze ten stary silnik budowy kontenerów.  Oznacza to  że jeżeli chcemy skorzystać z cash-a jakiegoś kontenera,  to ten kontener musi być już na maszynce wirtualnej,  a my go jeszcze nie mamy w tej chwili. Więc tak naprawdę nasz pipeline budowy kontenera będzie bardzo prosty i składał się tylko z trzech etapów

1.  na początku pobierzemy sobie obraz z naszego repozytorium po to żeby użyć go jako casha i przyśpieszyć w ten sposób proces budowy
    
2.  następnie w drugim kroku będziemy budować ten kontener
    
3.  a w trzecim Wyślemy go do naszego repozytorium
    

  

 i to będzie koniec. 

  

W takim razie zaczniemy sobie od definiowania naszego `cloudbuild.yaml`

  

```yaml

steps:

  - id: "pull-latest-container"

  - id: "build-new-image"

  - id: "push-to-repository"

```

  

Mamy listę trzech elementów,  czyli będziemy mieli trzy kroki  i na ten moment nadaliśmy sobie idki, które w skrócie mówią nam co będziemy robić.

  

Zacznijmy sobie od pierwszego kroku czyli od ściągnięcia najnowszego kontenera.

  

Drugi argument który musimy nadać to jest `name`:

  

Teraz to jak wam powiedziałem wirtualna maszynka która zostanie uruchomiona do tego żeby zbudować nasz kontener Generalnie za dużo rzeczy w sobie nie ma.  dlatego Cloud Build działa tak że On dostarcza pewnego rodzaju builderów które mogą wykonywać pewne działania.  tymi Bilderami są po prostu kontenery w których będą uruchamiane nasze konkretne kroki. Czyli generalnie będąc precyzyjnym nasz kontener będzie budowany w innym kontenerze. My korzystamy z Dockera podczas budowy naszego kontenera,  ale gdybyśmy korzystali z innych technologii Do budowy kontenerów to też są buildery do nich:

  

```yaml

steps:

  - id: "pull-latest-container"

    name: 'gcr.io/cloud-builders/docker'

```

  

Czyli w tym momencie wskazaliśmy, że naszym builderem będzie docker.

  

Dalej musimy wskazać co chcemy zrobić.  od razu napiszę kod i wytłumaczę wam jak to działa: 

  

```yaml

steps:

  - id: "pull-latest-container"

    name: 'gcr.io/cloud-builders/docker'

    args: ['pull', 'europe-central2-docker.pkg.dev/sotrender-rd/mrybinski-live-coding/api:latest']

```

  

Tak się składa że ten Builder który to Wskazałem,  to jest kontener  z zainstalowanym Dockerem w sobie I  jego ENTRYPOINT  wskazuje po prostu na `docker`. Więc w takiej sytuacji w kluczu `args` Musimy po prostu wskazać to co zostanie przekazane do tej komendy `docker`. 

  

Czy to jest to samo  jakbyśmy lokali na komputerze napisali po prostu

  

```bash

docker pull europe-central2-docker.pkg.dev/sotrender-rd/mrybinski-live-coding/api:latest

```

  

Czyli to co to co robiliśmy wcześniej na naszym.

  

Teraz Cloud Build ma bardzo fajny argument `allowFailure`:

  

```

steps:

  - id: "pull-latest-container"

    name: 'gcr.io/cloud-builders/docker'

    args: ['pull', 'europe-central2-docker.pkg.dev/sotrender-rd/akowalski-live-coding/api:latest']

    allowFailure: true

```

  

W którym przypadku pullowania obrazu jest bardzo przydatny. Dlaczego pozwalamy na to żeby ten krok mógł zfailować? Dlatego że my pobieramy ten obraz po to żeby skorzystać z cashe. Jeżeli tego obrazu nie będzie w repozytorium,  to nic nie szkodzi,  nasz kontener w drugim kroku zbuduje się bez problemu,  ale będzie się budował po prostu wolniej, Ale się zbuduję. więc nie chcemy żeby ten krok związany z pullem  po prostu zatrzymywał cały proces budowy kontenera, jeżeli tego obrazu nie będzie, bo tak jak mówie - zbudujemy nowa wersje kontenera bez problemu.

  

I to kończy nasz pierwszy krok.

  

Zanim pójdziemy dalej chciałbym wprowadzić jedną rzecz tutaj w campbildzie to jak nam znacznie łatwiej teraz późniejszą pracę.  ta specyfikacja kroków Cloud bilda którą właśnie teraz pozwala nam na definiowanie zmiennych, Więc Dodajmy ją sobie po stepsach:

  

```yaml

substitutions:

  _REPO_PATH: 'europe-central2-docker.pkg.dev/sotrender-rd'

  _REPO_NAME: 'akowalski-live-coding'

```

  

Czyli po prostu mam jedną zmienną `_REPO_PATH` która wskazuje na tą ścieżkę i  druga zmienna `_REPO_NAME` wskazująca na nazwę. Teraz Z mojego doświadczenia rekomenduje wam nadawanie nazw zmienne środowiskowych od podłogi,  czyli na przykład numerze pythonowej oznacza to coś prywatnego.  natomiast to jest związane z tym że Cloud Build ma bardzo dużo zmiennej środowiskowych gotowych dla nas którym możemy użyć w przypadku definiowania to jak nasze kontry mają budowane,  i używając podłogi przed nazwą po prostu zabezpieczamy się że czegoś nie nadnapiszemy co może coś popsuć. 

  

W `_REPO_PATH` wstawimy naszą ścieżkę do repo i ona dla każdego z Was będzie taka sama, natomiast w `_REPO_NAME` wstawcie proszę swoje repozytorium, które skłąda się z pierwszej litery imienia, potem nazwisko, potem `-live-coding`, np. `mrybinski-live-coding`.

  

Zmodyfikujmy sobie nasz pierwszy etap żeby z tych zmiennych skorzystać:

  

```yaml

  - id: "pull-latest-container"

    name: 'gcr.io/cloud-builders/docker'

    args: ['pull', '${_REPO_PATH}/${_REPO_NAME}/api:latest']

    allowFailure: true

```

  

Drugi krok jak sama nazwa wskazuje zakłada budowę obrazu.  i schemat działania będzie bardzo podobny tak jak to było w poprzednim roku, Czyli w `name` wskazujemy naszego buildera, A w `args` będziemy podawać to jak mamy ten kontener budować.

  

Teraz zwróćcie uwagę że pracujemy w YAMLu Czyli mamy te same zasady które na kubernetesie.  elementy listy w YAMLu będą połączone i rozdzielone spacjami, Więc tak naprawdę każde kolejne argumenty po prostu będą elementem listy.

  

```yaml

  - id: "build-new-image"

    name: 'gcr.io/cloud-builders/docker'

    args: [

      'build',

      '--tag=${_REPO_PATH}/${_REPO_NAME}/api:latest',

      '--file=deploy/docker/api/Dockerfile',

      '--cache-from=${_REPO_PATH}/${_REPO_NAME}/api:latest',

      '--network=cloudbuild',

      '--progress=plain',

      '.'

    ]

```

  

Czyli tak jak  Robiliśmy to na zjeździe drugim

1.  nadajemy tagi
    
2.  wskazujemy Gdzie jest nasz Dockerfile
    
3.  używamy argumen `--cache-from`  po to aby wskazać właśnie na kontener który przed chwilą pobraliśmy w poprzednim kroku po to aby skorzystać z niego jako cache
    
4.  Następnie musimy dodać dwie rzeczy które są niezbędne w przypadku stosowania Cloud builda czyli `--network=cloudbuild`  oraz `--progress=plan`  dzięki czemu Zobaczymy cały output w konsoli Cloud Build,
    
5. No i na końcu kropeczka, Czyli wskazanie Z którego miejsca budujemy kontener się zaczyna czyli w przypadku naszym po prostu z repo, Czyli wskazujemy z jakiego miejsca ma powstać Build Context to o czym wam mówiłem na zjeździe drugim. 
    

  

No i słuchajcie to Kończy nam od razu nasz krok drugi. 

  

Przechodzimy teraz do ostatniego kroku,  skoro mamy już konto rozbudowane to trzeba po prostu zpushować do repo.

  

```yaml

  - id: "push-to-repository"

    name: 'gcr.io/cloud-builders/docker'

    args: ['push', '--all-tags', '${_REPO_PATH}/${_REPO_NAME}/api']

```

  

Czyli jest tak samo jak wcześniej ustawiamy `name` na buildera, którego chcemy użyć. Następnie komendę Push nasz obraz. Przy czym bardzo ważne jest to że tutaj Nadałem argument `--all-tags`, Dlatego że naszemu obrazowi nadaliśmy kilka tagów, Po to aby łatwiej go zidentyfikować w naszym repozytorium i łatwiej też go pulować.  bez tego Argumentu zostanie zpushowany obraz tylko z jednym tagiem który został nadany jako pierwszy. 

  

Dobra w takim razie zapniemy to w nasz Spróbujmy w takim razie  spróbować odpalić to lokalnie:

  

```bash

gcloud builds submit --region=europe-central2 --config=deploy/docker/api/cloudbuild.yaml --async 

```

  

W tym celu używamy `gcloud builds submit` Który wchodzi w interakcję z Cloud Buildem I to ogromna prośba do was żeby pamiętać o argumencie region `--region=europe-central2` Żeby wszelkie operacje wykonywały się właśnie niedaleko nas w Warszawie. Jeżeli ktoś z was tego argumentu nie poda to oczywiście tragedii nie ma,  ale już teraz się was uczulać po prostu na wybór regionu w momencie kiedy wchodzicie w interakcje z chmurą dlatego że od regionu dużo zależy -  to ile zapłacicie,  oraz to jak długo zajmie przesył danych. Nasze klastry, serwisy obecnie stoją na `europe-central2`, więc chcemy budować w tym samym miejscu. I na końcu wskazanie gdzie jest nasz plik definiujacy kroki  powstawania naszego obrazu `--config`  i na końcu flaga `--async` Po to aby nie blokowało nam naszego terminala.

  

Po uruchomieniu mamy od razu informacje o tym że ten job został  zlecony No i mamy też linka żeby sobie go podejrzeć.  Wejdźmy do niego i zobaczmy co się dzieje.

  

Także widzimy że mamy output z Każdego kolejnego kroku,  

1. najpierw jest pulowany z obraz naszego repozytorium

2.  następnie mamy krok związany z budową tego obrazu tak zdefiniowaliśmy

3.  i na końcu pushowanie do repozytorium

  

Wejdźmy sobie takie rzeczy do Artifact Registry I naszego repozytorium  I zobaczmy w takim razie czy wszystko jest. 

  

### DALSZE KROKI KTÓRE TRZEBA WYKONAĆ, ABY DOKOŃCZYĆ LEKCJE O CLOUDBUILD ZOSTAŁY SPISANE PONIŻEJ, ALE NIE ZOSTAŁY ONE PRZYGOTOWANE PODCZAS PRZYGOTOWANIA LEKCJI NA 2-GI ZJAZD BO DALSZE KROKI MOCNO ZALEŻĄ OD 3-CIO ZJAZDY ORAZ POCZATKU 4-GO

  
  
  

1. Wytłumacz jak jest budowany obraz - w sensie wysyłanie build context do chmury. I nasze repo jest rozpakowywane w VMce i budowany obraz. Dlatego lepiej nie umieszczajcie w `.gcloudignore` Dockerfile bo wtedy on nie zbuduje obrazu - pokaz im.
    
2. Wróć do pipeline CICD i dodaj ten krok, żeby obraz się budował automatycznie
    
3. Na razie jest tag tylko latest, wiec trzeba dodać jeszcze tag z commitem. żeby to osiągnąc trzeba wprowadzić nowy parametr w `substitutions` i potem w `gcloud builds submit` dodać argument `--substitutions=_COMMIT_SHA=<...>`
    
4. Trzeba utworzyć folder z `python` i dodać Dockerfile tylko z FROMem, wyjaśnij, że chcemy być spójni z tym jak są budowane inne obrazy, a FROM to nic innego jak git pull.
    
5. Trzeba dodać `cloudbuild.yaml` do pozostałych czyli do `python`, `redis` oraz `postgres`. Wyjaśnij im, że to wszystko zależy od use case’a - jeżeli przygotowujemy bardziej generalny obraz, jak np. python to można go umieścić w innym repo: “generalnym repo”, a np. takie specyficzne obrazy dostosowane pod nasz use-case, mogą trafić do tego samego “repo” - to wszystko zależy od warunków w jakich pracujecie. Założmy, na potrzeby naszego zjazdu i przećwiczenia, że każdy z nas chce mieć swój obraz z pythonem, redisem i postgresem. I od tego zależy jak nasze API działa. Więc wepnij to też w pipeline CICD. Natomiast w rzeczywistości może być tak, że to będzie w oddzielnych repozytoriach i tam też będą pipeline’y CICD, które wrzucaja nowe wersje obrazu. Przy czym pushowanie takiego samego obrazu do Artifact Registry ma taką fajną zaletę, że nie powstanie nowy obraz jeżeli już taki był, a po prostu zostanie dodany mu tag z commitem. Więc generalnie to jest o tyle fajne, że mając informację o commicie mamy cały kod jaki został wtedy wdrożony, ORAZ wszystkie obrazy, które zostały użyte do działania naszego API.
    

Pokaż im jak to zrobić na przykładzie np. Pythona. Ale w ramach ćwiczeń niech zrobią wszystko u siebie: api, postgres, python, redis, wpieli to w CICD. (Ale ty musisz też wtedy sam to zrobić dla live-codingu żeby potem wszystko działało poprawnie - może wtedy kiedy będą wykonywać ćwiczenia? Przygotuj sobie w notatkach gotowe rozwiązania tak aby nie było problemów).

6. Wepnij to potem do pipeline CICD.
    

## DOCELOWY YAML? SPRAWDZ


```yaml

steps:

  - id: "pull-latest-container"

    name: 'gcr.io/cloud-builders/docker'

    args: ['pull', '${_REPO_PATH}/${_REPO_NAME}/api:latest']

    allowFailure: true

  - id: "build-new-image"

    name: 'gcr.io/cloud-builders/docker'

    args: [

      'build',

      '--tag=${_REPO_PATH}/${_REPO_NAME}/api:latest',

      '--file=deploy/docker/api/Dockerfile',

      '--cache-from=${_REPO_PATH}/${_REPO_NAME}/api:latest',

      '--network=cloudbuild',

      '--progress=plain',

      '.'

    ]

  - id: "push-to-repository"

    name: 'gcr.io/cloud-builders/docker'

    args: ['push', '--all-tags', '${_REPO_PATH}/${_REPO_NAME}/api']

substitutions:

  _REPO_PATH: 'europe-central2-docker.pkg.dev/GCLOUD_PROJECT'

  _REPO_NAME: 'mrybinski-live-coding-api'

```
