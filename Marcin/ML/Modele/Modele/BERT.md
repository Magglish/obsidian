# BERT 

BERT - [Bidirectional Encoder Representations from Transformers](https://arxiv.org/abs/1810.04805).

To tylko i wyłącznie [[Encoder-Decoder|Encoder]].

Uczony techniką [[Masked language modelling]] i [[Next-sentence prediction]]