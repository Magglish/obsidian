# Coverage loss

Loss, która wstrzymuje [[Attention mechanism|mechanizm atencji]] przed skupianiem się na tych samych słowach - jeden ze sposobów na to aby zredukować problem z powtarzaniem generowanych tokenów poprzez modele generatywne.