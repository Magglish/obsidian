# Activation Function

Funkcja aktywacji w sieci neuronowej, przykłady:

1. [[Sigmoid]]
2. [[Tanh]]
3. [[ReLU]]
4. [[PReLU]]
5. [[ELU]]
6. [[Maxout]]

Dlaczego ich używamy? Gdybyśmy ich nie użyli, to tak na prawde nasz model byłby jednym wielkim liniowym klasyfikatorem