# Exponential Linear Units

![[ELU Activation Function.png]]

1. Te same zalety co [[ReLU]]
2. Gradienty w całym X
3. Wartości wychodzące są bardziej zcentorwane wokół zera

Wady:

1. Więcej do obliczeń, bo wchodzi `exp` do wzoru