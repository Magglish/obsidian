# Word Embeddings

Word Embedding to nic innego jak reprezentacja numeryczna słów za pomocą wektorów, powstają w wyniku użycia modeli [[Word2Vec]]

Podejścia:

1. [[One-hot encodding]]
2. [[CBOW]]
3. [[One-hot word embeddings]]