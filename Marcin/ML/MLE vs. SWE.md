# MLE vs. SWE

1. **Nowy wymiar - dane** - W klasycznym projekcie IT wersja kodu określa wersję oprogramowania. W projektach z uczeniem maszynowym na wersję modelu wpływa wersja kodu i wersja danych. Reagowanie na zmianę kodu spowodowało rozwój specjalizacji DevOps. Natomiast projekt z uczeniem maszynowym to reagowanie na zmiany w kodzie i w danych, co podnosi trudność przynajmniej do kwadratu.
2. **Dłuższa pętla zwrotna** - Podczas gdy oprogramowanie na ogół może być opracowywane lokalnie wraz z natychmiastową pętlą zwrotną, jak nowa linia kodu wpływa na wynik końcowy. Piszesz test, sprawdzasz, czy świecą się tylko zielone światła, i idziesz dalej. W uczeniu maszynowym pętla zwrotna zaczyna się w tym samym miejscu, jednak może się skończyć za parę godzin, kiedy to skończysz trenować model.
3. **Większa ilość elementów do wersjonowania** - Ponieważ to wersja kodu tworzy wersję oprogramowania, dzięki systemowi kontroli wersji możemy w dowolnej chwili zbudować dowolny wariant aplikacji. W przypadku uczenia maszynowego jest inaczej.  Po pierwsze, wynikiem pracy nie jest kod, a model. Ten natomiast wynika z wersji kodu, który tworzy i trenuje model, oraz danych, które wykorzystuje. Dlatego jeśli chcesz mieć taką samą maszynę czasu, kiedy rozwijasz projekty z uczeniem maszynowym, musisz wersjonować kod, dane, a najlepiej i modele.
4. **Trudność w znalezeniu rozwiązań** - często eksperymentowanie oparte jest o intuicje, dlatego tak ważne jest doświadczenie w branży. Nawet znane patterny/rozwiązania z poprzednich prac czy opracowane przez inne duże firmy, nie zawsze będą działać do Twojego use-casea. Oznacza to, że ML jest bardziej eksperymentalny niż wytwarzanie tradycyjnego oprogramowania i często polega na zrobieniu kilku kroków wstecz żeby móc pójść dalej. 
6. **Trudność w testowaniu** - Do testowania dochodzi również element:
	1. testowania danych - zautomatyzować upewnianie się, czy są w takim stanie, w jakim oczekujemy  - testowanie danych powinno być spójne dla danych treningowych i podczas predykcji na żywo.
	2. testowania modeli - modele wymagają regularnego odświeżania, ponieważ danych cały czas przybywa, a ich charakter ulega ciągłej zmianie.
7. **Trudność w debugowaniu** - rzadko się zdarza że pierwsza iteracja algorytmu jest dobra. Możemy spotkać dwa problemy - Twój algorytm nie działa lub Twój algorytm działa niedostatecznie dobrze. W SWE jeśli kod nie działa to przeważnie problem leży gdzieś w jednym z dwóch wymiarów: od strony algorytmicznej albo od strony implementacyjnej.  
8. **Trudność w monitoringu** - W klasycznej aplikacji monitorujemy zarówno zużycie hardware (RAM, CPU), jak i samą aplikację, mierząc liczbę zapytań na sekundę i na podstawie tych metryk możemy odpowiednio reagować. W przypadku modeli monitorowanie również polega na obserwowaniu jego zachowania w czasie - czy predykcje na produkcji różnia się istotnie od tego co obserwowany w zbiorze danych uczących, czy podejmuje tak samo decyzję jak na danych uczących.
9. **[[Continuous Integration|CI]]/[[Continuous Deployment|CD]]/[[Continuous Training|CT]]/[[Continuous Monitoring|CM]]** - Ciągła integracja i ciągle dostarczanie to zbiór praktyk, które mają na celu automatyzować wdrożenia i codzienną pracę nad kodem tak, aby każda zmiana bez dodatkowego tarcia dotarła na zdalne środowisko. W podręcznikowej aplikacji jedynym powodem do zbudowania i wdrożenia nowej wersji jest zmiana w kodzie. Z modelami i tym razem jest inaczej. Modele się starzeją, a po pewnym czasie stają się bezużyteczne. Tym razem – dla odmiany – to przez dane. Dane, w których pojawiają się nowe wzorce, zmieniają się trendy. Rozwiązaniem tego problemu jest cykliczne, regularne trenowanie modeli. Jak widzisz, to nie tylko zmiana kodu powoduje wdrożenie nowych modeli. Oznacza to, że musisz stworzyć i utrzymywać dodatkowy proces.

**Dodatkowe powiązania:**
[[ML Code w infrastrukturze]], [[MLOps vs. DevOps]]

**Źródła:**
1. https://datasciencein.pl/uczenie-maszynowe-na-produkcji-dlaczego-to-takie-trudne/?utm_source=pocket_mylist
2. https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#devops_versus_mlops
3. https://ai.stanford.edu/~zayd/why-is-machine-learning-hard.html