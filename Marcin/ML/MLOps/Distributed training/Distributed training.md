# Distributed training
Distributed training to technika uczenia modeli korzystając z wielu maszyn jednocześnie. Powodem tego jest ogromna ilość danych która nie mieści się w pamięci jednego urządzenia czy też niewystarczająca moc pojedynczej maszyny, aby móc skończyć uczyć model w jakimś rozsądnym czasie.

Techniki:
1. [[Data Parallelism]]
2. [[Model Parallelism]]